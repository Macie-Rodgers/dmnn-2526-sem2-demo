<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.7.32">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Week 3: From Problem Framing to Tree-Based Models and Interpretability</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for syntax highlighting */
html { -webkit-text-size-adjust: 100%; }
pre > code.sourceCode { white-space: pre; position: relative; }
pre > code.sourceCode > span { display: inline-block; line-height: 1.25; }
pre > code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
div.sourceCode { margin: 1em 0; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
pre > code.sourceCode { white-space: pre-wrap; }
pre > code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
  }
pre.numberSource { margin-left: 3em;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
pre > code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
</style>


<script src="week3_files/libs/clipboard/clipboard.min.js"></script>
<script src="week3_files/libs/quarto-html/quarto.js" type="module"></script>
<script src="week3_files/libs/quarto-html/tabsets/tabsets.js" type="module"></script>
<script src="week3_files/libs/quarto-html/popper.min.js"></script>
<script src="week3_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="week3_files/libs/quarto-html/anchor.min.js"></script>
<link href="week3_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="week3_files/libs/quarto-html/quarto-syntax-highlighting-37eea08aefeeee20ff55810ff984fec1.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="week3_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="week3_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="week3_files/libs/bootstrap/bootstrap-bb462d781dde1847d9e3ccf7736099dd.min.css" rel="stylesheet" append-hash="true" id="quarto-bootstrap" data-mode="light">

  <script src="https://cdnjs.cloudflare.com/polyfill/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

<script type="text/javascript">
const typesetMath = (el) => {
  if (window.MathJax) {
    // MathJax Typeset
    window.MathJax.typeset([el]);
  } else if (window.katex) {
    // KaTeX Render
    var mathElements = el.getElementsByClassName("math");
    var macros = [];
    for (var i = 0; i < mathElements.length; i++) {
      var texText = mathElements[i].firstChild;
      if (mathElements[i].tagName == "SPAN") {
        window.katex.render(texText.data, mathElements[i], {
          displayMode: mathElements[i].classList.contains('display'),
          throwOnError: false,
          macros: macros,
          fleqn: false
        });
      }
    }
  }
}
window.Quarto = {
  typesetMath
};
</script>

</head>

<body class="quarto-light">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">
<div id="quarto-margin-sidebar" class="sidebar margin-sidebar">
  <nav id="TOC" role="doc-toc" class="toc-active">
    <h2 id="toc-title">Table of contents</h2>
   
  <ul>
  <li><a href="#part-a-reframing-the-task-as-a-machine-learning-problem" id="toc-part-a-reframing-the-task-as-a-machine-learning-problem" class="nav-link active" data-scroll-target="#part-a-reframing-the-task-as-a-machine-learning-problem">Part A — Reframing the Task as a Machine Learning Problem</a>
  <ul class="collapse">
  <li><a href="#a0.-load-the-dataset" id="toc-a0.-load-the-dataset" class="nav-link" data-scroll-target="#a0.-load-the-dataset">A0. Load the Dataset</a>
  <ul class="collapse">
  <li><a href="#r-load-and-inspect-the-data" id="toc-r-load-and-inspect-the-data" class="nav-link" data-scroll-target="#r-load-and-inspect-the-data">R: Load and Inspect the Data</a></li>
  <li><a href="#python-load-and-inspect-the-data" id="toc-python-load-and-inspect-the-data" class="nav-link" data-scroll-target="#python-load-and-inspect-the-data">Python: Load and Inspect the Data</a></li>
  </ul></li>
  <li><a href="#a1.-learning-requires-a-clear-question" id="toc-a1.-learning-requires-a-clear-question" class="nav-link" data-scroll-target="#a1.-learning-requires-a-clear-question">A1. Learning Requires a Clear Question</a></li>
  <li><a href="#a2.-do-we-have-labels" id="toc-a2.-do-we-have-labels" class="nav-link" data-scroll-target="#a2.-do-we-have-labels">A2. Do We Have Labels?</a></li>
  <li><a href="#a3.-supervised-learning-what-are-x-and-y" id="toc-a3.-supervised-learning-what-are-x-and-y" class="nav-link" data-scroll-target="#a3.-supervised-learning-what-are-x-and-y">A3. Supervised Learning — What Are X and Y?</a></li>
  <li><a href="#a4.-classification-or-regression" id="toc-a4.-classification-or-regression" class="nav-link" data-scroll-target="#a4.-classification-or-regression">A4. Classification or Regression?</a>
  <ul class="collapse">
  <li><a href="#inspecting-the-target-variable" id="toc-inspecting-the-target-variable" class="nav-link" data-scroll-target="#inspecting-the-target-variable">Inspecting the Target Variable</a></li>
  <li><a href="#interpretation" id="toc-interpretation" class="nav-link" data-scroll-target="#interpretation">Interpretation</a></li>
  </ul></li>
  <li><a href="#a5.-what-this-notebook-is-and-is-not-doing" id="toc-a5.-what-this-notebook-is-and-is-not-doing" class="nav-link" data-scroll-target="#a5.-what-this-notebook-is-and-is-not-doing">A5. What This Notebook Is — and Is Not — Doing</a></li>
  </ul></li>
  <li><a href="#part-b-defining-inputs-x-and-output-y" id="toc-part-b-defining-inputs-x-and-output-y" class="nav-link" data-scroll-target="#part-b-defining-inputs-x-and-output-y">Part B — Defining Inputs (X) and Output (Y)</a>
  <ul class="collapse">
  <li><a href="#part-b-what-information-can-the-model-use" id="toc-part-b-what-information-can-the-model-use" class="nav-link" data-scroll-target="#part-b-what-information-can-the-model-use">Part B: What Information Can the Model Use?</a></li>
  <li><a href="#b1.-revisiting-feature-validity-from-week-1" id="toc-b1.-revisiting-feature-validity-from-week-1" class="nav-link" data-scroll-target="#b1.-revisiting-feature-validity-from-week-1">B1. Revisiting Feature Validity (from Week 1)</a></li>
  <li><a href="#b2.-feature-eligibility-summary" id="toc-b2.-feature-eligibility-summary" class="nav-link" data-scroll-target="#b2.-feature-eligibility-summary">B2. Feature Eligibility Summary</a></li>
  <li><a href="#b3.-creating-the-modelling-dataset" id="toc-b3.-creating-the-modelling-dataset" class="nav-link" data-scroll-target="#b3.-creating-the-modelling-dataset">B3. Creating the Modelling Dataset</a>
  <ul class="collapse">
  <li><a href="#r-preparing-the-modelling-data" id="toc-r-preparing-the-modelling-data" class="nav-link" data-scroll-target="#r-preparing-the-modelling-data">R: Preparing the Modelling Data</a></li>
  <li><a href="#python-preparing-the-modelling-data" id="toc-python-preparing-the-modelling-data" class="nav-link" data-scroll-target="#python-preparing-the-modelling-data">Python: Preparing the Modelling Data</a></li>
  </ul></li>
  <li><a href="#b4.-a-note-on-what-we-are-not-doing-yet" id="toc-b4.-a-note-on-what-we-are-not-doing-yet" class="nav-link" data-scroll-target="#b4.-a-note-on-what-we-are-not-doing-yet">B4. A Note on What We Are <em>Not</em> Doing Yet</a></li>
  <li><a href="#key-takeaway-from-parts-a-and-b" id="toc-key-takeaway-from-parts-a-and-b" class="nav-link" data-scroll-target="#key-takeaway-from-parts-a-and-b">Key Takeaway from Parts A and B</a></li>
  </ul></li>
  <li><a href="#part-c-decision-trees-learning-through-splits" id="toc-part-c-decision-trees-learning-through-splits" class="nav-link" data-scroll-target="#part-c-decision-trees-learning-through-splits">Part C — Decision Trees: Learning Through Splits</a>
  <ul class="collapse">
  <li><a href="#part-c-why-decision-trees" id="toc-part-c-why-decision-trees" class="nav-link" data-scroll-target="#part-c-why-decision-trees">Part C: Why Decision Trees?</a></li>
  <li><a href="#c1.-the-core-idea-behind-a-decision-tree" id="toc-c1.-the-core-idea-behind-a-decision-tree" class="nav-link" data-scroll-target="#c1.-the-core-idea-behind-a-decision-tree">C1. The Core Idea Behind a Decision Tree</a></li>
  <li><a href="#c2.-what-does-learning-mean-for-a-tree" id="toc-c2.-what-does-learning-mean-for-a-tree" class="nav-link" data-scroll-target="#c2.-what-does-learning-mean-for-a-tree">C2. What Does “Learning” Mean for a Tree?</a></li>
  <li><a href="#c3.-training-a-simple-classification-tree" id="toc-c3.-training-a-simple-classification-tree" class="nav-link" data-scroll-target="#c3.-training-a-simple-classification-tree">C3. Training a Simple Classification Tree</a>
  <ul class="collapse">
  <li><a href="#r-training-a-decision-tree" id="toc-r-training-a-decision-tree" class="nav-link" data-scroll-target="#r-training-a-decision-tree">R: Training a Decision Tree</a></li>
  <li><a href="#python-training-a-decision-tree" id="toc-python-training-a-decision-tree" class="nav-link" data-scroll-target="#python-training-a-decision-tree">Python: Training a Decision Tree</a></li>
  </ul></li>
  <li><a href="#c4.-reading-a-decision-tree" id="toc-c4.-reading-a-decision-tree" class="nav-link" data-scroll-target="#c4.-reading-a-decision-tree">C4. Reading a Decision Tree</a></li>
  <li><a href="#c6.-trees-do-not-require-scaling-and-why" id="toc-c6.-trees-do-not-require-scaling-and-why" class="nav-link" data-scroll-target="#c6.-trees-do-not-require-scaling-and-why">C6. Trees Do Not Require Scaling — and Why</a></li>
  <li><a href="#c7.-instability-of-single-trees" id="toc-c7.-instability-of-single-trees" class="nav-link" data-scroll-target="#c7.-instability-of-single-trees">C7. Instability of Single Trees</a></li>
  </ul></li>
  <li><a href="#part-d-from-one-tree-to-many-tree-ensembles" id="toc-part-d-from-one-tree-to-many-tree-ensembles" class="nav-link" data-scroll-target="#part-d-from-one-tree-to-many-tree-ensembles">Part D — From One Tree to Many: Tree Ensembles</a>
  <ul class="collapse">
  <li><a href="#part-d-why-go-beyond-a-single-tree" id="toc-part-d-why-go-beyond-a-single-tree" class="nav-link" data-scroll-target="#part-d-why-go-beyond-a-single-tree">Part D: Why Go Beyond a Single Tree?</a></li>
  <li><a href="#d1.-the-idea-behind-ensembles" id="toc-d1.-the-idea-behind-ensembles" class="nav-link" data-scroll-target="#d1.-the-idea-behind-ensembles">D1. The Idea Behind Ensembles</a></li>
  <li><a href="#d2.-random-forests-stability-through-randomness" id="toc-d2.-random-forests-stability-through-randomness" class="nav-link" data-scroll-target="#d2.-random-forests-stability-through-randomness">D2. Random Forests — Stability Through Randomness</a>
  <ul class="collapse">
  <li><a href="#conceptual-overview" id="toc-conceptual-overview" class="nav-link" data-scroll-target="#conceptual-overview">Conceptual Overview</a></li>
  <li><a href="#r-training-a-random-forest" id="toc-r-training-a-random-forest" class="nav-link" data-scroll-target="#r-training-a-random-forest">R: Training a Random Forest</a></li>
  <li><a href="#python-training-a-random-forest" id="toc-python-training-a-random-forest" class="nav-link" data-scroll-target="#python-training-a-random-forest">Python: Training a Random Forest</a></li>
  </ul></li>
  <li><a href="#d3.-boosted-trees-learning-from-mistakes" id="toc-d3.-boosted-trees-learning-from-mistakes" class="nav-link" data-scroll-target="#d3.-boosted-trees-learning-from-mistakes">D3. Boosted Trees — Learning From Mistakes</a>
  <ul class="collapse">
  <li><a href="#conceptual-overview-1" id="toc-conceptual-overview-1" class="nav-link" data-scroll-target="#conceptual-overview-1">Conceptual Overview</a></li>
  <li><a href="#r-training-a-boosted-tree-model" id="toc-r-training-a-boosted-tree-model" class="nav-link" data-scroll-target="#r-training-a-boosted-tree-model">R: Training a Boosted Tree Model</a></li>
  <li><a href="#python-training-a-boosted-tree-model" id="toc-python-training-a-boosted-tree-model" class="nav-link" data-scroll-target="#python-training-a-boosted-tree-model">Python: Training a Boosted Tree Model</a></li>
  </ul></li>
  <li><a href="#d4.-comparing-behaviour-not-scores" id="toc-d4.-comparing-behaviour-not-scores" class="nav-link" data-scroll-target="#d4.-comparing-behaviour-not-scores">D4. Comparing Behaviour (Not Scores)</a>
  <ul class="collapse">
  <li><a href="#training-accuracy-illustrative-only" id="toc-training-accuracy-illustrative-only" class="nav-link" data-scroll-target="#training-accuracy-illustrative-only">Training Accuracy (Illustrative Only)</a></li>
  </ul></li>
  <li><a href="#d5.-strengths-and-trade-offs" id="toc-d5.-strengths-and-trade-offs" class="nav-link" data-scroll-target="#d5.-strengths-and-trade-offs">D5. Strengths and Trade-offs</a></li>
  <li><a href="#d6.-training-validation-and-test-sets" id="toc-d6.-training-validation-and-test-sets" class="nav-link" data-scroll-target="#d6.-training-validation-and-test-sets">D6. Training, Validation, and Test Sets</a>
  <ul class="collapse">
  <li><a href="#why-we-split-the-data" id="toc-why-we-split-the-data" class="nav-link" data-scroll-target="#why-we-split-the-data">Why We Split the Data</a></li>
  <li><a href="#conceptual-warning" id="toc-conceptual-warning" class="nav-link" data-scroll-target="#conceptual-warning">Conceptual Warning</a></li>
  </ul></li>
  <li><a href="#d6.1-creating-train-validation-test-splits" id="toc-d6.1-creating-train-validation-test-splits" class="nav-link" data-scroll-target="#d6.1-creating-train-validation-test-splits">D6.1 Creating Train / Validation / Test Splits</a>
  <ul class="collapse">
  <li><a href="#r-splitting-the-data" id="toc-r-splitting-the-data" class="nav-link" data-scroll-target="#r-splitting-the-data">R: Splitting the Data</a></li>
  <li><a href="#python-splitting-the-data" id="toc-python-splitting-the-data" class="nav-link" data-scroll-target="#python-splitting-the-data">Python: Splitting the Data</a></li>
  </ul></li>
  <li><a href="#d6.2-re-training-models-on-the-training-set" id="toc-d6.2-re-training-models-on-the-training-set" class="nav-link" data-scroll-target="#d6.2-re-training-models-on-the-training-set">D6.2 Re-training Models on the Training Set</a>
  <ul class="collapse">
  <li><a href="#r-re-training-models" id="toc-r-re-training-models" class="nav-link" data-scroll-target="#r-re-training-models">R: Re-training Models</a></li>
  <li><a href="#python-re-training-models" id="toc-python-re-training-models" class="nav-link" data-scroll-target="#python-re-training-models">Python: Re-training Models</a></li>
  </ul></li>
  <li><a href="#d6.3-comparing-behaviour-across-roles" id="toc-d6.3-comparing-behaviour-across-roles" class="nav-link" data-scroll-target="#d6.3-comparing-behaviour-across-roles">D6.3 Comparing Behaviour Across Roles</a>
  <ul class="collapse">
  <li><a href="#r-2" id="toc-r-2" class="nav-link" data-scroll-target="#r-2">R</a></li>
  <li><a href="#python-2" id="toc-python-2" class="nav-link" data-scroll-target="#python-2">Python</a></li>
  </ul></li>
  <li><a href="#d6.4-a-final-check-on-the-test-set" id="toc-d6.4-a-final-check-on-the-test-set" class="nav-link" data-scroll-target="#d6.4-a-final-check-on-the-test-set">D6.4 A Final Check on the Test Set</a>
  <ul class="collapse">
  <li><a href="#r-test-set-accuracy" id="toc-r-test-set-accuracy" class="nav-link" data-scroll-target="#r-test-set-accuracy">R: Test Set Accuracy</a></li>
  <li><a href="#python-test-set-accuracy" id="toc-python-test-set-accuracy" class="nav-link" data-scroll-target="#python-test-set-accuracy">Python: Test Set Accuracy</a></li>
  </ul></li>
  <li><a href="#d6.5-whats-not-covered" id="toc-d6.5-whats-not-covered" class="nav-link" data-scroll-target="#d6.5-whats-not-covered">D6.5 Whats Not Covered</a>
  <ul class="collapse">
  <li><a href="#key-takeaway-from-part-d6" id="toc-key-takeaway-from-part-d6" class="nav-link" data-scroll-target="#key-takeaway-from-part-d6">Key takeaway from Part D6</a></li>
  </ul></li>
  </ul></li>
  <li><a href="#part-e-interpretability-understanding-model-decisions" id="toc-part-e-interpretability-understanding-model-decisions" class="nav-link" data-scroll-target="#part-e-interpretability-understanding-model-decisions">Part E — Interpretability: Understanding Model Decisions</a>
  <ul class="collapse">
  <li><a href="#e1.-global-interpretability-which-features-matter-overall" id="toc-e1.-global-interpretability-which-features-matter-overall" class="nav-link" data-scroll-target="#e1.-global-interpretability-which-features-matter-overall">E1. Global Interpretability — Which Features Matter Overall?</a>
  <ul class="collapse">
  <li><a href="#r-feature-importance-random-forest" id="toc-r-feature-importance-random-forest" class="nav-link" data-scroll-target="#r-feature-importance-random-forest">R: Feature Importance (Random Forest)</a></li>
  <li><a href="#python-feature-importance-random-forest" id="toc-python-feature-importance-random-forest" class="nav-link" data-scroll-target="#python-feature-importance-random-forest">Python: Feature Importance (Random Forest)</a></li>
  </ul></li>
  <li><a href="#e2.-interpreting-feature-importance-carefully" id="toc-e2.-interpreting-feature-importance-carefully" class="nav-link" data-scroll-target="#e2.-interpreting-feature-importance-carefully">E2. Interpreting Feature Importance Carefully</a></li>
  <li><a href="#e3.-local-interpretability-explaining-individual-predictions" id="toc-e3.-local-interpretability-explaining-individual-predictions" class="nav-link" data-scroll-target="#e3.-local-interpretability-explaining-individual-predictions">E3. Local Interpretability — Explaining Individual Predictions</a></li>
  <li><a href="#e4.-interpretability-as-a-modelling-constraint" id="toc-e4.-interpretability-as-a-modelling-constraint" class="nav-link" data-scroll-target="#e4.-interpretability-as-a-modelling-constraint">E4. Interpretability as a Modelling Constraint</a></li>
  <li><a href="#key-takeaway-from-parts-d-and-e" id="toc-key-takeaway-from-parts-d-and-e" class="nav-link" data-scroll-target="#key-takeaway-from-parts-d-and-e">Key Takeaway from Parts D and E</a></li>
  </ul></li>
  <li><a href="#part-f-from-meaning-to-models-a-reflective-synthesis" id="toc-part-f-from-meaning-to-models-a-reflective-synthesis" class="nav-link" data-scroll-target="#part-f-from-meaning-to-models-a-reflective-synthesis">Part F — From Meaning to Models: A Reflective Synthesis</a>
  <ul class="collapse">
  <li><a href="#part-f-what-have-we-actually-done" id="toc-part-f-what-have-we-actually-done" class="nav-link" data-scroll-target="#part-f-what-have-we-actually-done">Part F: What Have We Actually Done?</a></li>
  <li><a href="#f1.-the-journey-so-far" id="toc-f1.-the-journey-so-far" class="nav-link" data-scroll-target="#f1.-the-journey-so-far">F1. The Journey So Far</a></li>
  <li><a href="#f2.-accuracy-was-never-the-main-goal" id="toc-f2.-accuracy-was-never-the-main-goal" class="nav-link" data-scroll-target="#f2.-accuracy-was-never-the-main-goal">F2. Accuracy Was Never the Main Goal</a></li>
  <li><a href="#f3.-why-interpretability-is-not-optional" id="toc-f3.-why-interpretability-is-not-optional" class="nav-link" data-scroll-target="#f3.-why-interpretability-is-not-optional">F3. Why Interpretability Is Not Optional</a></li>
  <li><a href="#f4.-model-choice-is-a-contextual-decision" id="toc-f4.-model-choice-is-a-contextual-decision" class="nav-link" data-scroll-target="#f4.-model-choice-is-a-contextual-decision">F4. Model Choice Is a Contextual Decision</a></li>
  <li><a href="#f5.-what-we-deliberately-did-not-do" id="toc-f5.-what-we-deliberately-did-not-do" class="nav-link" data-scroll-target="#f5.-what-we-deliberately-did-not-do">F5. What We Deliberately Did <em>Not</em> Do</a></li>
  <li><a href="#f6.-looking-ahead" id="toc-f6.-looking-ahead" class="nav-link" data-scroll-target="#f6.-looking-ahead">F6. Looking Ahead</a></li>
  <li><a href="#final-takeaway" id="toc-final-takeaway" class="nav-link" data-scroll-target="#final-takeaway">Final Takeaway</a></li>
  </ul></li>
  </ul>
<div class="quarto-alternate-formats"><h2>Other Formats</h2><ul><li><a href="week3.pdf"><i class="bi bi-file-pdf"></i>PDF</a></li></ul></div></nav>
</div>
<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Week 3: From Problem Framing to Tree-Based Models and Interpretability</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  


</header>


<section id="part-a-reframing-the-task-as-a-machine-learning-problem" class="level1">
<h1>Part A — Reframing the Task as a Machine Learning Problem</h1>
<hr>
<p>In <strong>Week 1</strong>, we focused on understanding the dataset:</p>
<ul>
<li>what a row represents,</li>
<li>how variables are generated,</li>
<li>which values are meaningful,</li>
<li>and which variables are valid at prediction time.</li>
</ul>
<p>In this notebook, we move to a <strong>different kind of question</strong>:</p>
<blockquote class="blockquote">
<p><strong>Given what we now understand about the data, how can we frame this as a machine learning problem?</strong></p>
</blockquote>
<hr>
<section id="a0.-load-the-dataset" class="level2">
<h2 class="anchored" data-anchor-id="a0.-load-the-dataset">A0. Load the Dataset</h2>
<p>We continue to use the same “UCI Bank Marketing” dataset that we selected for week 1.</p>
<section id="r-load-and-inspect-the-data" class="level3">
<h3 class="anchored" data-anchor-id="r-load-and-inspect-the-data">R: Load and Inspect the Data</h3>
<section id="load-required-packages" class="level4">
<h4 class="anchored" data-anchor-id="load-required-packages">Load required packages</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb1"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb1-1"><a href="#cb1-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(tidyverse)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="read-the-dataset" class="level4">
<h4 class="anchored" data-anchor-id="read-the-dataset">Read the dataset</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb2"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb2-1"><a href="#cb2-1" aria-hidden="true" tabindex="-1"></a>bank <span class="ot">&lt;-</span> <span class="fu">read.csv</span>(<span class="st">"data/raw/bank-additional.csv"</span>, <span class="at">sep =</span> <span class="st">";"</span>,</span>
<span id="cb2-2"><a href="#cb2-2" aria-hidden="true" tabindex="-1"></a><span class="at">stringsAsFactors =</span> <span class="cn">FALSE</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="display-first-few-rows" class="level4">
<h4 class="anchored" data-anchor-id="display-first-few-rows">Display first few rows</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb3"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb3-1"><a href="#cb3-1" aria-hidden="true" tabindex="-1"></a><span class="fu">head</span>(bank)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>  age         job marital         education default housing    loan   contact
1  30 blue-collar married          basic.9y      no     yes      no  cellular
2  39    services  single       high.school      no      no      no telephone
3  25    services married       high.school      no     yes      no telephone
4  38    services married          basic.9y      no unknown unknown telephone
5  47      admin. married university.degree      no     yes      no  cellular
6  32    services  single university.degree      no      no      no  cellular
  month day_of_week duration campaign pdays previous    poutcome emp.var.rate
1   may         fri      487        2   999        0 nonexistent         -1.8
2   may         fri      346        4   999        0 nonexistent          1.1
3   jun         wed      227        1   999        0 nonexistent          1.4
4   jun         fri       17        3   999        0 nonexistent          1.4
5   nov         mon       58        1   999        0 nonexistent         -0.1
6   sep         thu      128        3   999        2     failure         -1.1
  cons.price.idx cons.conf.idx euribor3m nr.employed  y
1         92.893         -46.2     1.313      5099.1 no
2         93.994         -36.4     4.855      5191.0 no
3         94.465         -41.8     4.962      5228.1 no
4         94.465         -41.8     4.959      5228.1 no
5         93.200         -42.0     4.191      5195.8 no
6         94.199         -37.5     0.884      4963.6 no</code></pre>
</div>
</div>
</section>
</section>
<section id="python-load-and-inspect-the-data" class="level3">
<h3 class="anchored" data-anchor-id="python-load-and-inspect-the-data">Python: Load and Inspect the Data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb5"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb5-1"><a href="#cb5-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<section id="read-the-dataset-1" class="level4">
<h4 class="anchored" data-anchor-id="read-the-dataset-1">Read the dataset</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb6"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb6-1"><a href="#cb6-1" aria-hidden="true" tabindex="-1"></a>bank <span class="op">=</span> pd.read_csv(<span class="st">"data/raw/bank-additional.csv"</span>, sep<span class="op">=</span><span class="st">";"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
</section>
<section id="display-first-few-rows-1" class="level4">
<h4 class="anchored" data-anchor-id="display-first-few-rows-1">Display first few rows</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb7"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb7-1"><a href="#cb7-1" aria-hidden="true" tabindex="-1"></a>bank.head()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>   age          job  marital  ... euribor3m nr.employed   y
0   30  blue-collar  married  ...     1.313      5099.1  no
1   39     services   single  ...     4.855      5191.0  no
2   25     services  married  ...     4.962      5228.1  no
3   38     services  married  ...     4.959      5228.1  no
4   47       admin.  married  ...     4.191      5195.8  no

[5 rows x 21 columns]</code></pre>
</div>
</div>
</section>
</section>
</section>
<section id="a1.-learning-requires-a-clear-question" class="level2">
<h2 class="anchored" data-anchor-id="a1.-learning-requires-a-clear-question">A1. Learning Requires a Clear Question</h2>
<p>Machine learning is not applied <em>to data</em> — it is applied <em>to questions</em>.</p>
<p>Before writing any model code, we must be able to answer:</p>
<ul>
<li>Do we have correct answers available?</li>
<li>Are we trying to predict something, or discover structure?</li>
<li>If we are predicting, what exactly is the output?</li>
</ul>
<p>Only once these questions are answered does it make sense to talk about models.</p>
<hr>
</section>
<section id="a2.-do-we-have-labels" class="level2">
<h2 class="anchored" data-anchor-id="a2.-do-we-have-labels">A2. Do We Have Labels?</h2>
<p>Recall the variable <code>y</code> in the Bank Marketing dataset.</p>
<p>It records whether a contacted client <strong>subscribed to a term deposit</strong> (<code>yes</code> or <code>no</code>).</p>
<p>This means:</p>
<ul>
<li>For each row, we already know the outcome.</li>
<li>The “right answer” is available during training.</li>
<li>The dataset contains <strong>input–output pairs</strong>.</li>
</ul>
<p>Therefore, this dataset supports <strong>supervised learning</strong>.</p>
<blockquote class="blockquote">
<p><strong>Supervised learning</strong> means learning from examples where the correct output is known.</p>
</blockquote>
<hr>
</section>
<section id="a3.-supervised-learning-what-are-x-and-y" class="level2">
<h2 class="anchored" data-anchor-id="a3.-supervised-learning-what-are-x-and-y">A3. Supervised Learning — What Are X and Y?</h2>
<p>In supervised learning, we distinguish between:</p>
<ul>
<li><strong>Inputs (X):</strong> the information we use to make a decision</li>
<li><strong>Output (Y):</strong> the value we want to predict</li>
</ul>
<p>In our case:</p>
<ul>
<li><strong>Y:</strong> whether the client subscribed (<code>y</code>)</li>
<li><strong>X:</strong> client attributes, campaign details, and economic context variables</li>
</ul>
<p>This distinction is critical, because:</p>
<ul>
<li>not all variables can appear in X,</li>
<li>and some variables may look useful but are invalid.</li>
</ul>
<p>We will revisit this shortly.</p>
<hr>
</section>
<section id="a4.-classification-or-regression" class="level2">
<h2 class="anchored" data-anchor-id="a4.-classification-or-regression">A4. Classification or Regression?</h2>
<p>Supervised learning problems typically fall into two categories:</p>
<ul>
<li><strong>Regression:</strong> predicting a numeric value</li>
<li><strong>Classification:</strong> predicting a category</li>
</ul>
<p>Let us examine the target variable <code>y</code>.</p>
<hr>
<section id="inspecting-the-target-variable" class="level3">
<h3 class="anchored" data-anchor-id="inspecting-the-target-variable">Inspecting the Target Variable</h3>
<section id="r" class="level4">
<h4 class="anchored" data-anchor-id="r">R</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb9"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb9-1"><a href="#cb9-1" aria-hidden="true" tabindex="-1"></a><span class="fu">table</span>(bank<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
  no  yes 
3668  451 </code></pre>
</div>
<div class="sourceCode cell-code" id="cb11"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb11-1"><a href="#cb11-1" aria-hidden="true" tabindex="-1"></a><span class="fu">prop.table</span>(<span class="fu">table</span>(bank<span class="sc">$</span>y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>
       no       yes 
0.8905074 0.1094926 </code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-1-contents" aria-controls="callout-1" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-1" class="callout-1-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><code>table(bank$y)</code> counts how many observations belong to each class.</li>
<li><code>prop.table(...)</code> converts counts into proportions.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Before building any model, we need to understand <strong>class balance</strong>.</li>
<li>This affects how we interpret predictions and accuracy later.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python" class="level4">
<h4 class="anchored" data-anchor-id="python">Python</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb13"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb13-1"><a href="#cb13-1" aria-hidden="true" tabindex="-1"></a>bank[<span class="st">"y"</span>].value_counts()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>y
no     3668
yes     451
Name: count, dtype: int64</code></pre>
</div>
<div class="sourceCode cell-code" id="cb15"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb15-1"><a href="#cb15-1" aria-hidden="true" tabindex="-1"></a>bank[<span class="st">"y"</span>].value_counts(normalize<span class="op">=</span><span class="va">True</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>y
no     0.890507
yes    0.109493
Name: proportion, dtype: float64</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-2-contents" aria-controls="callout-2" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-2" class="callout-2-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><code>.value_counts()</code> counts observations per class.</li>
<li><code>normalize=True</code> converts counts to proportions.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Many machine learning issues originate from imbalanced targets.</li>
<li>We observe this early, rather than discovering it after modelling.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="interpretation" class="level3">
<h3 class="anchored" data-anchor-id="interpretation">Interpretation</h3>
<p>From this inspection:</p>
<ul>
<li><code>y</code> has <strong>two categories</strong>: <code>yes</code> and <code>no</code></li>
<li>The classes are <strong>not evenly balanced</strong></li>
<li>The output is <strong>categorical</strong>, not numeric</li>
</ul>
<p>Therefore:</p>
<blockquote class="blockquote">
<p>This is a <strong>binary classification</strong> problem.</p>
</blockquote>
<p>At this stage, we simply <strong>acknowledge</strong> the imbalance. We do <em>not</em> attempt to “fix” it yet.</p>
<hr>
</section>
</section>
<section id="a5.-what-this-notebook-is-and-is-not-doing" class="level2">
<h2 class="anchored" data-anchor-id="a5.-what-this-notebook-is-and-is-not-doing">A5. What This Notebook Is — and Is Not — Doing</h2>
<p>Before proceeding, it is important to be explicit about scope.</p>
<p>In this notebook, we <strong>will</strong>:</p>
<ul>
<li>frame the problem correctly,</li>
<li>train interpretable tree-based models,</li>
<li>reason about model behaviour and explanations.</li>
</ul>
<p>We <strong>will not</strong>:</p>
<ul>
<li>optimise performance aggressively,</li>
<li>tune hyperparameters extensively,</li>
<li>treat accuracy as the main objective.</li>
</ul>
<p>This mirrors the philosophy of Week 1:</p>
<blockquote class="blockquote">
<p><strong>Sound modelling decisions come before performance optimisation.</strong></p>
</blockquote>
<hr>
</section>
</section>
<section id="part-b-defining-inputs-x-and-output-y" class="level1">
<h1>Part B — Defining Inputs (X) and Output (Y)</h1>
<hr>
<section id="part-b-what-information-can-the-model-use" class="level2">
<h2 class="anchored" data-anchor-id="part-b-what-information-can-the-model-use">Part B: What Information Can the Model Use?</h2>
<p>Once we have identified the learning type, the next question is:</p>
<blockquote class="blockquote">
<p><strong>Which variables are legitimate inputs at prediction time?</strong></p>
</blockquote>
<p>This is not a technical question — it is a <strong>validity question</strong>.</p>
<hr>
</section>
<section id="b1.-revisiting-feature-validity-from-week-1" class="level2">
<h2 class="anchored" data-anchor-id="b1.-revisiting-feature-validity-from-week-1">B1. Revisiting Feature Validity (from Week 1)</h2>
<p>From Week 1, we already know:</p>
<ul>
<li>some variables are only known <em>after</em> the call,</li>
<li>some variables contain sentinel values,</li>
<li>some variables encode past outcomes.</li>
</ul>
<p>Using such variables incorrectly can lead to:</p>
<ul>
<li>data leakage,</li>
<li>unrealistically high performance,</li>
<li>invalid conclusions.</li>
</ul>
<p>We therefore <strong>revisit</strong> feature eligibility before modelling.</p>
<hr>
</section>
<section id="b2.-feature-eligibility-summary" class="level2">
<h2 class="anchored" data-anchor-id="b2.-feature-eligibility-summary">B2. Feature Eligibility Summary</h2>
<p>We classify variables into three broad categories:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Category</th>
<th>Meaning</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>✔ Valid</td>
<td>Known before prediction, safe to use</td>
</tr>
<tr class="even">
<td>⚠ Requires care</td>
<td>Encoded values or indirect information</td>
</tr>
<tr class="odd">
<td>✘ Invalid</td>
<td>Known only after outcome (leakage)</td>
</tr>
</tbody>
</table>
<p>A critical example:</p>
<ul>
<li><p><code>duration</code> — call length</p>
<ul>
<li>known <strong>after</strong> the call ends</li>
<li>directly correlated with success</li>
<li><strong>must not</strong> be used for prediction</li>
</ul></li>
</ul>
<hr>
</section>
<section id="b3.-creating-the-modelling-dataset" class="level2">
<h2 class="anchored" data-anchor-id="b3.-creating-the-modelling-dataset">B3. Creating the Modelling Dataset</h2>
<p>We now construct a dataset suitable for modelling by:</p>
<ul>
<li>removing invalid features,</li>
<li>keeping representation simple and explicit,</li>
<li><strong>not</strong> performing aggressive cleaning yet.</li>
</ul>
<hr>
<section id="r-preparing-the-modelling-data" class="level3">
<h3 class="anchored" data-anchor-id="r-preparing-the-modelling-data">R: Preparing the Modelling Data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb17"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb17-1"><a href="#cb17-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(dplyr)</span>
<span id="cb17-2"><a href="#cb17-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb17-3"><a href="#cb17-3" aria-hidden="true" tabindex="-1"></a>model_data <span class="ot">&lt;-</span> bank <span class="sc">%&gt;%</span></span>
<span id="cb17-4"><a href="#cb17-4" aria-hidden="true" tabindex="-1"></a>  <span class="fu">select</span>(<span class="sc">-</span>duration) <span class="sc">%&gt;%</span></span>
<span id="cb17-5"><a href="#cb17-5" aria-hidden="true" tabindex="-1"></a>  <span class="fu">mutate</span>(<span class="at">y =</span> <span class="fu">as.factor</span>(y))</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-3-contents" aria-controls="callout-3" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-3" class="callout-3-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><code>select(-duration)</code> removes a variable that causes data leakage.</li>
<li><code>as.factor(y)</code> ensures the target is treated as categorical.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Even though trees can sometimes infer types automatically, <strong>being explicit prevents silent modelling mistakes</strong>.</li>
<li>Removing leakage variables early protects model validity.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python-preparing-the-modelling-data" class="level3">
<h3 class="anchored" data-anchor-id="python-preparing-the-modelling-data">Python: Preparing the Modelling Data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb18"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb18-1"><a href="#cb18-1" aria-hidden="true" tabindex="-1"></a>model_data <span class="op">=</span> bank.drop(columns<span class="op">=</span>[<span class="st">"duration"</span>])</span>
<span id="cb18-2"><a href="#cb18-2" aria-hidden="true" tabindex="-1"></a>model_data[<span class="st">"y"</span>] <span class="op">=</span> model_data[<span class="st">"y"</span>].astype(<span class="st">"category"</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-4-contents" aria-controls="callout-4" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-4" class="callout-4-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Drops the <code>duration</code> column to prevent leakage.</li>
<li>Converts <code>y</code> to a categorical type.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Some libraries behave differently depending on data types.</li>
<li>Explicit types make modelling intent clear and reproducible.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="b4.-a-note-on-what-we-are-not-doing-yet" class="level2">
<h2 class="anchored" data-anchor-id="b4.-a-note-on-what-we-are-not-doing-yet">B4. A Note on What We Are <em>Not</em> Doing Yet</h2>
<p>At this stage, we deliberately avoid:</p>
<ul>
<li>one-hot encoding,</li>
<li>scaling,</li>
<li>imputation,</li>
<li>feature selection.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-5-contents" aria-controls="callout-5" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Brief explanations of the steps we are avoiding (for context)
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-5" class="callout-5-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>These terms appear frequently in machine learning workflows.<br>
We briefly explain them here for awareness — <strong>not because you must apply them now</strong>.</p>
<p><strong>One-hot encoding</strong><br>
Converts categorical variables into multiple binary (0/1) columns.<br>
For example, a variable like <code>Country</code> may become many columns such as <code>Country_UK</code>, <code>Country_France</code>, etc.</p>
<p><strong>Scaling</strong><br>
Rescales numeric variables (e.g.&nbsp;standardisation or normalisation) so they have comparable ranges.<br>
This is important for distance-based models but not all models require it.</p>
<p><strong>Imputation</strong><br>
Fills in missing values using rules such as mean, median, or model-based estimates.<br>
Imputation always introduces assumptions about the data.</p>
<p><strong>Feature selection</strong><br>
Chooses a subset of variables to keep, often based on statistical or model-based criteria.<br>
This can simplify models but may also remove meaningful information if done prematurely.</p>
<p>These steps are common — but they are <strong>not neutral</strong>. Each one changes how the data represents reality.</p>
</div>
</div>
</div>
<p>Why?</p>
<p>Because:</p>
<ul>
<li>trees do not require scaling,</li>
<li>encoding is a <strong>modelling choice</strong>, not a default step,</li>
<li>premature transformations hide reasoning.</li>
</ul>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-6-contents" aria-controls="callout-6" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why we postpone these steps in this notebook
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-6" class="callout-6-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Each reason below relates directly to how decision trees behave.</p>
<p><strong>Trees do not require scaling</strong><br>
Decision trees split data using rules like<br>
“Is <code>total_spend &gt; 100</code>?”<br>
They compare values, not distances, so feature scale does not affect the result.</p>
<p><strong>Encoding is a modelling choice, not a default step</strong><br>
How categories are encoded determines how the model can use them.<br>
Encoding too early can hide important decisions about meaning and structure.</p>
<p><strong>Premature transformations hide reasoning</strong><br>
Early transformations make the data look “model-ready” but obscure: - what information is original, - what assumptions were introduced, - and how modelling decisions affect results.</p>
<p>In this module, we prioritise <strong>understanding before automation</strong>.</p>
</div>
</div>
</div>
<p>These steps are <strong>used as needed</strong>, and <strong>not as a default choice</strong>.</p>
<hr>
</section>
<section id="key-takeaway-from-parts-a-and-b" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaway-from-parts-a-and-b">Key Takeaway from Parts A and B</h2>
<blockquote class="blockquote">
<p><strong>Machine learning starts with decisions about meaning, not algorithms.</strong></p>
</blockquote>
<p>So far, we have:</p>
<ul>
<li>identified this as a <strong>supervised classification problem</strong>,</li>
<li>defined a valid target variable,</li>
<li>constructed a leakage-free input dataset,</li>
<li>resisted premature optimisation.</li>
</ul>
<p>Only now are we ready to introduce models.</p>
<hr>
</section>
</section>
<section id="part-c-decision-trees-learning-through-splits" class="level1">
<h1>Part C — Decision Trees: Learning Through Splits</h1>
<hr>
<section id="part-c-why-decision-trees" class="level2">
<h2 class="anchored" data-anchor-id="part-c-why-decision-trees">Part C: Why Decision Trees?</h2>
<p>Let’s begin with <strong>decision trees</strong> as out first model. This is a simple place to start because decision trees:</p>
<ul>
<li>make predictions using <strong>explicit rules</strong>,</li>
<li>resemble human decision-making,</li>
<li>work naturally with mixed data types,</li>
<li>allow us to <em>see</em> how decisions are made.</li>
</ul>
<p>Most importantly:</p>
<blockquote class="blockquote">
<p><strong>Decision trees make modelling assumptions visible.</strong></p>
</blockquote>
<p>This makes them an ideal first model — not because they are the most powerful, but <strong>because they are the most transparent</strong>.</p>
<hr>
</section>
<section id="c1.-the-core-idea-behind-a-decision-tree" class="level2">
<h2 class="anchored" data-anchor-id="c1.-the-core-idea-behind-a-decision-tree">C1. The Core Idea Behind a Decision Tree</h2>
<p>A decision tree learns by repeatedly asking questions such as:</p>
<ul>
<li><em>Is age greater than some value?</em></li>
<li><em>Is contact method equal to “cellular”?</em></li>
<li><em>Was the client contacted before?</em></li>
</ul>
<p>Each question:</p>
<ul>
<li>splits the data into groups,</li>
<li>aims to make those groups <strong>more homogeneous</strong> with respect to the target variable.</li>
</ul>
<p>This idea of homogeneity is often described as <strong>purity</strong>.</p>
<hr>
</section>
<section id="c2.-what-does-learning-mean-for-a-tree" class="level2">
<h2 class="anchored" data-anchor-id="c2.-what-does-learning-mean-for-a-tree">C2. What Does “Learning” Mean for a Tree?</h2>
<p>A decision tree is <em>not</em> memorising rows.</p>
<p>Instead, it:</p>
<ol type="1">
<li>evaluates many possible splits,</li>
<li>chooses the split that best improves purity,</li>
<li>applies the same logic recursively to the resulting subsets.</li>
</ol>
<p>You have already computed <strong>entropy</strong> and <strong>information gain</strong>.</p>
<hr>
</section>
<section id="c3.-training-a-simple-classification-tree" class="level2">
<h2 class="anchored" data-anchor-id="c3.-training-a-simple-classification-tree">C3. Training a Simple Classification Tree</h2>
<p>We now train a <strong>shallow decision tree</strong> as a baseline model.</p>
<p>The goal is <strong>interpretability</strong>, not performance.</p>
<hr>
<section id="r-training-a-decision-tree" class="level3">
<h3 class="anchored" data-anchor-id="r-training-a-decision-tree">R: Training a Decision Tree</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb19"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb19-1"><a href="#cb19-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart)</span>
<span id="cb19-2"><a href="#cb19-2" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(rpart.plot)</span>
<span id="cb19-3"><a href="#cb19-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-4"><a href="#cb19-4" aria-hidden="true" tabindex="-1"></a>tree_model <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb19-5"><a href="#cb19-5" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb19-6"><a href="#cb19-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> model_data,</span>
<span id="cb19-7"><a href="#cb19-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"class"</span>,</span>
<span id="cb19-8"><a href="#cb19-8" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">maxdepth =</span> <span class="dv">3</span>)</span>
<span id="cb19-9"><a href="#cb19-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb19-10"><a href="#cb19-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb19-11"><a href="#cb19-11" aria-hidden="true" tabindex="-1"></a><span class="fu">rpart.plot</span>(tree_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week3_files/figure-html/unnamed-chunk-11-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-7-contents" aria-controls="callout-7" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-7" class="callout-7-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li><code>rpart()</code> fits a decision tree model.</li>
<li><code>y ~ .</code> means “predict <code>y</code> using all other variables”.</li>
<li><code>method = "class"</code> specifies a classification task.</li>
<li><code>maxdepth = 3</code> limits the depth of the tree.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Limiting depth prevents the tree from growing overly complex.</li>
<li>A shallow tree is easier to interpret and less prone to overfitting.</li>
<li>Depth control is a <strong>modelling decision</strong>, not a technical necessity.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python-training-a-decision-tree" class="level3">
<h3 class="anchored" data-anchor-id="python-training-a-decision-tree">Python: Training a Decision Tree</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb20"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb20-1"><a href="#cb20-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb20-2"><a href="#cb20-2" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> matplotlib.pyplot <span class="im">as</span> plt</span>
<span id="cb20-3"><a href="#cb20-3" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier, plot_tree</span>
<span id="cb20-4"><a href="#cb20-4" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.compose <span class="im">import</span> ColumnTransformer</span>
<span id="cb20-5"><a href="#cb20-5" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.preprocessing <span class="im">import</span> OneHotEncoder</span>
<span id="cb20-6"><a href="#cb20-6" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb20-7"><a href="#cb20-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-8"><a href="#cb20-8" aria-hidden="true" tabindex="-1"></a><span class="co"># Split features / target</span></span>
<span id="cb20-9"><a href="#cb20-9" aria-hidden="true" tabindex="-1"></a>X <span class="op">=</span> model_data.drop(columns<span class="op">=</span>[<span class="st">"y"</span>])</span>
<span id="cb20-10"><a href="#cb20-10" aria-hidden="true" tabindex="-1"></a>y <span class="op">=</span> model_data[<span class="st">"y"</span>]</span>
<span id="cb20-11"><a href="#cb20-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-12"><a href="#cb20-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Identify column types</span></span>
<span id="cb20-13"><a href="#cb20-13" aria-hidden="true" tabindex="-1"></a>cat_cols <span class="op">=</span> X.select_dtypes(include<span class="op">=</span>[<span class="st">"object"</span>, <span class="st">"category"</span>]).columns</span>
<span id="cb20-14"><a href="#cb20-14" aria-hidden="true" tabindex="-1"></a>num_cols <span class="op">=</span> X.select_dtypes(exclude<span class="op">=</span>[<span class="st">"object"</span>, <span class="st">"category"</span>]).columns</span>
<span id="cb20-15"><a href="#cb20-15" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-16"><a href="#cb20-16" aria-hidden="true" tabindex="-1"></a><span class="co"># Preprocessing: encode categoricals, pass through numerics</span></span>
<span id="cb20-17"><a href="#cb20-17" aria-hidden="true" tabindex="-1"></a>preprocess <span class="op">=</span> ColumnTransformer(</span>
<span id="cb20-18"><a href="#cb20-18" aria-hidden="true" tabindex="-1"></a>    transformers<span class="op">=</span>[</span>
<span id="cb20-19"><a href="#cb20-19" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"num"</span>, <span class="st">"passthrough"</span>, num_cols),</span>
<span id="cb20-20"><a href="#cb20-20" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"cat"</span>, OneHotEncoder(handle_unknown<span class="op">=</span><span class="st">"ignore"</span>), cat_cols),</span>
<span id="cb20-21"><a href="#cb20-21" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb20-22"><a href="#cb20-22" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-23"><a href="#cb20-23" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-24"><a href="#cb20-24" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision tree (rpart-style)</span></span>
<span id="cb20-25"><a href="#cb20-25" aria-hidden="true" tabindex="-1"></a>tree_model <span class="op">=</span> Pipeline(</span>
<span id="cb20-26"><a href="#cb20-26" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span>[</span>
<span id="cb20-27"><a href="#cb20-27" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"prep"</span>, preprocess),</span>
<span id="cb20-28"><a href="#cb20-28" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"tree"</span>, DecisionTreeClassifier(</span>
<span id="cb20-29"><a href="#cb20-29" aria-hidden="true" tabindex="-1"></a>            max_depth<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb20-30"><a href="#cb20-30" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb20-31"><a href="#cb20-31" aria-hidden="true" tabindex="-1"></a>        )),</span>
<span id="cb20-32"><a href="#cb20-32" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb20-33"><a href="#cb20-33" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb20-34"><a href="#cb20-34" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb20-35"><a href="#cb20-35" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit model</span></span>
<span id="cb20-36"><a href="#cb20-36" aria-hidden="true" tabindex="-1"></a>tree_model.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;
}

#sk-container-id-1.light {
  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: black;
  --sklearn-color-background: white;
  --sklearn-color-border-box: black;
  --sklearn-color-icon: #696969;
}

#sk-container-id-1.dark {
  --sklearn-color-text-on-default-background: white;
  --sklearn-color-background: #111;
  --sklearn-color-border-box: white;
  --sklearn-color-icon: #878787;
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: center;
  justify-content: center;
  gap: 0.5em;
}

#sk-container-id-1 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-3) 1pt solid;
  color: var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3) 1pt solid;
  color: var(--sklearn-color-fitted-level-3);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-unfitted-level-0);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-fitted-level-0);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table {
    font-family: monospace;
}

.estimator-table summary {
    padding: .5rem;
    cursor: pointer;
}

.estimator-table summary::marker {
    font-size: 0.7rem;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
    margin-top: 0;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

/*
    `table td`is set in notebook with right text-align.
    We need to overwrite it.
*/
.estimator-table table td.param {
    text-align: left;
    position: relative;
    padding: 0;
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left !important;
}

.user-set td.value {
    color:rgb(255, 94, 0);
    background-color: transparent;
}

.default td {
    color: black;
    text-align: left !important;
}

.user-set td i,
.default td i {
    color: black;
}

/*
    Styles for parameter documentation links
    We need styling for visited so jupyter doesn't overwrite it
*/
a.param-doc-link,
a.param-doc-link:link,
a.param-doc-link:visited {
    text-decoration: underline dashed;
    text-underline-offset: .3em;
    color: inherit;
    display: block;
    padding: .5em;
}

/* "hack" to make the entire area of the cell containing the link clickable */
a.param-doc-link::before {
    position: absolute;
    content: "";
    inset: 0;
}

.param-doc-description {
    display: none;
    position: absolute;
    z-index: 9999;
    left: 0;
    padding: .5ex;
    margin-left: 1.5em;
    color: var(--sklearn-color-text);
    box-shadow: .3em .3em .4em #999;
    width: max-content;
    text-align: left;
    max-height: 10em;
    overflow-y: auto;

    /* unfitted */
    background: var(--sklearn-color-unfitted-level-0);
    border: thin solid var(--sklearn-color-unfitted-level-3);
}

/* Fitted state for parameter tooltips */
.fitted .param-doc-description {
    /* fitted */
    background: var(--sklearn-color-fitted-level-0);
    border: thin solid var(--sklearn-color-fitted-level-3);
}

.param-doc-link:hover .param-doc-description {
    display: block;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('prep',
                 ColumnTransformer(transformers=[('num', 'passthrough',
                                                  Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')),
                                                 ('cat',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object'))])),
                ('tree', DecisionTreeClassifier(max_depth=3, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox"><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>Pipeline</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">steps <span class="param-doc-description">steps: list of tuples<br>
<br>
List of (name of step, estimator) tuples that are to be chained in<br>
sequential order. To be compatible with the scikit-learn API, all steps<br>
must define `fit`. All non-last steps must also define `transform`. See<br>
:ref:`Combining Estimators <combining_estimators>` for more details.</combining_estimators></span></a></td>
<td class="value">[('prep', ...), ('tree', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transform_input <span class="param-doc-description">transform_input: list of str, default=None<br>
<br>
The names of the :term:`metadata` parameters that should be transformed by the<br>
pipeline before passing it to the step consuming it.<br>
<br>
This enables transforming some input arguments to ``fit`` (other than ``X``)<br>
to be transformed by the steps of the pipeline up to the step which requires<br>
them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>
For instance, this can be used to pass a validation set through the pipeline.<br>
<br>
You can only set this if metadata routing is enabled, which you<br>
can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br>
<br>
.. versionadded:: 1.6</metadata_routing></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">memory <span class="param-doc-description">memory: str or object with the joblib.Memory interface, default=None<br>
<br>
Used to cache the fitted transformers of the pipeline. The last step<br>
will never be cached, even if it is a transformer. By default, no<br>
caching is performed. If a string is given, it is the path to the<br>
caching directory. Enabling caching triggers a clone of the transformers<br>
before fitting. Therefore, the transformer instance given to the<br>
pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>
or ``steps`` to inspect estimators within the pipeline. Caching the<br>
transformers is advantageous when fitting is time consuming. See<br>
:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>
for an example on how to enable caching.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each step will be printed as it<br>
is completed.</span></a></td>
<td class="value">False</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox"><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>prep: ColumnTransformer</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html">?<span>Documentation for prep: ColumnTransformer</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformers,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">transformers <span class="param-doc-description">transformers: list of tuples<br>
<br>
List of (name, transformer, columns) tuples specifying the<br>
transformer objects to be applied to subsets of the data.<br>
<br>
name : str<br>
Like in Pipeline and FeatureUnion, this allows the transformer and<br>
its parameters to be set using ``set_params`` and searched in grid<br>
search.<br>
transformer : {'drop', 'passthrough'} or estimator<br>
Estimator must support :term:`fit` and :term:`transform`.<br>
Special-cased strings 'drop' and 'passthrough' are accepted as<br>
well, to indicate to drop the columns or to pass them through<br>
untransformed, respectively.<br>
columns : str, array-like of str, int, array-like of int, array-like of bool, slice or callable<br>
Indexes the data on its second axis. Integers are interpreted as<br>
positional columns, while strings can reference DataFrame columns<br>
by name. A scalar string or int should be used where<br>
``transformer`` expects X to be a 1d array-like (vector),<br>
otherwise a 2d array will be passed to the transformer.<br>
A callable is passed the input data `X` and can return any of the<br>
above. To select multiple columns by name or dtype, you can use<br>
:obj:`make_column_selector`.</span></a></td>
<td class="value">[('num', ...), ('cat', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=remainder,-%7B%27drop%27%2C%20%27passthrough%27%7D%20or%20estimator%2C%20default%3D%27drop%27" class="param-doc-link" rel="noreferrer" target="_blank">remainder <span class="param-doc-description">remainder: {'drop', 'passthrough'} or estimator, default='drop'<br>
<br>
By default, only the specified columns in `transformers` are<br>
transformed and combined in the output, and the non-specified<br>
columns are dropped. (default of ``'drop'``).<br>
By specifying ``remainder='passthrough'``, all remaining columns that<br>
were not specified in `transformers`, but present in the data passed<br>
to `fit` will be automatically passed through. This subset of columns<br>
is concatenated with the output of the transformers. For dataframes,<br>
extra columns not seen during `fit` will be excluded from the output<br>
of `transform`.<br>
By setting ``remainder`` to be an estimator, the remaining<br>
non-specified columns will use the ``remainder`` estimator. The<br>
estimator must support :term:`fit` and :term:`transform`.<br>
Note that using this feature requires that the DataFrame columns<br>
input at :term:`fit` and :term:`transform` have identical order.</span></a></td>
<td class="value">'drop'</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=sparse_threshold,-float%2C%20default%3D0.3" class="param-doc-link" rel="noreferrer" target="_blank">sparse_threshold <span class="param-doc-description">sparse_threshold: float, default=0.3<br>
<br>
If the output of the different transformers contains sparse matrices,<br>
these will be stacked as a sparse matrix if the overall density is<br>
lower than this value. Use ``sparse_threshold=0`` to always return<br>
dense. When the transformed output consists of all dense data, the<br>
stacked result will be dense, and this keyword will be ignored.</span></a></td>
<td class="value">0.3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=n_jobs,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">n_jobs <span class="param-doc-description">n_jobs: int, default=None<br>
<br>
Number of jobs to run in parallel.<br>
``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>
``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>
for more details.</n_jobs></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformer_weights,-dict%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transformer_weights <span class="param-doc-description">transformer_weights: dict, default=None<br>
<br>
Multiplicative weights for features per transformer. The output of the<br>
transformer is multiplied by these weights. Keys are transformer names,<br>
values the weights.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each transformer will be<br>
printed as it is completed.</span></a></td>
<td class="value">False</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose_feature_names_out,-bool%2C%20str%20or%20Callable%5B%5Bstr%2C%20str%5D%2C%20str%5D%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">verbose_feature_names_out <span class="param-doc-description">verbose_feature_names_out: bool, str or Callable[[str, str], str], default=True<br>
<br>
- If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix<br>
all feature names with the name of the transformer that generated that<br>
feature. It is equivalent to setting<br>
`verbose_feature_names_out="{transformer_name}__{feature_name}"`.<br>
- If False, :meth:`ColumnTransformer.get_feature_names_out` will not<br>
prefix any feature names and will error if feature names are not<br>
unique.<br>
- If ``Callable[[str, str], str]``,<br>
:meth:`ColumnTransformer.get_feature_names_out` will rename all the features<br>
using the name of the transformer. The first argument of the callable is the<br>
transformer name and the second argument is the feature name. The returned<br>
string will be the new feature name.<br>
- If ``str``, it must be a string ready for formatting. The given string will<br>
be formatted using two field names: ``transformer_name`` and ``feature_name``.<br>
e.g. ``"{feature_name}__{transformer_name}"``. See :meth:`str.format` method<br>
from the standard library for more info.<br>
<br>
.. versionadded:: 1.0<br>
<br>
.. versionchanged:: 1.6<br>
`verbose_feature_names_out` can be a callable or a string to be formatted.</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=force_int_remainder_cols,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">force_int_remainder_cols <span class="param-doc-description">force_int_remainder_cols: bool, default=False<br>
<br>
This parameter has no effect.<br>
<br>
.. note::<br>
If you do not access the list of columns for the remainder columns<br>
in the `transformers_` fitted attribute, you do not need to set<br>
this parameter.<br>
<br>
.. versionadded:: 1.5<br>
<br>
.. versionchanged:: 1.7<br>
The default value for `force_int_remainder_cols` will change from<br>
`True` to `False` in version 1.7.<br>
<br>
.. deprecated:: 1.7<br>
`force_int_remainder_cols` is deprecated and will be removed in 1.9.</span></a></td>
<td class="value">'deprecated'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-3" type="checkbox"><label for="sk-estimator-id-3" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>num</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-4" type="checkbox"><label for="sk-estimator-id-4" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>passthrough</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>passthrough</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-5" type="checkbox"><label for="sk-estimator-id-5" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>cat</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__"><pre>Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-6" type="checkbox"><label for="sk-estimator-id-6" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>OneHotEncoder</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html">?<span>Documentation for OneHotEncoder</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=categories,-%27auto%27%20or%20a%20list%20of%20array-like%2C%20default%3D%27auto%27" class="param-doc-link" rel="noreferrer" target="_blank">categories <span class="param-doc-description">categories: 'auto' or a list of array-like, default='auto'<br>
<br>
Categories (unique values) per feature:<br>
<br>
- 'auto' : Determine categories automatically from the training data.<br>
- list : ``categories[i]`` holds the categories expected in the ith<br>
column. The passed categories should not mix strings and numeric<br>
values within a single feature, and should be sorted in case of<br>
numeric values.<br>
<br>
The used categories can be found in the ``categories_`` attribute.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">'auto'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=drop,-%7B%27first%27%2C%20%27if_binary%27%7D%20or%20an%20array-like%20of%20shape%20%28n_features%2C%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">drop <span class="param-doc-description">drop: {'first', 'if_binary'} or an array-like of shape (n_features,), default=None<br>
<br>
Specifies a methodology to use to drop one of the categories per<br>
feature. This is useful in situations where perfectly collinear<br>
features cause problems, such as when feeding the resulting data<br>
into an unregularized linear regression model.<br>
<br>
However, dropping one category breaks the symmetry of the original<br>
representation and can therefore induce a bias in downstream models,<br>
for instance for penalized linear classification or regression models.<br>
<br>
- None : retain all features (the default).<br>
- 'first' : drop the first category in each feature. If only one<br>
category is present, the feature will be dropped entirely.<br>
- 'if_binary' : drop the first category in each feature with two<br>
categories. Features with 1 or more than 2 categories are<br>
left intact.<br>
- array : ``drop[i]`` is the category in feature ``X[:, i]`` that<br>
should be dropped.<br>
<br>
When `max_categories` or `min_frequency` is configured to group<br>
infrequent categories, the dropping behavior is handled after the<br>
grouping.<br>
<br>
.. versionadded:: 0.21<br>
The parameter `drop` was added in 0.21.<br>
<br>
.. versionchanged:: 0.23<br>
The option `drop='if_binary'` was added in 0.23.<br>
<br>
.. versionchanged:: 1.1<br>
Support for dropping infrequent categories.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=sparse_output,-bool%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">sparse_output <span class="param-doc-description">sparse_output: bool, default=True<br>
<br>
When ``True``, it returns a :class:`scipy.sparse.csr_matrix`,<br>
i.e. a sparse matrix in "Compressed Sparse Row" (CSR) format.<br>
<br>
.. versionadded:: 1.2<br>
`sparse` was renamed to `sparse_output`</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=dtype,-number%20type%2C%20default%3Dnp.float64" class="param-doc-link" rel="noreferrer" target="_blank">dtype <span class="param-doc-description">dtype: number type, default=np.float64<br>
<br>
Desired dtype of output.</span></a></td>
<td class="value">&lt;class 'numpy.float64'&gt;</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=handle_unknown,-%7B%27error%27%2C%20%27ignore%27%2C%20%27infrequent_if_exist%27%2C%20%27warn%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27error%27" class="param-doc-link" rel="noreferrer" target="_blank">handle_unknown <span class="param-doc-description">handle_unknown: {'error', 'ignore', 'infrequent_if_exist', 'warn'}, default='error'<br>
<br>
Specifies the way unknown categories are handled during :meth:`transform`.<br>
<br>
- 'error' : Raise an error if an unknown category is present during transform.<br>
- 'ignore' : When an unknown category is encountered during<br>
transform, the resulting one-hot encoded columns for this feature<br>
will be all zeros. In the inverse transform, an unknown category<br>
will be denoted as None.<br>
- 'infrequent_if_exist' : When an unknown category is encountered<br>
during transform, the resulting one-hot encoded columns for this<br>
feature will map to the infrequent category if it exists. The<br>
infrequent category will be mapped to the last position in the<br>
encoding. During inverse transform, an unknown category will be<br>
mapped to the category denoted `'infrequent'` if it exists. If the<br>
`'infrequent'` category does not exist, then :meth:`transform` and<br>
:meth:`inverse_transform` will handle an unknown category as with<br>
`handle_unknown='ignore'`. Infrequent categories exist based on<br>
`min_frequency` and `max_categories`. Read more in the<br>
:ref:`User Guide <encoder_infrequent_categories>`.<br>
- 'warn' : When an unknown category is encountered during transform<br>
a warning is issued, and the encoding then proceeds as described for<br>
`handle_unknown="infrequent_if_exist"`.<br>
<br>
.. versionchanged:: 1.1<br>
`'infrequent_if_exist'` was added to automatically handle unknown<br>
categories and infrequent categories.<br>
<br>
.. versionadded:: 1.6<br>
The option `"warn"` was added in 1.6.</encoder_infrequent_categories></span></a></td>
<td class="value">'ignore'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=min_frequency,-int%20or%20float%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">min_frequency <span class="param-doc-description">min_frequency: int or float, default=None<br>
<br>
Specifies the minimum frequency below which a category will be<br>
considered infrequent.<br>
<br>
- If `int`, categories with a smaller cardinality will be considered<br>
infrequent.<br>
<br>
- If `float`, categories with a smaller cardinality than<br>
`min_frequency * n_samples` will be considered infrequent.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=max_categories,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_categories <span class="param-doc-description">max_categories: int, default=None<br>
<br>
Specifies an upper limit to the number of output features for each input<br>
feature when considering infrequent categories. If there are infrequent<br>
categories, `max_categories` includes the category representing the<br>
infrequent categories along with the frequent categories. If `None`,<br>
there is no limit to the number of output features.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=feature_name_combiner,-%22concat%22%20or%20callable%2C%20default%3D%22concat%22" class="param-doc-link" rel="noreferrer" target="_blank">feature_name_combiner <span class="param-doc-description">feature_name_combiner: "concat" or callable, default="concat"<br>
<br>
Callable with signature `def callable(input_feature, category)` that returns a<br>
string. This is used to create feature names to be returned by<br>
:meth:`get_feature_names_out`.<br>
<br>
`"concat"` concatenates encoded feature name and category with<br>
`feature + "_" + str(category)`.E.g. feature X with values 1, 6, 7 create<br>
feature names `X_1, X_6, X_7`.<br>
<br>
.. versionadded:: 1.3</span></a></td>
<td class="value">'concat'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-7" type="checkbox"><label for="sk-estimator-id-7" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeClassifier</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="tree__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22" class="param-doc-link" rel="noreferrer" target="_blank">criterion <span class="param-doc-description">criterion: {"gini", "entropy", "log_loss"}, default="gini"<br>
<br>
The function to measure the quality of a split. Supported criteria are<br>
"gini" for the Gini impurity and "log_loss" and "entropy" both for the<br>
Shannon information gain, see :ref:`tree_mathematical_formulation`.</span></a></td>
<td class="value">'gini'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22" class="param-doc-link" rel="noreferrer" target="_blank">splitter <span class="param-doc-description">splitter: {"best", "random"}, default="best"<br>
<br>
The strategy used to choose the split at each node. Supported<br>
strategies are "best" to choose the best split and "random" to choose<br>
the best random split.</span></a></td>
<td class="value">'best'</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_depth <span class="param-doc-description">max_depth: int, default=None<br>
<br>
The maximum depth of the tree. If None, then nodes are expanded until<br>
all leaves are pure or until all leaves contain less than<br>
min_samples_split samples.</span></a></td>
<td class="value">3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_split <span class="param-doc-description">min_samples_split: int or float, default=2<br>
<br>
The minimum number of samples required to split an internal node:<br>
<br>
- If int, then consider `min_samples_split` as the minimum number.<br>
- If float, then `min_samples_split` is a fraction and<br>
`ceil(min_samples_split * n_samples)` are the minimum<br>
number of samples for each split.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">2</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_leaf <span class="param-doc-description">min_samples_leaf: int or float, default=1<br>
<br>
The minimum number of samples required to be at a leaf node.<br>
A split point at any depth will only be considered if it leaves at<br>
least ``min_samples_leaf`` training samples in each of the left and<br>
right branches. This may have the effect of smoothing the model,<br>
especially in regression.<br>
<br>
- If int, then consider `min_samples_leaf` as the minimum number.<br>
- If float, then `min_samples_leaf` is a fraction and<br>
`ceil(min_samples_leaf * n_samples)` are the minimum<br>
number of samples for each node.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">1</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_weight_fraction_leaf <span class="param-doc-description">min_weight_fraction_leaf: float, default=0.0<br>
<br>
The minimum weighted fraction of the sum total of weights (of all<br>
the input samples) required to be at a leaf node. Samples have<br>
equal weight when sample_weight is not provided.</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_features <span class="param-doc-description">max_features: int, float or {"sqrt", "log2"}, default=None<br>
<br>
The number of features to consider when looking for the best split:<br>
<br>
- If int, then consider `max_features` features at each split.<br>
- If float, then `max_features` is a fraction and<br>
`max(1, int(max_features * n_features_in_))` features are considered at<br>
each split.<br>
- If "sqrt", then `max_features=sqrt(n_features)`.<br>
- If "log2", then `max_features=log2(n_features)`.<br>
- If None, then `max_features=n_features`.<br>
<br>
.. note::<br>
<br>
The search for a split does not stop until at least one<br>
valid partition of the node samples is found, even if it requires to<br>
effectively inspect more than ``max_features`` features.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="user-set even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">random_state <span class="param-doc-description">random_state: int, RandomState instance or None, default=None<br>
<br>
Controls the randomness of the estimator. The features are always<br>
randomly permuted at each split, even if ``splitter`` is set to<br>
``"best"``. When ``max_features &lt; n_features``, the algorithm will<br>
select ``max_features`` at random at each split before finding the best<br>
split among them. But the best found split may vary across different<br>
runs, even if ``max_features=n_features``. That is the case, if the<br>
improvement of the criterion is identical for several splits and one<br>
split has to be selected at random. To obtain a deterministic behaviour<br>
during fitting, ``random_state`` has to be fixed to an integer.<br>
See :term:`Glossary <random_state>` for details.</random_state></span></a></td>
<td class="value">42</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_leaf_nodes <span class="param-doc-description">max_leaf_nodes: int, default=None<br>
<br>
Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>
Best nodes are defined as relative reduction in impurity.<br>
If None then unlimited number of leaf nodes.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_impurity_decrease <span class="param-doc-description">min_impurity_decrease: float, default=0.0<br>
<br>
A node will be split if this split induces a decrease of the impurity<br>
greater than or equal to this value.<br>
<br>
The weighted impurity decrease equation is the following::<br>
<br>
N_t / N * (impurity - N_t_R / N_t * right_impurity<br>
- N_t_L / N_t * left_impurity)<br>
<br>
where ``N`` is the total number of samples, ``N_t`` is the number of<br>
samples at the current node, ``N_t_L`` is the number of samples in the<br>
left child, and ``N_t_R`` is the number of samples in the right child.<br>
<br>
``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>
if ``sample_weight`` is passed.<br>
<br>
.. versionadded:: 0.19</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">class_weight <span class="param-doc-description">class_weight: dict, list of dict or "balanced", default=None<br>
<br>
Weights associated with classes in the form ``{class_label: weight}``.<br>
If None, all classes are supposed to have weight one. For<br>
multi-output problems, a list of dicts can be provided in the same<br>
order as the columns of y.<br>
<br>
Note that for multioutput (including multilabel) weights should be<br>
defined for each class of every column in its own dict. For example,<br>
for four-class multilabel classification weights should be<br>
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>
[{1:1}, {2:5}, {3:1}, {4:1}].<br>
<br>
The "balanced" mode uses the values of y to automatically adjust<br>
weights inversely proportional to class frequencies in the input data<br>
as ``n_samples / (n_classes * np.bincount(y))``<br>
<br>
For multi-output, the weights of each column of y will be multiplied.<br>
<br>
Note that these weights will be multiplied with sample_weight (passed<br>
through the fit method) if sample_weight is specified.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">ccp_alpha <span class="param-doc-description">ccp_alpha: non-negative float, default=0.0<br>
<br>
Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>
subtree with the largest cost complexity that is smaller than<br>
``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>
:ref:`minimal_cost_complexity_pruning` for details. See<br>
:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>
for an example of such pruning.<br>
<br>
.. versionadded:: 0.22</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">monotonic_cst <span class="param-doc-description">monotonic_cst: array-like of int of shape (n_features), default=None<br>
<br>
Indicates the monotonicity constraint to enforce on each feature.<br>
- 1: monotonic increase<br>
- 0: no constraint<br>
- -1: monotonic decrease<br>
<br>
If monotonic_cst is None, no constraints are applied.<br>
<br>
Monotonicity constraints are not supported for:<br>
- multiclass classifications (i.e. when `n_classes &gt; 2`),<br>
- multioutput classifications (i.e. when `n_outputs_ &gt; 1`),<br>
- classifications trained on data with missing values.<br>
<br>
The constraints hold over the probability of the positive class.<br>
<br>
Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br>
<br>
.. versionadded:: 1.4</monotonic_cst_gbdt></span></a></td>
<td class="value">None</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.copy-paste-icon').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling
        .textContent.trim().split(' ')[0];
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});


/**
 * Adapted from Skrub
 * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789
 * @returns "light" or "dark"
 */
function detectTheme(element) {
    const body = document.querySelector('body');

    // Check VSCode theme
    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');
    const themeNameAttr = body.getAttribute('data-vscode-theme-name');

    if (themeKindAttr && themeNameAttr) {
        const themeKind = themeKindAttr.toLowerCase();
        const themeName = themeNameAttr.toLowerCase();

        if (themeKind.includes("dark") || themeName.includes("dark")) {
            return "dark";
        }
        if (themeKind.includes("light") || themeName.includes("light")) {
            return "light";
        }
    }

    // Check Jupyter theme
    if (body.getAttribute('data-jp-theme-light') === 'false') {
        return 'dark';
    } else if (body.getAttribute('data-jp-theme-light') === 'true') {
        return 'light';
    }

    // Guess based on a parent element's color
    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');
    const match = color.match(/^rgb\s*\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)\s*$/i);
    if (match) {
        const [r, g, b] = [
            parseFloat(match[1]),
            parseFloat(match[2]),
            parseFloat(match[3])
        ];

        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness
        const luma = 0.299 * r + 0.587 * g + 0.114 * b;

        if (luma > 180) {
            // If the text is very bright we have a dark theme
            return 'dark';
        }
        if (luma < 75) {
            // If the text is very dark we have a light theme
            return 'light';
        }
        // Otherwise fall back to the next heuristic.
    }

    // Fallback to system preference
    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
}


function forceTheme(elementId) {
    const estimatorElement = document.querySelector(`#${elementId}`);
    if (estimatorElement === null) {
        console.error(`Element with id ${elementId} not found.`);
    } else {
        const theme = detectTheme(estimatorElement);
        estimatorElement.classList.add(theme);
    }
}

forceTheme('sk-container-id-1');</script>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-8-contents" aria-controls="callout-8" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing — and why it looks more complex than the R version
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-8" class="callout-8-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>This Python code trains the <strong>same type of decision tree</strong> as the R version,<br>
but it makes <strong>data representation steps explicit</strong> rather than implicit.</p>
<hr>
<section id="step-1-separating-inputs-and-output" class="level3">
<h3 class="anchored" data-anchor-id="step-1-separating-inputs-and-output">Step 1: Separating inputs and output</h3>
<ul>
<li><code>X</code> contains all input features.</li>
<li><code>y</code> is the target variable. This mirrors the supervised learning setup discussed earlier (inputs → output).</li>
</ul>
<hr>
</section>
<section id="step-2-identifying-column-types" class="level3">
<h3 class="anchored" data-anchor-id="step-2-identifying-column-types">Step 2: Identifying column types</h3>
<ul>
<li>Categorical columns are identified by their data type (<code>object</code> or <code>category</code>).</li>
<li>Numeric columns are identified by exclusion.</li>
</ul>
<p>In R, this distinction is handled automatically inside <code>rpart()</code>.<br>
In Python, we must state it explicitly.</p>
<hr>
</section>
<section id="step-3-preprocessing-representation-decisions" class="level3">
<h3 class="anchored" data-anchor-id="step-3-preprocessing-representation-decisions">Step 3: Preprocessing (representation decisions)</h3>
<ul>
<li>Numeric variables are passed through unchanged.</li>
<li>Categorical variables are one-hot encoded.</li>
<li><code>handle_unknown="ignore"</code> ensures the model does not fail if unseen categories appear later.</li>
</ul>
<p>This step defines <strong>how the data is represented</strong> before the model sees it.</p>
<blockquote class="blockquote">
<p>This directly connects to Week 1:<br>
<strong>representation is a modelling decision, not a technical detail</strong>.</p>
</blockquote>
<hr>
</section>
<section id="step-4-pipeline-construction" class="level3">
<h3 class="anchored" data-anchor-id="step-4-pipeline-construction">Step 4: Pipeline construction</h3>
<ul>
<li>The pipeline links preprocessing and the decision tree into a single workflow.</li>
<li>Preprocessing always happens before model training.</li>
<li>This prevents inconsistencies and improves reproducibility.</li>
</ul>
<p>Nothing “extra” is being learned here — the steps are simply made visible.</p>
<hr>
</section>
<section id="step-5-decision-tree-model" class="level3">
<h3 class="anchored" data-anchor-id="step-5-decision-tree-model">Step 5: Decision tree model</h3>
<ul>
<li><code>max_depth=3</code> limits tree complexity for interpretability.</li>
<li><code>random_state=42</code> ensures reproducible results.</li>
</ul>
<p>These assumptions are <strong>identical</strong> to the R version.</p>
<hr>
</section>
<section id="why-the-python-version-looks-heavier-than-the-r-version" class="level3">
<h3 class="anchored" data-anchor-id="why-the-python-version-looks-heavier-than-the-r-version">Why the Python version looks heavier than the R version</h3>
<p>In R, functions like <code>rpart()</code>: - automatically recognise categorical variables, - decide how to split them internally, - hide most representation choices from the user.</p>
<p>In Python, scikit-learn follows a different philosophy:</p>
<blockquote class="blockquote">
<p><strong>Models only operate on numeric data.<br>
All representation decisions must be made explicitly.</strong></p>
</blockquote>
<p>This makes the Python code longer —<br>
but it also makes modelling assumptions <strong>visible, inspectable, and reproducible</strong>.</p>
<hr>
</section>
<section id="key-takeaway" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaway">Key takeaway</h3>
<p>The Python code is not more complicated <em>conceptually</em> than the R code.</p>
<p>It simply exposes decisions that R handles behind the scenes.</p>
<p>Both approaches are valid — they just make different design choices.</p>
</section>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-9-contents" aria-controls="callout-9" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Understanding <code>max_depth</code> in decision trees
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-9" class="callout-9-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>What does <code>max_depth</code> mean (conceptually)?</strong><br>
<code>max_depth</code> controls how many decision levels a tree is allowed to grow from the root to a leaf.</p>
<ul>
<li>A depth of <strong>1</strong> means a single split (a decision stump).</li>
<li>A depth of <strong>3</strong> means up to three sequential decisions.</li>
<li>Larger depths allow more complex rules.</li>
</ul>
<p>Each additional level: - increases model flexibility, - increases the risk of overfitting, - increases computational cost.</p>
<hr>
<section id="typical-behaviour-at-different-depths" class="level3">
<h3 class="anchored" data-anchor-id="typical-behaviour-at-different-depths">Typical behaviour at different depths</h3>
<p><strong>Very shallow trees (depth 1–2)</strong><br>
- Learn only coarse patterns<br>
- Often <em>underfit</em> the data<br>
- Easy to interpret<br>
- Useful as teaching or baseline models</p>
<p><strong>Moderate depth trees (depth 3–5)</strong><br>
- Capture meaningful interactions<br>
- Balance bias and variance reasonably<br>
- Still interpretable<br>
- Common starting point in practice</p>
<p><strong>Deep trees (depth &gt; 6–10)</strong><br>
- Can memorise training data<br>
- High risk of overfitting<br>
- Hard to interpret<br>
- Often unstable to small data changes</p>
<p><strong>Unrestricted depth</strong><br>
- Tree grows until stopping rules are met<br>
- Often impractical for interpretation<br>
- Can be computationally expensive<br>
- Rarely justified without strong validation</p>
<hr>
</section>
<section id="why-we-limit-depth-in-this-notebook" class="level3">
<h3 class="anchored" data-anchor-id="why-we-limit-depth-in-this-notebook">Why we limit depth in this notebook</h3>
<p>In this notebook: - our goal is <strong>understanding</strong>, not optimisation, - we want to <em>see</em> and <em>reason about</em> decision rules, - shallow trees make assumptions visible.</p>
<p>A deeper tree may score better on training data,<br>
but it tells us <strong>less</strong> about what the model has learned.</p>
<hr>
</section>
<section id="max_depth-in-different-libraries" class="level3">
<h3 class="anchored" data-anchor-id="max_depth-in-different-libraries"><code>max_depth</code> in different libraries</h3>
<p><strong>In scikit-learn (Python)</strong><br>
- <code>max_depth=None</code> means <em>no explicit limit</em><br>
- The tree grows until other stopping conditions apply<br>
- Explicitly setting <code>max_depth</code> is strongly recommended</p>
<p><strong>In rpart (R)</strong><br>
- Depth is controlled via <code>rpart.control(maxdepth = ...)</code><br>
- rpart also applies additional complexity penalties<br>
- Even so, depth limits improve clarity and stability</p>
<hr>
</section>
<section id="key-takeaway-1" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaway-1">Key takeaway</h3>
<blockquote class="blockquote">
<p>Increasing tree depth always increases complexity —<br>
but it does <em>not</em> always increase understanding or validity.</p>
</blockquote>
<p>Choosing <code>max_depth</code> is a <strong>modelling decision</strong>,<br>
not a technical requirement.</p>
</section>
</div>
</div>
</div>
<hr>
<div class="cell">
<div class="sourceCode cell-code" id="cb21"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb21-1"><a href="#cb21-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Visualise the trained decision tree</span></span>
<span id="cb21-2"><a href="#cb21-2" aria-hidden="true" tabindex="-1"></a>plt.figure(figsize<span class="op">=</span>(<span class="dv">20</span>, <span class="dv">8</span>))</span>
<span id="cb21-3"><a href="#cb21-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-4"><a href="#cb21-4" aria-hidden="true" tabindex="-1"></a>plot_tree(</span>
<span id="cb21-5"><a href="#cb21-5" aria-hidden="true" tabindex="-1"></a>    tree_model.named_steps[<span class="st">"tree"</span>],</span>
<span id="cb21-6"><a href="#cb21-6" aria-hidden="true" tabindex="-1"></a>    feature_names<span class="op">=</span>tree_model.named_steps[<span class="st">"prep"</span>].get_feature_names_out(),</span>
<span id="cb21-7"><a href="#cb21-7" aria-hidden="true" tabindex="-1"></a>    class_names<span class="op">=</span>tree_model.named_steps[<span class="st">"tree"</span>].classes_,</span>
<span id="cb21-8"><a href="#cb21-8" aria-hidden="true" tabindex="-1"></a>    filled<span class="op">=</span><span class="va">True</span></span>
<span id="cb21-9"><a href="#cb21-9" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb21-10"><a href="#cb21-10" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb21-11"><a href="#cb21-11" aria-hidden="true" tabindex="-1"></a>plt.show()</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week3_files/figure-html/unnamed-chunk-13-1.png" class="img-fluid figure-img" width="1920"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why does the tree show <em>Gini</em> instead of <em>Entropy</em>?
</div>
</div>
<div class="callout-body-container callout-body">
<p>You might be surprised to see <strong>Gini impurity</strong>, since we studied <strong>entropy and information gain</strong>.</p>
<p>There’s no contradiction.</p>
<p>Both <strong>entropy</strong> and <strong>Gini</strong> measure the same idea:<br>
<strong>how mixed the classes are in a node</strong>, and how much a split reduces that impurity.</p>
<p>For <strong>binary classification</strong> (class proportions (p) and (1-p)):</p>
<ul>
<li><p><strong>Entropy</strong> <span class="math display">\[
H = -p \log_2 p - (1-p)\log_2(1-p)
\]</span></p></li>
<li><p><strong>Gini impurity</strong> <span class="math display">\[
G = 2p(1-p)
\]</span></p></li>
</ul>
<p>Both are:</p>
<ul>
<li><strong>0</strong> for a pure node ((p=0) or (p=1))</li>
<li><strong>maximal</strong> when the classes are evenly mixed ((p=0.5))</li>
<li>used to choose splits that <em>reduce impurity</em></li>
</ul>
<p>Entropy comes from <strong>information theory</strong> and is great for understanding <em>why</em> trees work.<br>
Gini is a <strong>simpler and faster measure</strong>, commonly used in practice (including sklearn).</p>
<p>In most cases, they lead to <strong>very similar trees</strong>.</p>
<p>So:</p>
<ul>
<li>what you learned (entropy &amp; information gain) is <strong>conceptually fundamental</strong></li>
<li>what you see (Gini) is a <strong>practical default</strong></li>
</ul>
<p>Same idea, slightly different math.</p>
</div>
</div>
</section>
</section>
<section id="c4.-reading-a-decision-tree" class="level2">
<h2 class="anchored" data-anchor-id="c4.-reading-a-decision-tree">C4. Reading a Decision Tree</h2>
<p>When interpreting a decision tree:</p>
<ul>
<li><p>Each internal node shows:</p>
<ul>
<li>a feature,</li>
<li>a split condition,</li>
<li>how many observations reach that node.</li>
</ul></li>
<li><p>Each leaf node shows:</p>
<ul>
<li>a predicted class,</li>
<li>class proportions.</li>
</ul></li>
</ul>
<p>Key questions to ask:</p>
<ul>
<li>Which features appear near the root?</li>
<li>Are the splits intuitive?</li>
<li>Do they align with our domain understanding?</li>
</ul>
<hr>
</section>
<section id="c6.-trees-do-not-require-scaling-and-why" class="level2">
<h2 class="anchored" data-anchor-id="c6.-trees-do-not-require-scaling-and-why">C6. Trees Do Not Require Scaling — and Why</h2>
<p>Unlike distance-based models, decision trees:</p>
<ul>
<li>compare values using <strong>inequality tests</strong>,</li>
<li>do not compute distances,</li>
<li>are unaffected by feature scale.</li>
</ul>
<p>This means:</p>
<ul>
<li>no standardisation is required,</li>
<li>raw numeric values are acceptable.</li>
</ul>
<p>This is one reason trees are popular in practice.</p>
<hr>
</section>
<section id="c7.-instability-of-single-trees" class="level2">
<h2 class="anchored" data-anchor-id="c7.-instability-of-single-trees">C7. Instability of Single Trees</h2>
<p>Despite their interpretability, single decision trees have a major weakness:</p>
<blockquote class="blockquote">
<p><strong>They are highly sensitive to the data.</strong></p>
</blockquote>
<p>Small changes in:</p>
<ul>
<li>the training sample,</li>
<li>rare categories,</li>
<li>noisy variables</li>
</ul>
<p>can lead to <strong>very different trees</strong>.</p>
<p>This instability limits:</p>
<ul>
<li>reliability,</li>
<li>generalisation,</li>
<li>trust in predictions.</li>
</ul>
<p>Recall from Week 1:</p>
<ul>
<li>the dataset contains rare categories,</li>
<li>some variables encode historical outcomes,</li>
<li>the target is imbalanced.</li>
</ul>
<p>All of these factors make <strong>single trees fragile</strong>.</p>
<p>This naturally leads to the next question:</p>
<blockquote class="blockquote">
<p><em>Can we keep the logic of trees, but reduce their instability?</em></p>
</blockquote>
<hr>
<p>Decision trees give us:</p>
<ul>
<li>transparency,</li>
<li>interpretability,</li>
<li>clear decision logic.</li>
</ul>
<p>But they struggle with:</p>
<ul>
<li>variance,</li>
<li>noise,</li>
<li>robustness.</li>
</ul>
<p>In the next part, we address this limitation by introducing <strong>tree ensembles</strong>, which combine many trees into a single, more stable model.</p>
<hr>
</section>
</section>
<section id="part-d-from-one-tree-to-many-tree-ensembles" class="level1">
<h1>Part D — From One Tree to Many: Tree Ensembles</h1>
<hr>
<section id="part-d-why-go-beyond-a-single-tree" class="level2">
<h2 class="anchored" data-anchor-id="part-d-why-go-beyond-a-single-tree">Part D: Why Go Beyond a Single Tree?</h2>
<p>In Part C, we trained a <strong>single decision tree</strong> and observed two things:</p>
<ul>
<li>the tree is easy to understand,</li>
<li>the tree is sensitive to the data.</li>
</ul>
<p>This sensitivity is not a bug — it is a consequence of how trees work. They make <strong>hard, greedy decisions</strong> at each split.</p>
<p>The natural question is:</p>
<blockquote class="blockquote">
<p><em>Can we keep the logic of decision trees, but make the results more stable?</em></p>
</blockquote>
<p>Tree ensembles are the answer.</p>
<hr>
</section>
<section id="d1.-the-idea-behind-ensembles" class="level2">
<h2 class="anchored" data-anchor-id="d1.-the-idea-behind-ensembles">D1. The Idea Behind Ensembles</h2>
<p>An <strong>ensemble</strong> combines the predictions of multiple models.</p>
<p>The underlying principle is simple:</p>
<blockquote class="blockquote">
<p><strong>Many imperfect models can produce a better result than one fragile model.</strong></p>
</blockquote>
<p>Tree ensembles do this while:</p>
<ul>
<li>keeping the basic structure of trees,</li>
<li>reducing sensitivity to noise,</li>
<li>improving generalisation.</li>
</ul>
<p>We will examine two major types:</p>
<ol type="1">
<li><strong>Random forests</strong></li>
<li><strong>Boosted trees</strong></li>
</ol>
<hr>
</section>
<section id="d2.-random-forests-stability-through-randomness" class="level2">
<h2 class="anchored" data-anchor-id="d2.-random-forests-stability-through-randomness">D2. Random Forests — Stability Through Randomness</h2>
<section id="conceptual-overview" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-overview">Conceptual Overview</h3>
<p>A <strong>random forest</strong>:</p>
<ul>
<li>trains many decision trees,</li>
<li>each tree sees a slightly different version of the data,</li>
<li>predictions are aggregated (e.g.&nbsp;majority vote).</li>
</ul>
<p>Two sources of randomness are introduced:</p>
<ul>
<li>random sampling of observations,</li>
<li>random selection of features at each split.</li>
</ul>
<p>This randomness:</p>
<ul>
<li>decorrelates trees,</li>
<li>reduces variance,</li>
<li>improves stability.</li>
</ul>
<hr>
</section>
<section id="r-training-a-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="r-training-a-random-forest">R: Training a Random Forest</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb22"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb22-1"><a href="#cb22-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(randomForest)</span>
<span id="cb22-2"><a href="#cb22-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb22-3"><a href="#cb22-3" aria-hidden="true" tabindex="-1"></a>rf_model <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(</span>
<span id="cb22-4"><a href="#cb22-4" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb22-5"><a href="#cb22-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> model_data,</span>
<span id="cb22-6"><a href="#cb22-6" aria-hidden="true" tabindex="-1"></a>  <span class="at">ntree =</span> <span class="dv">200</span>,</span>
<span id="cb22-7"><a href="#cb22-7" aria-hidden="true" tabindex="-1"></a>  <span class="at">importance =</span> <span class="cn">TRUE</span></span>
<span id="cb22-8"><a href="#cb22-8" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-11-contents" aria-controls="callout-11" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-11" class="callout-11-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Trains 200 decision trees (<code>ntree = 200</code>).</li>
<li>Each tree is trained on a random subset of the data.</li>
<li><code>importance = TRUE</code> enables later feature importance analysis.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Increasing the number of trees reduces variance.</li>
<li>Individual trees may be weak, but the ensemble is strong.</li>
<li>Random forests trade interpretability for stability.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python-training-a-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="python-training-a-random-forest">Python: Training a Random Forest</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb23"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb23-1"><a href="#cb23-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> RandomForestClassifier</span>
<span id="cb23-2"><a href="#cb23-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb23-3"><a href="#cb23-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-4"><a href="#cb23-4" aria-hidden="true" tabindex="-1"></a>rf_model <span class="op">=</span> Pipeline(</span>
<span id="cb23-5"><a href="#cb23-5" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span>[</span>
<span id="cb23-6"><a href="#cb23-6" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"prep"</span>, preprocess),   <span class="co"># reuse existing ColumnTransformer</span></span>
<span id="cb23-7"><a href="#cb23-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"rf"</span>, RandomForestClassifier(</span>
<span id="cb23-8"><a href="#cb23-8" aria-hidden="true" tabindex="-1"></a>            n_estimators<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb23-9"><a href="#cb23-9" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb23-10"><a href="#cb23-10" aria-hidden="true" tabindex="-1"></a>        )),</span>
<span id="cb23-11"><a href="#cb23-11" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb23-12"><a href="#cb23-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb23-13"><a href="#cb23-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb23-14"><a href="#cb23-14" aria-hidden="true" tabindex="-1"></a>rf_model.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;
}

#sk-container-id-2.light {
  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: black;
  --sklearn-color-background: white;
  --sklearn-color-border-box: black;
  --sklearn-color-icon: #696969;
}

#sk-container-id-2.dark {
  --sklearn-color-text-on-default-background: white;
  --sklearn-color-background: #111;
  --sklearn-color-border-box: white;
  --sklearn-color-icon: #878787;
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: center;
  justify-content: center;
  gap: 0.5em;
}

#sk-container-id-2 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-3) 1pt solid;
  color: var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3) 1pt solid;
  color: var(--sklearn-color-fitted-level-3);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-unfitted-level-0);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-fitted-level-0);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table {
    font-family: monospace;
}

.estimator-table summary {
    padding: .5rem;
    cursor: pointer;
}

.estimator-table summary::marker {
    font-size: 0.7rem;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
    margin-top: 0;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

/*
    `table td`is set in notebook with right text-align.
    We need to overwrite it.
*/
.estimator-table table td.param {
    text-align: left;
    position: relative;
    padding: 0;
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left !important;
}

.user-set td.value {
    color:rgb(255, 94, 0);
    background-color: transparent;
}

.default td {
    color: black;
    text-align: left !important;
}

.user-set td i,
.default td i {
    color: black;
}

/*
    Styles for parameter documentation links
    We need styling for visited so jupyter doesn't overwrite it
*/
a.param-doc-link,
a.param-doc-link:link,
a.param-doc-link:visited {
    text-decoration: underline dashed;
    text-underline-offset: .3em;
    color: inherit;
    display: block;
    padding: .5em;
}

/* "hack" to make the entire area of the cell containing the link clickable */
a.param-doc-link::before {
    position: absolute;
    content: "";
    inset: 0;
}

.param-doc-description {
    display: none;
    position: absolute;
    z-index: 9999;
    left: 0;
    padding: .5ex;
    margin-left: 1.5em;
    color: var(--sklearn-color-text);
    box-shadow: .3em .3em .4em #999;
    width: max-content;
    text-align: left;
    max-height: 10em;
    overflow-y: auto;

    /* unfitted */
    background: var(--sklearn-color-unfitted-level-0);
    border: thin solid var(--sklearn-color-unfitted-level-3);
}

/* Fitted state for parameter tooltips */
.fitted .param-doc-description {
    /* fitted */
    background: var(--sklearn-color-fitted-level-0);
    border: thin solid var(--sklearn-color-fitted-level-3);
}

.param-doc-link:hover .param-doc-description {
    display: block;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('prep',
                 ColumnTransformer(transformers=[('num', 'passthrough',
                                                  Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')),
                                                 ('cat',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object'))])),
                ('rf',
                 RandomForestClassifier(n_estimators=200, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-8" type="checkbox"><label for="sk-estimator-id-8" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>Pipeline</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">steps <span class="param-doc-description">steps: list of tuples<br>
<br>
List of (name of step, estimator) tuples that are to be chained in<br>
sequential order. To be compatible with the scikit-learn API, all steps<br>
must define `fit`. All non-last steps must also define `transform`. See<br>
:ref:`Combining Estimators <combining_estimators>` for more details.</combining_estimators></span></a></td>
<td class="value">[('prep', ...), ('rf', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transform_input <span class="param-doc-description">transform_input: list of str, default=None<br>
<br>
The names of the :term:`metadata` parameters that should be transformed by the<br>
pipeline before passing it to the step consuming it.<br>
<br>
This enables transforming some input arguments to ``fit`` (other than ``X``)<br>
to be transformed by the steps of the pipeline up to the step which requires<br>
them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>
For instance, this can be used to pass a validation set through the pipeline.<br>
<br>
You can only set this if metadata routing is enabled, which you<br>
can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br>
<br>
.. versionadded:: 1.6</metadata_routing></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">memory <span class="param-doc-description">memory: str or object with the joblib.Memory interface, default=None<br>
<br>
Used to cache the fitted transformers of the pipeline. The last step<br>
will never be cached, even if it is a transformer. By default, no<br>
caching is performed. If a string is given, it is the path to the<br>
caching directory. Enabling caching triggers a clone of the transformers<br>
before fitting. Therefore, the transformer instance given to the<br>
pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>
or ``steps`` to inspect estimators within the pipeline. Caching the<br>
transformers is advantageous when fitting is time consuming. See<br>
:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>
for an example on how to enable caching.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each step will be printed as it<br>
is completed.</span></a></td>
<td class="value">False</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-9" type="checkbox"><label for="sk-estimator-id-9" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>prep: ColumnTransformer</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html">?<span>Documentation for prep: ColumnTransformer</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformers,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">transformers <span class="param-doc-description">transformers: list of tuples<br>
<br>
List of (name, transformer, columns) tuples specifying the<br>
transformer objects to be applied to subsets of the data.<br>
<br>
name : str<br>
Like in Pipeline and FeatureUnion, this allows the transformer and<br>
its parameters to be set using ``set_params`` and searched in grid<br>
search.<br>
transformer : {'drop', 'passthrough'} or estimator<br>
Estimator must support :term:`fit` and :term:`transform`.<br>
Special-cased strings 'drop' and 'passthrough' are accepted as<br>
well, to indicate to drop the columns or to pass them through<br>
untransformed, respectively.<br>
columns : str, array-like of str, int, array-like of int, array-like of bool, slice or callable<br>
Indexes the data on its second axis. Integers are interpreted as<br>
positional columns, while strings can reference DataFrame columns<br>
by name. A scalar string or int should be used where<br>
``transformer`` expects X to be a 1d array-like (vector),<br>
otherwise a 2d array will be passed to the transformer.<br>
A callable is passed the input data `X` and can return any of the<br>
above. To select multiple columns by name or dtype, you can use<br>
:obj:`make_column_selector`.</span></a></td>
<td class="value">[('num', ...), ('cat', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=remainder,-%7B%27drop%27%2C%20%27passthrough%27%7D%20or%20estimator%2C%20default%3D%27drop%27" class="param-doc-link" rel="noreferrer" target="_blank">remainder <span class="param-doc-description">remainder: {'drop', 'passthrough'} or estimator, default='drop'<br>
<br>
By default, only the specified columns in `transformers` are<br>
transformed and combined in the output, and the non-specified<br>
columns are dropped. (default of ``'drop'``).<br>
By specifying ``remainder='passthrough'``, all remaining columns that<br>
were not specified in `transformers`, but present in the data passed<br>
to `fit` will be automatically passed through. This subset of columns<br>
is concatenated with the output of the transformers. For dataframes,<br>
extra columns not seen during `fit` will be excluded from the output<br>
of `transform`.<br>
By setting ``remainder`` to be an estimator, the remaining<br>
non-specified columns will use the ``remainder`` estimator. The<br>
estimator must support :term:`fit` and :term:`transform`.<br>
Note that using this feature requires that the DataFrame columns<br>
input at :term:`fit` and :term:`transform` have identical order.</span></a></td>
<td class="value">'drop'</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=sparse_threshold,-float%2C%20default%3D0.3" class="param-doc-link" rel="noreferrer" target="_blank">sparse_threshold <span class="param-doc-description">sparse_threshold: float, default=0.3<br>
<br>
If the output of the different transformers contains sparse matrices,<br>
these will be stacked as a sparse matrix if the overall density is<br>
lower than this value. Use ``sparse_threshold=0`` to always return<br>
dense. When the transformed output consists of all dense data, the<br>
stacked result will be dense, and this keyword will be ignored.</span></a></td>
<td class="value">0.3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=n_jobs,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">n_jobs <span class="param-doc-description">n_jobs: int, default=None<br>
<br>
Number of jobs to run in parallel.<br>
``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>
``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>
for more details.</n_jobs></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformer_weights,-dict%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transformer_weights <span class="param-doc-description">transformer_weights: dict, default=None<br>
<br>
Multiplicative weights for features per transformer. The output of the<br>
transformer is multiplied by these weights. Keys are transformer names,<br>
values the weights.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each transformer will be<br>
printed as it is completed.</span></a></td>
<td class="value">False</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose_feature_names_out,-bool%2C%20str%20or%20Callable%5B%5Bstr%2C%20str%5D%2C%20str%5D%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">verbose_feature_names_out <span class="param-doc-description">verbose_feature_names_out: bool, str or Callable[[str, str], str], default=True<br>
<br>
- If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix<br>
all feature names with the name of the transformer that generated that<br>
feature. It is equivalent to setting<br>
`verbose_feature_names_out="{transformer_name}__{feature_name}"`.<br>
- If False, :meth:`ColumnTransformer.get_feature_names_out` will not<br>
prefix any feature names and will error if feature names are not<br>
unique.<br>
- If ``Callable[[str, str], str]``,<br>
:meth:`ColumnTransformer.get_feature_names_out` will rename all the features<br>
using the name of the transformer. The first argument of the callable is the<br>
transformer name and the second argument is the feature name. The returned<br>
string will be the new feature name.<br>
- If ``str``, it must be a string ready for formatting. The given string will<br>
be formatted using two field names: ``transformer_name`` and ``feature_name``.<br>
e.g. ``"{feature_name}__{transformer_name}"``. See :meth:`str.format` method<br>
from the standard library for more info.<br>
<br>
.. versionadded:: 1.0<br>
<br>
.. versionchanged:: 1.6<br>
`verbose_feature_names_out` can be a callable or a string to be formatted.</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=force_int_remainder_cols,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">force_int_remainder_cols <span class="param-doc-description">force_int_remainder_cols: bool, default=False<br>
<br>
This parameter has no effect.<br>
<br>
.. note::<br>
If you do not access the list of columns for the remainder columns<br>
in the `transformers_` fitted attribute, you do not need to set<br>
this parameter.<br>
<br>
.. versionadded:: 1.5<br>
<br>
.. versionchanged:: 1.7<br>
The default value for `force_int_remainder_cols` will change from<br>
`True` to `False` in version 1.7.<br>
<br>
.. deprecated:: 1.7<br>
`force_int_remainder_cols` is deprecated and will be removed in 1.9.</span></a></td>
<td class="value">'deprecated'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-10" type="checkbox"><label for="sk-estimator-id-10" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>num</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-11" type="checkbox"><label for="sk-estimator-id-11" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>passthrough</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>passthrough</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-12" type="checkbox"><label for="sk-estimator-id-12" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>cat</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__"><pre>Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-13" type="checkbox"><label for="sk-estimator-id-13" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>OneHotEncoder</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html">?<span>Documentation for OneHotEncoder</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=categories,-%27auto%27%20or%20a%20list%20of%20array-like%2C%20default%3D%27auto%27" class="param-doc-link" rel="noreferrer" target="_blank">categories <span class="param-doc-description">categories: 'auto' or a list of array-like, default='auto'<br>
<br>
Categories (unique values) per feature:<br>
<br>
- 'auto' : Determine categories automatically from the training data.<br>
- list : ``categories[i]`` holds the categories expected in the ith<br>
column. The passed categories should not mix strings and numeric<br>
values within a single feature, and should be sorted in case of<br>
numeric values.<br>
<br>
The used categories can be found in the ``categories_`` attribute.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">'auto'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=drop,-%7B%27first%27%2C%20%27if_binary%27%7D%20or%20an%20array-like%20of%20shape%20%28n_features%2C%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">drop <span class="param-doc-description">drop: {'first', 'if_binary'} or an array-like of shape (n_features,), default=None<br>
<br>
Specifies a methodology to use to drop one of the categories per<br>
feature. This is useful in situations where perfectly collinear<br>
features cause problems, such as when feeding the resulting data<br>
into an unregularized linear regression model.<br>
<br>
However, dropping one category breaks the symmetry of the original<br>
representation and can therefore induce a bias in downstream models,<br>
for instance for penalized linear classification or regression models.<br>
<br>
- None : retain all features (the default).<br>
- 'first' : drop the first category in each feature. If only one<br>
category is present, the feature will be dropped entirely.<br>
- 'if_binary' : drop the first category in each feature with two<br>
categories. Features with 1 or more than 2 categories are<br>
left intact.<br>
- array : ``drop[i]`` is the category in feature ``X[:, i]`` that<br>
should be dropped.<br>
<br>
When `max_categories` or `min_frequency` is configured to group<br>
infrequent categories, the dropping behavior is handled after the<br>
grouping.<br>
<br>
.. versionadded:: 0.21<br>
The parameter `drop` was added in 0.21.<br>
<br>
.. versionchanged:: 0.23<br>
The option `drop='if_binary'` was added in 0.23.<br>
<br>
.. versionchanged:: 1.1<br>
Support for dropping infrequent categories.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=sparse_output,-bool%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">sparse_output <span class="param-doc-description">sparse_output: bool, default=True<br>
<br>
When ``True``, it returns a :class:`scipy.sparse.csr_matrix`,<br>
i.e. a sparse matrix in "Compressed Sparse Row" (CSR) format.<br>
<br>
.. versionadded:: 1.2<br>
`sparse` was renamed to `sparse_output`</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=dtype,-number%20type%2C%20default%3Dnp.float64" class="param-doc-link" rel="noreferrer" target="_blank">dtype <span class="param-doc-description">dtype: number type, default=np.float64<br>
<br>
Desired dtype of output.</span></a></td>
<td class="value">&lt;class 'numpy.float64'&gt;</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=handle_unknown,-%7B%27error%27%2C%20%27ignore%27%2C%20%27infrequent_if_exist%27%2C%20%27warn%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27error%27" class="param-doc-link" rel="noreferrer" target="_blank">handle_unknown <span class="param-doc-description">handle_unknown: {'error', 'ignore', 'infrequent_if_exist', 'warn'}, default='error'<br>
<br>
Specifies the way unknown categories are handled during :meth:`transform`.<br>
<br>
- 'error' : Raise an error if an unknown category is present during transform.<br>
- 'ignore' : When an unknown category is encountered during<br>
transform, the resulting one-hot encoded columns for this feature<br>
will be all zeros. In the inverse transform, an unknown category<br>
will be denoted as None.<br>
- 'infrequent_if_exist' : When an unknown category is encountered<br>
during transform, the resulting one-hot encoded columns for this<br>
feature will map to the infrequent category if it exists. The<br>
infrequent category will be mapped to the last position in the<br>
encoding. During inverse transform, an unknown category will be<br>
mapped to the category denoted `'infrequent'` if it exists. If the<br>
`'infrequent'` category does not exist, then :meth:`transform` and<br>
:meth:`inverse_transform` will handle an unknown category as with<br>
`handle_unknown='ignore'`. Infrequent categories exist based on<br>
`min_frequency` and `max_categories`. Read more in the<br>
:ref:`User Guide <encoder_infrequent_categories>`.<br>
- 'warn' : When an unknown category is encountered during transform<br>
a warning is issued, and the encoding then proceeds as described for<br>
`handle_unknown="infrequent_if_exist"`.<br>
<br>
.. versionchanged:: 1.1<br>
`'infrequent_if_exist'` was added to automatically handle unknown<br>
categories and infrequent categories.<br>
<br>
.. versionadded:: 1.6<br>
The option `"warn"` was added in 1.6.</encoder_infrequent_categories></span></a></td>
<td class="value">'ignore'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=min_frequency,-int%20or%20float%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">min_frequency <span class="param-doc-description">min_frequency: int or float, default=None<br>
<br>
Specifies the minimum frequency below which a category will be<br>
considered infrequent.<br>
<br>
- If `int`, categories with a smaller cardinality will be considered<br>
infrequent.<br>
<br>
- If `float`, categories with a smaller cardinality than<br>
`min_frequency * n_samples` will be considered infrequent.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=max_categories,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_categories <span class="param-doc-description">max_categories: int, default=None<br>
<br>
Specifies an upper limit to the number of output features for each input<br>
feature when considering infrequent categories. If there are infrequent<br>
categories, `max_categories` includes the category representing the<br>
infrequent categories along with the frequent categories. If `None`,<br>
there is no limit to the number of output features.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=feature_name_combiner,-%22concat%22%20or%20callable%2C%20default%3D%22concat%22" class="param-doc-link" rel="noreferrer" target="_blank">feature_name_combiner <span class="param-doc-description">feature_name_combiner: "concat" or callable, default="concat"<br>
<br>
Callable with signature `def callable(input_feature, category)` that returns a<br>
string. This is used to create feature names to be returned by<br>
:meth:`get_feature_names_out`.<br>
<br>
`"concat"` concatenates encoded feature name and category with<br>
`feature + "_" + str(category)`.E.g. feature X with values 1, 6, 7 create<br>
feature names `X_1, X_6, X_7`.<br>
<br>
.. versionadded:: 1.3</span></a></td>
<td class="value">'concat'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-14" type="checkbox"><label for="sk-estimator-id-14" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>RandomForestClassifier</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html">?<span>Documentation for RandomForestClassifier</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="rf__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100" class="param-doc-link" rel="noreferrer" target="_blank">n_estimators <span class="param-doc-description">n_estimators: int, default=100<br>
<br>
The number of trees in the forest.<br>
<br>
.. versionchanged:: 0.22<br>
The default value of ``n_estimators`` changed from 10 to 100<br>
in 0.22.</span></a></td>
<td class="value">200</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22" class="param-doc-link" rel="noreferrer" target="_blank">criterion <span class="param-doc-description">criterion: {"gini", "entropy", "log_loss"}, default="gini"<br>
<br>
The function to measure the quality of a split. Supported criteria are<br>
"gini" for the Gini impurity and "log_loss" and "entropy" both for the<br>
Shannon information gain, see :ref:`tree_mathematical_formulation`.<br>
Note: This parameter is tree-specific.</span></a></td>
<td class="value">'gini'</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_depth <span class="param-doc-description">max_depth: int, default=None<br>
<br>
The maximum depth of the tree. If None, then nodes are expanded until<br>
all leaves are pure or until all leaves contain less than<br>
min_samples_split samples.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_split <span class="param-doc-description">min_samples_split: int or float, default=2<br>
<br>
The minimum number of samples required to split an internal node:<br>
<br>
- If int, then consider `min_samples_split` as the minimum number.<br>
- If float, then `min_samples_split` is a fraction and<br>
`ceil(min_samples_split * n_samples)` are the minimum<br>
number of samples for each split.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">2</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_leaf <span class="param-doc-description">min_samples_leaf: int or float, default=1<br>
<br>
The minimum number of samples required to be at a leaf node.<br>
A split point at any depth will only be considered if it leaves at<br>
least ``min_samples_leaf`` training samples in each of the left and<br>
right branches. This may have the effect of smoothing the model,<br>
especially in regression.<br>
<br>
- If int, then consider `min_samples_leaf` as the minimum number.<br>
- If float, then `min_samples_leaf` is a fraction and<br>
`ceil(min_samples_leaf * n_samples)` are the minimum<br>
number of samples for each node.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">1</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_weight_fraction_leaf <span class="param-doc-description">min_weight_fraction_leaf: float, default=0.0<br>
<br>
The minimum weighted fraction of the sum total of weights (of all<br>
the input samples) required to be at a leaf node. Samples have<br>
equal weight when sample_weight is not provided.</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_features,-%7B%22sqrt%22%2C%20%22log2%22%2C%20None%7D%2C%20int%20or%20float%2C%20default%3D%22sqrt%22" class="param-doc-link" rel="noreferrer" target="_blank">max_features <span class="param-doc-description">max_features: {"sqrt", "log2", None}, int or float, default="sqrt"<br>
<br>
The number of features to consider when looking for the best split:<br>
<br>
- If int, then consider `max_features` features at each split.<br>
- If float, then `max_features` is a fraction and<br>
`max(1, int(max_features * n_features_in_))` features are considered at each<br>
split.<br>
- If "sqrt", then `max_features=sqrt(n_features)`.<br>
- If "log2", then `max_features=log2(n_features)`.<br>
- If None, then `max_features=n_features`.<br>
<br>
.. versionchanged:: 1.1<br>
The default of `max_features` changed from `"auto"` to `"sqrt"`.<br>
<br>
Note: the search for a split does not stop until at least one<br>
valid partition of the node samples is found, even if it requires to<br>
effectively inspect more than ``max_features`` features.</span></a></td>
<td class="value">'sqrt'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_leaf_nodes <span class="param-doc-description">max_leaf_nodes: int, default=None<br>
<br>
Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>
Best nodes are defined as relative reduction in impurity.<br>
If None then unlimited number of leaf nodes.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_impurity_decrease <span class="param-doc-description">min_impurity_decrease: float, default=0.0<br>
<br>
A node will be split if this split induces a decrease of the impurity<br>
greater than or equal to this value.<br>
<br>
The weighted impurity decrease equation is the following::<br>
<br>
N_t / N * (impurity - N_t_R / N_t * right_impurity<br>
- N_t_L / N_t * left_impurity)<br>
<br>
where ``N`` is the total number of samples, ``N_t`` is the number of<br>
samples at the current node, ``N_t_L`` is the number of samples in the<br>
left child, and ``N_t_R`` is the number of samples in the right child.<br>
<br>
``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>
if ``sample_weight`` is passed.<br>
<br>
.. versionadded:: 0.19</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=bootstrap,-bool%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">bootstrap <span class="param-doc-description">bootstrap: bool, default=True<br>
<br>
Whether bootstrap samples are used when building trees. If False, the<br>
whole dataset is used to build each tree.</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=oob_score,-bool%20or%20callable%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">oob_score <span class="param-doc-description">oob_score: bool or callable, default=False<br>
<br>
Whether to use out-of-bag samples to estimate the generalization score.<br>
By default, :func:`~sklearn.metrics.accuracy_score` is used.<br>
Provide a callable with signature `metric(y_true, y_pred)` to use a<br>
custom metric. Only available if `bootstrap=True`.<br>
<br>
For an illustration of out-of-bag (OOB) error estimation, see the example<br>
:ref:`sphx_glr_auto_examples_ensemble_plot_ensemble_oob.py`.</span></a></td>
<td class="value">False</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=n_jobs,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">n_jobs <span class="param-doc-description">n_jobs: int, default=None<br>
<br>
The number of jobs to run in parallel. :meth:`fit`, :meth:`predict`,<br>
:meth:`decision_path` and :meth:`apply` are all parallelized over the<br>
trees. ``None`` means 1 unless in a :obj:`joblib.parallel_backend`<br>
context. ``-1`` means using all processors. See :term:`Glossary<br>
<n_jobs>` for more details.</n_jobs></span></a></td>
<td class="value">None</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">random_state <span class="param-doc-description">random_state: int, RandomState instance or None, default=None<br>
<br>
Controls both the randomness of the bootstrapping of the samples used<br>
when building trees (if ``bootstrap=True``) and the sampling of the<br>
features to consider when looking for the best split at each node<br>
(if ``max_features &lt; n_features``).<br>
See :term:`Glossary <random_state>` for details.</random_state></span></a></td>
<td class="value">42</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=verbose,-int%2C%20default%3D0" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: int, default=0<br>
<br>
Controls the verbosity when fitting and predicting.</span></a></td>
<td class="value">0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">warm_start <span class="param-doc-description">warm_start: bool, default=False<br>
<br>
When set to ``True``, reuse the solution of the previous call to fit<br>
and add more estimators to the ensemble, otherwise, just fit a whole<br>
new forest. See :term:`Glossary <warm_start>` and<br>
:ref:`tree_ensemble_warm_start` for details.</warm_start></span></a></td>
<td class="value">False</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=class_weight,-%7B%22balanced%22%2C%20%22balanced_subsample%22%7D%2C%20dict%20or%20list%20of%20dicts%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">class_weight <span class="param-doc-description">class_weight: {"balanced", "balanced_subsample"}, dict or list of dicts, default=None<br>
<br>
Weights associated with classes in the form ``{class_label: weight}``.<br>
If not given, all classes are supposed to have weight one. For<br>
multi-output problems, a list of dicts can be provided in the same<br>
order as the columns of y.<br>
<br>
Note that for multioutput (including multilabel) weights should be<br>
defined for each class of every column in its own dict. For example,<br>
for four-class multilabel classification weights should be<br>
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>
[{1:1}, {2:5}, {3:1}, {4:1}].<br>
<br>
The "balanced" mode uses the values of y to automatically adjust<br>
weights inversely proportional to class frequencies in the input data<br>
as ``n_samples / (n_classes * np.bincount(y))``<br>
<br>
The "balanced_subsample" mode is the same as "balanced" except that<br>
weights are computed based on the bootstrap sample for every tree<br>
grown.<br>
<br>
For multi-output, the weights of each column of y will be multiplied.<br>
<br>
Note that these weights will be multiplied with sample_weight (passed<br>
through the fit method) if sample_weight is specified.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">ccp_alpha <span class="param-doc-description">ccp_alpha: non-negative float, default=0.0<br>
<br>
Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>
subtree with the largest cost complexity that is smaller than<br>
``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>
:ref:`minimal_cost_complexity_pruning` for details. See<br>
:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>
for an example of such pruning.<br>
<br>
.. versionadded:: 0.22</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=max_samples,-int%20or%20float%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_samples <span class="param-doc-description">max_samples: int or float, default=None<br>
<br>
If bootstrap is True, the number of samples to draw from X<br>
to train each base estimator.<br>
<br>
- If None (default), then draw `X.shape[0]` samples.<br>
- If int, then draw `max_samples` samples.<br>
- If float, then draw `max(round(n_samples * max_samples), 1)` samples. Thus,<br>
`max_samples` should be in the interval `(0.0, 1.0]`.<br>
<br>
.. versionadded:: 0.22</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.RandomForestClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">monotonic_cst <span class="param-doc-description">monotonic_cst: array-like of int of shape (n_features), default=None<br>
<br>
Indicates the monotonicity constraint to enforce on each feature.<br>
- 1: monotonic increase<br>
- 0: no constraint<br>
- -1: monotonic decrease<br>
<br>
If monotonic_cst is None, no constraints are applied.<br>
<br>
Monotonicity constraints are not supported for:<br>
- multiclass classifications (i.e. when `n_classes &gt; 2`),<br>
- multioutput classifications (i.e. when `n_outputs_ &gt; 1`),<br>
- classifications trained on data with missing values.<br>
<br>
The constraints hold over the probability of the positive class.<br>
<br>
Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br>
<br>
.. versionadded:: 1.4</monotonic_cst_gbdt></span></a></td>
<td class="value">None</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.copy-paste-icon').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling
        .textContent.trim().split(' ')[0];
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});


/**
 * Adapted from Skrub
 * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789
 * @returns "light" or "dark"
 */
function detectTheme(element) {
    const body = document.querySelector('body');

    // Check VSCode theme
    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');
    const themeNameAttr = body.getAttribute('data-vscode-theme-name');

    if (themeKindAttr && themeNameAttr) {
        const themeKind = themeKindAttr.toLowerCase();
        const themeName = themeNameAttr.toLowerCase();

        if (themeKind.includes("dark") || themeName.includes("dark")) {
            return "dark";
        }
        if (themeKind.includes("light") || themeName.includes("light")) {
            return "light";
        }
    }

    // Check Jupyter theme
    if (body.getAttribute('data-jp-theme-light') === 'false') {
        return 'dark';
    } else if (body.getAttribute('data-jp-theme-light') === 'true') {
        return 'light';
    }

    // Guess based on a parent element's color
    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');
    const match = color.match(/^rgb\s*\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)\s*$/i);
    if (match) {
        const [r, g, b] = [
            parseFloat(match[1]),
            parseFloat(match[2]),
            parseFloat(match[3])
        ];

        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness
        const luma = 0.299 * r + 0.587 * g + 0.114 * b;

        if (luma > 180) {
            // If the text is very bright we have a dark theme
            return 'dark';
        }
        if (luma < 75) {
            // If the text is very dark we have a light theme
            return 'light';
        }
        // Otherwise fall back to the next heuristic.
    }

    // Fallback to system preference
    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
}


function forceTheme(elementId) {
    const estimatorElement = document.querySelector(`#${elementId}`);
    if (estimatorElement === null) {
        console.error(`Element with id ${elementId} not found.`);
    } else {
        const theme = detectTheme(estimatorElement);
        estimatorElement.classList.add(theme);
    }
}

forceTheme('sk-container-id-2');</script>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-12-contents" aria-controls="callout-12" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-12" class="callout-12-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Trains an ensemble of 200 decision trees.</li>
<li><code>n_estimators</code> controls the number of trees.</li>
<li><code>random_state</code> ensures reproducible results.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Without a fixed seed, results may vary between runs.</li>
<li>Ensemble size affects computation time and stability.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="d3.-boosted-trees-learning-from-mistakes" class="level2">
<h2 class="anchored" data-anchor-id="d3.-boosted-trees-learning-from-mistakes">D3. Boosted Trees — Learning From Mistakes</h2>
<section id="conceptual-overview-1" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-overview-1">Conceptual Overview</h3>
<p>Boosted trees follow a different idea:</p>
<ul>
<li>trees are trained <strong>sequentially</strong>, not independently,</li>
<li>each new tree focuses on correcting previous errors,</li>
<li>difficult cases receive increasing attention.</li>
</ul>
<p>Where random forests reduce <strong>variance</strong>, boosting aims to reduce <strong>bias</strong>.</p>
<hr>
</section>
<section id="r-training-a-boosted-tree-model" class="level3">
<h3 class="anchored" data-anchor-id="r-training-a-boosted-tree-model">R: Training a Boosted Tree Model</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb24"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb24-1"><a href="#cb24-1" aria-hidden="true" tabindex="-1"></a><span class="fu">library</span>(gbm)</span>
<span id="cb24-2"><a href="#cb24-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-3"><a href="#cb24-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Copy data so original stays untouched</span></span>
<span id="cb24-4"><a href="#cb24-4" aria-hidden="true" tabindex="-1"></a>model_data_gbm <span class="ot">&lt;-</span> model_data</span>
<span id="cb24-5"><a href="#cb24-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-6"><a href="#cb24-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert character predictors to factors</span></span>
<span id="cb24-7"><a href="#cb24-7" aria-hidden="true" tabindex="-1"></a>model_data_gbm[] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(</span>
<span id="cb24-8"><a href="#cb24-8" aria-hidden="true" tabindex="-1"></a>  model_data_gbm,</span>
<span id="cb24-9"><a href="#cb24-9" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(x) <span class="cf">if</span> (<span class="fu">is.character</span>(x)) <span class="fu">factor</span>(x) <span class="cf">else</span> x</span>
<span id="cb24-10"><a href="#cb24-10" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb24-11"><a href="#cb24-11" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-12"><a href="#cb24-12" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert response to numeric 0/1 (Bernoulli requirement)</span></span>
<span id="cb24-13"><a href="#cb24-13" aria-hidden="true" tabindex="-1"></a>model_data_gbm<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(model_data_gbm<span class="sc">$</span>y) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb24-14"><a href="#cb24-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb24-15"><a href="#cb24-15" aria-hidden="true" tabindex="-1"></a><span class="co"># Fit GBM model</span></span>
<span id="cb24-16"><a href="#cb24-16" aria-hidden="true" tabindex="-1"></a>gb_model <span class="ot">&lt;-</span> <span class="fu">gbm</span>(</span>
<span id="cb24-17"><a href="#cb24-17" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb24-18"><a href="#cb24-18" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> model_data_gbm,</span>
<span id="cb24-19"><a href="#cb24-19" aria-hidden="true" tabindex="-1"></a>  <span class="at">distribution =</span> <span class="st">"bernoulli"</span>,</span>
<span id="cb24-20"><a href="#cb24-20" aria-hidden="true" tabindex="-1"></a>  <span class="at">n.trees =</span> <span class="dv">200</span>,</span>
<span id="cb24-21"><a href="#cb24-21" aria-hidden="true" tabindex="-1"></a>  <span class="at">interaction.depth =</span> <span class="dv">3</span>,</span>
<span id="cb24-22"><a href="#cb24-22" aria-hidden="true" tabindex="-1"></a>  <span class="at">shrinkage =</span> <span class="fl">0.01</span>,</span>
<span id="cb24-23"><a href="#cb24-23" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb24-24"><a href="#cb24-24" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-13-contents" aria-controls="callout-13" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-13" class="callout-13-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Fits a gradient boosting model for binary classification.</li>
<li><code>distribution = "bernoulli"</code> matches the binary target.</li>
<li><code>interaction.depth</code> controls tree depth in boosting.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Boosting builds complexity gradually.</li>
<li>Shallow trees combined sequentially can form powerful models.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python-training-a-boosted-tree-model" class="level3">
<h3 class="anchored" data-anchor-id="python-training-a-boosted-tree-model">Python: Training a Boosted Tree Model</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb25"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb25-1"><a href="#cb25-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.ensemble <span class="im">import</span> GradientBoostingClassifier</span>
<span id="cb25-2"><a href="#cb25-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb25-3"><a href="#cb25-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-4"><a href="#cb25-4" aria-hidden="true" tabindex="-1"></a>gb_model <span class="op">=</span> Pipeline(</span>
<span id="cb25-5"><a href="#cb25-5" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span>[</span>
<span id="cb25-6"><a href="#cb25-6" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"prep"</span>, preprocess),   <span class="co"># reuse your ColumnTransformer</span></span>
<span id="cb25-7"><a href="#cb25-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"gb"</span>, GradientBoostingClassifier(</span>
<span id="cb25-8"><a href="#cb25-8" aria-hidden="true" tabindex="-1"></a>            n_estimators<span class="op">=</span><span class="dv">200</span>,</span>
<span id="cb25-9"><a href="#cb25-9" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb25-10"><a href="#cb25-10" aria-hidden="true" tabindex="-1"></a>        )),</span>
<span id="cb25-11"><a href="#cb25-11" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb25-12"><a href="#cb25-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb25-13"><a href="#cb25-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb25-14"><a href="#cb25-14" aria-hidden="true" tabindex="-1"></a>gb_model.fit(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-3 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;
}

#sk-container-id-3.light {
  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: black;
  --sklearn-color-background: white;
  --sklearn-color-border-box: black;
  --sklearn-color-icon: #696969;
}

#sk-container-id-3.dark {
  --sklearn-color-text-on-default-background: white;
  --sklearn-color-background: #111;
  --sklearn-color-border-box: white;
  --sklearn-color-icon: #878787;
}

#sk-container-id-3 {
  color: var(--sklearn-color-text);
}

#sk-container-id-3 pre {
  padding: 0;
}

#sk-container-id-3 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-3 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-3 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-3 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-3 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-3 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-3 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-3 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-3 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-3 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-3 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-3 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: center;
  justify-content: center;
  gap: 0.5em;
}

#sk-container-id-3 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-3 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-3 div.sk-label label.sk-toggleable__label,
#sk-container-id-3 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-3 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-3 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  line-height: 1.2em;
}

#sk-container-id-3 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-3 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-3 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-3 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-3 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-3) 1pt solid;
  color: var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3) 1pt solid;
  color: var(--sklearn-color-fitted-level-3);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-unfitted-level-0);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-fitted-level-0);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-3 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-3 a.estimator_doc_link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-3 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-3 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table {
    font-family: monospace;
}

.estimator-table summary {
    padding: .5rem;
    cursor: pointer;
}

.estimator-table summary::marker {
    font-size: 0.7rem;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
    margin-top: 0;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

/*
    `table td`is set in notebook with right text-align.
    We need to overwrite it.
*/
.estimator-table table td.param {
    text-align: left;
    position: relative;
    padding: 0;
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left !important;
}

.user-set td.value {
    color:rgb(255, 94, 0);
    background-color: transparent;
}

.default td {
    color: black;
    text-align: left !important;
}

.user-set td i,
.default td i {
    color: black;
}

/*
    Styles for parameter documentation links
    We need styling for visited so jupyter doesn't overwrite it
*/
a.param-doc-link,
a.param-doc-link:link,
a.param-doc-link:visited {
    text-decoration: underline dashed;
    text-underline-offset: .3em;
    color: inherit;
    display: block;
    padding: .5em;
}

/* "hack" to make the entire area of the cell containing the link clickable */
a.param-doc-link::before {
    position: absolute;
    content: "";
    inset: 0;
}

.param-doc-description {
    display: none;
    position: absolute;
    z-index: 9999;
    left: 0;
    padding: .5ex;
    margin-left: 1.5em;
    color: var(--sklearn-color-text);
    box-shadow: .3em .3em .4em #999;
    width: max-content;
    text-align: left;
    max-height: 10em;
    overflow-y: auto;

    /* unfitted */
    background: var(--sklearn-color-unfitted-level-0);
    border: thin solid var(--sklearn-color-unfitted-level-3);
}

/* Fitted state for parameter tooltips */
.fitted .param-doc-description {
    /* fitted */
    background: var(--sklearn-color-fitted-level-0);
    border: thin solid var(--sklearn-color-fitted-level-3);
}

.param-doc-link:hover .param-doc-description {
    display: block;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><div id="sk-container-id-3" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('prep',
                 ColumnTransformer(transformers=[('num', 'passthrough',
                                                  Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')),
                                                 ('cat',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object'))])),
                ('gb',
                 GradientBoostingClassifier(n_estimators=200,
                                            random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-15" type="checkbox"><label for="sk-estimator-id-15" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>Pipeline</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">steps <span class="param-doc-description">steps: list of tuples<br>
<br>
List of (name of step, estimator) tuples that are to be chained in<br>
sequential order. To be compatible with the scikit-learn API, all steps<br>
must define `fit`. All non-last steps must also define `transform`. See<br>
:ref:`Combining Estimators <combining_estimators>` for more details.</combining_estimators></span></a></td>
<td class="value">[('prep', ...), ('gb', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transform_input <span class="param-doc-description">transform_input: list of str, default=None<br>
<br>
The names of the :term:`metadata` parameters that should be transformed by the<br>
pipeline before passing it to the step consuming it.<br>
<br>
This enables transforming some input arguments to ``fit`` (other than ``X``)<br>
to be transformed by the steps of the pipeline up to the step which requires<br>
them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>
For instance, this can be used to pass a validation set through the pipeline.<br>
<br>
You can only set this if metadata routing is enabled, which you<br>
can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br>
<br>
.. versionadded:: 1.6</metadata_routing></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">memory <span class="param-doc-description">memory: str or object with the joblib.Memory interface, default=None<br>
<br>
Used to cache the fitted transformers of the pipeline. The last step<br>
will never be cached, even if it is a transformer. By default, no<br>
caching is performed. If a string is given, it is the path to the<br>
caching directory. Enabling caching triggers a clone of the transformers<br>
before fitting. Therefore, the transformer instance given to the<br>
pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>
or ``steps`` to inspect estimators within the pipeline. Caching the<br>
transformers is advantageous when fitting is time consuming. See<br>
:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>
for an example on how to enable caching.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each step will be printed as it<br>
is completed.</span></a></td>
<td class="value">False</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-16" type="checkbox"><label for="sk-estimator-id-16" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>prep: ColumnTransformer</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html">?<span>Documentation for prep: ColumnTransformer</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformers,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">transformers <span class="param-doc-description">transformers: list of tuples<br>
<br>
List of (name, transformer, columns) tuples specifying the<br>
transformer objects to be applied to subsets of the data.<br>
<br>
name : str<br>
Like in Pipeline and FeatureUnion, this allows the transformer and<br>
its parameters to be set using ``set_params`` and searched in grid<br>
search.<br>
transformer : {'drop', 'passthrough'} or estimator<br>
Estimator must support :term:`fit` and :term:`transform`.<br>
Special-cased strings 'drop' and 'passthrough' are accepted as<br>
well, to indicate to drop the columns or to pass them through<br>
untransformed, respectively.<br>
columns : str, array-like of str, int, array-like of int, array-like of bool, slice or callable<br>
Indexes the data on its second axis. Integers are interpreted as<br>
positional columns, while strings can reference DataFrame columns<br>
by name. A scalar string or int should be used where<br>
``transformer`` expects X to be a 1d array-like (vector),<br>
otherwise a 2d array will be passed to the transformer.<br>
A callable is passed the input data `X` and can return any of the<br>
above. To select multiple columns by name or dtype, you can use<br>
:obj:`make_column_selector`.</span></a></td>
<td class="value">[('num', ...), ('cat', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=remainder,-%7B%27drop%27%2C%20%27passthrough%27%7D%20or%20estimator%2C%20default%3D%27drop%27" class="param-doc-link" rel="noreferrer" target="_blank">remainder <span class="param-doc-description">remainder: {'drop', 'passthrough'} or estimator, default='drop'<br>
<br>
By default, only the specified columns in `transformers` are<br>
transformed and combined in the output, and the non-specified<br>
columns are dropped. (default of ``'drop'``).<br>
By specifying ``remainder='passthrough'``, all remaining columns that<br>
were not specified in `transformers`, but present in the data passed<br>
to `fit` will be automatically passed through. This subset of columns<br>
is concatenated with the output of the transformers. For dataframes,<br>
extra columns not seen during `fit` will be excluded from the output<br>
of `transform`.<br>
By setting ``remainder`` to be an estimator, the remaining<br>
non-specified columns will use the ``remainder`` estimator. The<br>
estimator must support :term:`fit` and :term:`transform`.<br>
Note that using this feature requires that the DataFrame columns<br>
input at :term:`fit` and :term:`transform` have identical order.</span></a></td>
<td class="value">'drop'</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=sparse_threshold,-float%2C%20default%3D0.3" class="param-doc-link" rel="noreferrer" target="_blank">sparse_threshold <span class="param-doc-description">sparse_threshold: float, default=0.3<br>
<br>
If the output of the different transformers contains sparse matrices,<br>
these will be stacked as a sparse matrix if the overall density is<br>
lower than this value. Use ``sparse_threshold=0`` to always return<br>
dense. When the transformed output consists of all dense data, the<br>
stacked result will be dense, and this keyword will be ignored.</span></a></td>
<td class="value">0.3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=n_jobs,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">n_jobs <span class="param-doc-description">n_jobs: int, default=None<br>
<br>
Number of jobs to run in parallel.<br>
``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>
``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>
for more details.</n_jobs></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformer_weights,-dict%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transformer_weights <span class="param-doc-description">transformer_weights: dict, default=None<br>
<br>
Multiplicative weights for features per transformer. The output of the<br>
transformer is multiplied by these weights. Keys are transformer names,<br>
values the weights.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each transformer will be<br>
printed as it is completed.</span></a></td>
<td class="value">False</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose_feature_names_out,-bool%2C%20str%20or%20Callable%5B%5Bstr%2C%20str%5D%2C%20str%5D%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">verbose_feature_names_out <span class="param-doc-description">verbose_feature_names_out: bool, str or Callable[[str, str], str], default=True<br>
<br>
- If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix<br>
all feature names with the name of the transformer that generated that<br>
feature. It is equivalent to setting<br>
`verbose_feature_names_out="{transformer_name}__{feature_name}"`.<br>
- If False, :meth:`ColumnTransformer.get_feature_names_out` will not<br>
prefix any feature names and will error if feature names are not<br>
unique.<br>
- If ``Callable[[str, str], str]``,<br>
:meth:`ColumnTransformer.get_feature_names_out` will rename all the features<br>
using the name of the transformer. The first argument of the callable is the<br>
transformer name and the second argument is the feature name. The returned<br>
string will be the new feature name.<br>
- If ``str``, it must be a string ready for formatting. The given string will<br>
be formatted using two field names: ``transformer_name`` and ``feature_name``.<br>
e.g. ``"{feature_name}__{transformer_name}"``. See :meth:`str.format` method<br>
from the standard library for more info.<br>
<br>
.. versionadded:: 1.0<br>
<br>
.. versionchanged:: 1.6<br>
`verbose_feature_names_out` can be a callable or a string to be formatted.</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=force_int_remainder_cols,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">force_int_remainder_cols <span class="param-doc-description">force_int_remainder_cols: bool, default=False<br>
<br>
This parameter has no effect.<br>
<br>
.. note::<br>
If you do not access the list of columns for the remainder columns<br>
in the `transformers_` fitted attribute, you do not need to set<br>
this parameter.<br>
<br>
.. versionadded:: 1.5<br>
<br>
.. versionchanged:: 1.7<br>
The default value for `force_int_remainder_cols` will change from<br>
`True` to `False` in version 1.7.<br>
<br>
.. deprecated:: 1.7<br>
`force_int_remainder_cols` is deprecated and will be removed in 1.9.</span></a></td>
<td class="value">'deprecated'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-17" type="checkbox"><label for="sk-estimator-id-17" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>num</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-18" type="checkbox"><label for="sk-estimator-id-18" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>passthrough</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>passthrough</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-19" type="checkbox"><label for="sk-estimator-id-19" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>cat</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__"><pre>Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-20" type="checkbox"><label for="sk-estimator-id-20" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>OneHotEncoder</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html">?<span>Documentation for OneHotEncoder</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=categories,-%27auto%27%20or%20a%20list%20of%20array-like%2C%20default%3D%27auto%27" class="param-doc-link" rel="noreferrer" target="_blank">categories <span class="param-doc-description">categories: 'auto' or a list of array-like, default='auto'<br>
<br>
Categories (unique values) per feature:<br>
<br>
- 'auto' : Determine categories automatically from the training data.<br>
- list : ``categories[i]`` holds the categories expected in the ith<br>
column. The passed categories should not mix strings and numeric<br>
values within a single feature, and should be sorted in case of<br>
numeric values.<br>
<br>
The used categories can be found in the ``categories_`` attribute.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">'auto'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=drop,-%7B%27first%27%2C%20%27if_binary%27%7D%20or%20an%20array-like%20of%20shape%20%28n_features%2C%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">drop <span class="param-doc-description">drop: {'first', 'if_binary'} or an array-like of shape (n_features,), default=None<br>
<br>
Specifies a methodology to use to drop one of the categories per<br>
feature. This is useful in situations where perfectly collinear<br>
features cause problems, such as when feeding the resulting data<br>
into an unregularized linear regression model.<br>
<br>
However, dropping one category breaks the symmetry of the original<br>
representation and can therefore induce a bias in downstream models,<br>
for instance for penalized linear classification or regression models.<br>
<br>
- None : retain all features (the default).<br>
- 'first' : drop the first category in each feature. If only one<br>
category is present, the feature will be dropped entirely.<br>
- 'if_binary' : drop the first category in each feature with two<br>
categories. Features with 1 or more than 2 categories are<br>
left intact.<br>
- array : ``drop[i]`` is the category in feature ``X[:, i]`` that<br>
should be dropped.<br>
<br>
When `max_categories` or `min_frequency` is configured to group<br>
infrequent categories, the dropping behavior is handled after the<br>
grouping.<br>
<br>
.. versionadded:: 0.21<br>
The parameter `drop` was added in 0.21.<br>
<br>
.. versionchanged:: 0.23<br>
The option `drop='if_binary'` was added in 0.23.<br>
<br>
.. versionchanged:: 1.1<br>
Support for dropping infrequent categories.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=sparse_output,-bool%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">sparse_output <span class="param-doc-description">sparse_output: bool, default=True<br>
<br>
When ``True``, it returns a :class:`scipy.sparse.csr_matrix`,<br>
i.e. a sparse matrix in "Compressed Sparse Row" (CSR) format.<br>
<br>
.. versionadded:: 1.2<br>
`sparse` was renamed to `sparse_output`</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=dtype,-number%20type%2C%20default%3Dnp.float64" class="param-doc-link" rel="noreferrer" target="_blank">dtype <span class="param-doc-description">dtype: number type, default=np.float64<br>
<br>
Desired dtype of output.</span></a></td>
<td class="value">&lt;class 'numpy.float64'&gt;</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=handle_unknown,-%7B%27error%27%2C%20%27ignore%27%2C%20%27infrequent_if_exist%27%2C%20%27warn%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27error%27" class="param-doc-link" rel="noreferrer" target="_blank">handle_unknown <span class="param-doc-description">handle_unknown: {'error', 'ignore', 'infrequent_if_exist', 'warn'}, default='error'<br>
<br>
Specifies the way unknown categories are handled during :meth:`transform`.<br>
<br>
- 'error' : Raise an error if an unknown category is present during transform.<br>
- 'ignore' : When an unknown category is encountered during<br>
transform, the resulting one-hot encoded columns for this feature<br>
will be all zeros. In the inverse transform, an unknown category<br>
will be denoted as None.<br>
- 'infrequent_if_exist' : When an unknown category is encountered<br>
during transform, the resulting one-hot encoded columns for this<br>
feature will map to the infrequent category if it exists. The<br>
infrequent category will be mapped to the last position in the<br>
encoding. During inverse transform, an unknown category will be<br>
mapped to the category denoted `'infrequent'` if it exists. If the<br>
`'infrequent'` category does not exist, then :meth:`transform` and<br>
:meth:`inverse_transform` will handle an unknown category as with<br>
`handle_unknown='ignore'`. Infrequent categories exist based on<br>
`min_frequency` and `max_categories`. Read more in the<br>
:ref:`User Guide <encoder_infrequent_categories>`.<br>
- 'warn' : When an unknown category is encountered during transform<br>
a warning is issued, and the encoding then proceeds as described for<br>
`handle_unknown="infrequent_if_exist"`.<br>
<br>
.. versionchanged:: 1.1<br>
`'infrequent_if_exist'` was added to automatically handle unknown<br>
categories and infrequent categories.<br>
<br>
.. versionadded:: 1.6<br>
The option `"warn"` was added in 1.6.</encoder_infrequent_categories></span></a></td>
<td class="value">'ignore'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=min_frequency,-int%20or%20float%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">min_frequency <span class="param-doc-description">min_frequency: int or float, default=None<br>
<br>
Specifies the minimum frequency below which a category will be<br>
considered infrequent.<br>
<br>
- If `int`, categories with a smaller cardinality will be considered<br>
infrequent.<br>
<br>
- If `float`, categories with a smaller cardinality than<br>
`min_frequency * n_samples` will be considered infrequent.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=max_categories,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_categories <span class="param-doc-description">max_categories: int, default=None<br>
<br>
Specifies an upper limit to the number of output features for each input<br>
feature when considering infrequent categories. If there are infrequent<br>
categories, `max_categories` includes the category representing the<br>
infrequent categories along with the frequent categories. If `None`,<br>
there is no limit to the number of output features.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=feature_name_combiner,-%22concat%22%20or%20callable%2C%20default%3D%22concat%22" class="param-doc-link" rel="noreferrer" target="_blank">feature_name_combiner <span class="param-doc-description">feature_name_combiner: "concat" or callable, default="concat"<br>
<br>
Callable with signature `def callable(input_feature, category)` that returns a<br>
string. This is used to create feature names to be returned by<br>
:meth:`get_feature_names_out`.<br>
<br>
`"concat"` concatenates encoded feature name and category with<br>
`feature + "_" + str(category)`.E.g. feature X with values 1, 6, 7 create<br>
feature names `X_1, X_6, X_7`.<br>
<br>
.. versionadded:: 1.3</span></a></td>
<td class="value">'concat'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-21" type="checkbox"><label for="sk-estimator-id-21" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>GradientBoostingClassifier</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html">?<span>Documentation for GradientBoostingClassifier</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="gb__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=loss,-%7B%27log_loss%27%2C%20%27exponential%27%7D%2C%20default%3D%27log_loss%27" class="param-doc-link" rel="noreferrer" target="_blank">loss <span class="param-doc-description">loss: {'log_loss', 'exponential'}, default='log_loss'<br>
<br>
The loss function to be optimized. 'log_loss' refers to binomial and<br>
multinomial deviance, the same as used in logistic regression.<br>
It is a good choice for classification with probabilistic outputs.<br>
For loss 'exponential', gradient boosting recovers the AdaBoost algorithm.</span></a></td>
<td class="value">'log_loss'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=learning_rate,-float%2C%20default%3D0.1" class="param-doc-link" rel="noreferrer" target="_blank">learning_rate <span class="param-doc-description">learning_rate: float, default=0.1<br>
<br>
Learning rate shrinks the contribution of each tree by `learning_rate`.<br>
There is a trade-off between learning_rate and n_estimators.<br>
Values must be in the range `[0.0, inf)`.<br>
<br>
For an example of the effects of this parameter and its interaction with<br>
``subsample``, see<br>
:ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_regularization.py`.</span></a></td>
<td class="value">0.1</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=n_estimators,-int%2C%20default%3D100" class="param-doc-link" rel="noreferrer" target="_blank">n_estimators <span class="param-doc-description">n_estimators: int, default=100<br>
<br>
The number of boosting stages to perform. Gradient boosting<br>
is fairly robust to over-fitting so a large number usually<br>
results in better performance.<br>
Values must be in the range `[1, inf)`.</span></a></td>
<td class="value">200</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=subsample,-float%2C%20default%3D1.0" class="param-doc-link" rel="noreferrer" target="_blank">subsample <span class="param-doc-description">subsample: float, default=1.0<br>
<br>
The fraction of samples to be used for fitting the individual base<br>
learners. If smaller than 1.0 this results in Stochastic Gradient<br>
Boosting. `subsample` interacts with the parameter `n_estimators`.<br>
Choosing `subsample &lt; 1.0` leads to a reduction of variance<br>
and an increase in bias.<br>
Values must be in the range `(0.0, 1.0]`.</span></a></td>
<td class="value">1.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=criterion,-%7B%27friedman_mse%27%2C%20%27squared_error%27%7D%2C%20default%3D%27friedman_mse%27" class="param-doc-link" rel="noreferrer" target="_blank">criterion <span class="param-doc-description">criterion: {'friedman_mse', 'squared_error'}, default='friedman_mse'<br>
<br>
The function to measure the quality of a split. Supported criteria are<br>
'friedman_mse' for the mean squared error with improvement score by<br>
Friedman, 'squared_error' for mean squared error. The default value of<br>
'friedman_mse' is generally the best as it can provide a better<br>
approximation in some cases.<br>
<br>
.. versionadded:: 0.18</span></a></td>
<td class="value">'friedman_mse'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_split <span class="param-doc-description">min_samples_split: int or float, default=2<br>
<br>
The minimum number of samples required to split an internal node:<br>
<br>
- If int, values must be in the range `[2, inf)`.<br>
- If float, values must be in the range `(0.0, 1.0]` and `min_samples_split`<br>
will be `ceil(min_samples_split * n_samples)`.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">2</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_leaf <span class="param-doc-description">min_samples_leaf: int or float, default=1<br>
<br>
The minimum number of samples required to be at a leaf node.<br>
A split point at any depth will only be considered if it leaves at<br>
least ``min_samples_leaf`` training samples in each of the left and<br>
right branches. This may have the effect of smoothing the model,<br>
especially in regression.<br>
<br>
- If int, values must be in the range `[1, inf)`.<br>
- If float, values must be in the range `(0.0, 1.0)` and `min_samples_leaf`<br>
will be `ceil(min_samples_leaf * n_samples)`.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">1</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_weight_fraction_leaf <span class="param-doc-description">min_weight_fraction_leaf: float, default=0.0<br>
<br>
The minimum weighted fraction of the sum total of weights (of all<br>
the input samples) required to be at a leaf node. Samples have<br>
equal weight when sample_weight is not provided.<br>
Values must be in the range `[0.0, 0.5]`.</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=max_depth,-int%20or%20None%2C%20default%3D3" class="param-doc-link" rel="noreferrer" target="_blank">max_depth <span class="param-doc-description">max_depth: int or None, default=3<br>
<br>
Maximum depth of the individual regression estimators. The maximum<br>
depth limits the number of nodes in the tree. Tune this parameter<br>
for best performance; the best value depends on the interaction<br>
of the input variables. If None, then nodes are expanded until<br>
all leaves are pure or until all leaves contain less than<br>
min_samples_split samples.<br>
If int, values must be in the range `[1, inf)`.</span></a></td>
<td class="value">3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_impurity_decrease <span class="param-doc-description">min_impurity_decrease: float, default=0.0<br>
<br>
A node will be split if this split induces a decrease of the impurity<br>
greater than or equal to this value.<br>
Values must be in the range `[0.0, inf)`.<br>
<br>
The weighted impurity decrease equation is the following::<br>
<br>
N_t / N * (impurity - N_t_R / N_t * right_impurity<br>
- N_t_L / N_t * left_impurity)<br>
<br>
where ``N`` is the total number of samples, ``N_t`` is the number of<br>
samples at the current node, ``N_t_L`` is the number of samples in the<br>
left child, and ``N_t_R`` is the number of samples in the right child.<br>
<br>
``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>
if ``sample_weight`` is passed.<br>
<br>
.. versionadded:: 0.19</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=init,-estimator%20or%20%27zero%27%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">init <span class="param-doc-description">init: estimator or 'zero', default=None<br>
<br>
An estimator object that is used to compute the initial predictions.<br>
``init`` has to provide :term:`fit` and :term:`predict_proba`. If<br>
'zero', the initial raw predictions are set to zero. By default, a<br>
``DummyEstimator`` predicting the classes priors is used.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="user-set even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">random_state <span class="param-doc-description">random_state: int, RandomState instance or None, default=None<br>
<br>
Controls the random seed given to each Tree estimator at each<br>
boosting iteration.<br>
In addition, it controls the random permutation of the features at<br>
each split (see Notes for more details).<br>
It also controls the random splitting of the training data to obtain a<br>
validation set if `n_iter_no_change` is not None.<br>
Pass an int for reproducible output across multiple function calls.<br>
See :term:`Glossary <random_state>`.</random_state></span></a></td>
<td class="value">42</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=max_features,-%7B%27sqrt%27%2C%20%27log2%27%7D%2C%20int%20or%20float%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_features <span class="param-doc-description">max_features: {'sqrt', 'log2'}, int or float, default=None<br>
<br>
The number of features to consider when looking for the best split:<br>
<br>
- If int, values must be in the range `[1, inf)`.<br>
- If float, values must be in the range `(0.0, 1.0]` and the features<br>
considered at each split will be `max(1, int(max_features * n_features_in_))`.<br>
- If 'sqrt', then `max_features=sqrt(n_features)`.<br>
- If 'log2', then `max_features=log2(n_features)`.<br>
- If None, then `max_features=n_features`.<br>
<br>
Choosing `max_features &lt; n_features` leads to a reduction of variance<br>
and an increase in bias.<br>
<br>
Note: the search for a split does not stop until at least one<br>
valid partition of the node samples is found, even if it requires to<br>
effectively inspect more than ``max_features`` features.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=verbose,-int%2C%20default%3D0" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: int, default=0<br>
<br>
Enable verbose output. If 1 then it prints progress and performance<br>
once in a while (the more trees the lower the frequency). If greater<br>
than 1 then it prints progress and performance for every tree.<br>
Values must be in the range `[0, inf)`.</span></a></td>
<td class="value">0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_leaf_nodes <span class="param-doc-description">max_leaf_nodes: int, default=None<br>
<br>
Grow trees with ``max_leaf_nodes`` in best-first fashion.<br>
Best nodes are defined as relative reduction in impurity.<br>
Values must be in the range `[2, inf)`.<br>
If `None`, then unlimited number of leaf nodes.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=warm_start,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">warm_start <span class="param-doc-description">warm_start: bool, default=False<br>
<br>
When set to ``True``, reuse the solution of the previous call to fit<br>
and add more estimators to the ensemble, otherwise, just erase the<br>
previous solution. See :term:`the Glossary <warm_start>`.</warm_start></span></a></td>
<td class="value">False</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=validation_fraction,-float%2C%20default%3D0.1" class="param-doc-link" rel="noreferrer" target="_blank">validation_fraction <span class="param-doc-description">validation_fraction: float, default=0.1<br>
<br>
The proportion of training data to set aside as validation set for<br>
early stopping. Values must be in the range `(0.0, 1.0)`.<br>
Only used if ``n_iter_no_change`` is set to an integer.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">0.1</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=n_iter_no_change,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">n_iter_no_change <span class="param-doc-description">n_iter_no_change: int, default=None<br>
<br>
``n_iter_no_change`` is used to decide if early stopping will be used<br>
to terminate training when validation score is not improving. By<br>
default it is set to None to disable early stopping. If set to a<br>
number, it will set aside ``validation_fraction`` size of the training<br>
data as validation and terminate training when validation score is not<br>
improving in all of the previous ``n_iter_no_change`` numbers of<br>
iterations. The split is stratified.<br>
Values must be in the range `[1, inf)`.<br>
See<br>
:ref:`sphx_glr_auto_examples_ensemble_plot_gradient_boosting_early_stopping.py`.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=tol,-float%2C%20default%3D1e-4" class="param-doc-link" rel="noreferrer" target="_blank">tol <span class="param-doc-description">tol: float, default=1e-4<br>
<br>
Tolerance for the early stopping. When the loss is not improving<br>
by at least tol for ``n_iter_no_change`` iterations (if set to a<br>
number), the training stops.<br>
Values must be in the range `[0.0, inf)`.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">0.0001</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.ensemble.GradientBoostingClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">ccp_alpha <span class="param-doc-description">ccp_alpha: non-negative float, default=0.0<br>
<br>
Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>
subtree with the largest cost complexity that is smaller than<br>
``ccp_alpha`` will be chosen. By default, no pruning is performed.<br>
Values must be in the range `[0.0, inf)`.<br>
See :ref:`minimal_cost_complexity_pruning` for details. See<br>
:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>
for an example of such pruning.<br>
<br>
.. versionadded:: 0.22</span></a></td>
<td class="value">0.0</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.copy-paste-icon').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling
        .textContent.trim().split(' ')[0];
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});


/**
 * Adapted from Skrub
 * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789
 * @returns "light" or "dark"
 */
function detectTheme(element) {
    const body = document.querySelector('body');

    // Check VSCode theme
    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');
    const themeNameAttr = body.getAttribute('data-vscode-theme-name');

    if (themeKindAttr && themeNameAttr) {
        const themeKind = themeKindAttr.toLowerCase();
        const themeName = themeNameAttr.toLowerCase();

        if (themeKind.includes("dark") || themeName.includes("dark")) {
            return "dark";
        }
        if (themeKind.includes("light") || themeName.includes("light")) {
            return "light";
        }
    }

    // Check Jupyter theme
    if (body.getAttribute('data-jp-theme-light') === 'false') {
        return 'dark';
    } else if (body.getAttribute('data-jp-theme-light') === 'true') {
        return 'light';
    }

    // Guess based on a parent element's color
    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');
    const match = color.match(/^rgb\s*\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)\s*$/i);
    if (match) {
        const [r, g, b] = [
            parseFloat(match[1]),
            parseFloat(match[2]),
            parseFloat(match[3])
        ];

        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness
        const luma = 0.299 * r + 0.587 * g + 0.114 * b;

        if (luma > 180) {
            // If the text is very bright we have a dark theme
            return 'dark';
        }
        if (luma < 75) {
            // If the text is very dark we have a light theme
            return 'light';
        }
        // Otherwise fall back to the next heuristic.
    }

    // Fallback to system preference
    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
}


function forceTheme(elementId) {
    const estimatorElement = document.querySelector(`#${elementId}`);
    if (estimatorElement === null) {
        console.error(`Element with id ${elementId} not found.`);
    } else {
        const theme = detectTheme(estimatorElement);
        estimatorElement.classList.add(theme);
    }
}

forceTheme('sk-container-id-3');</script>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-14-contents" aria-controls="callout-14" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-14" class="callout-14-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Trains a gradient boosting classifier.</li>
<li>Trees are built sequentially.</li>
<li>Each tree focuses on previous errors.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Boosted models often outperform single trees.</li>
<li>They are also harder to interpret directly.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="d4.-comparing-behaviour-not-scores" class="level2">
<h2 class="anchored" data-anchor-id="d4.-comparing-behaviour-not-scores">D4. Comparing Behaviour (Not Scores)</h2>
<p>At this stage, we <strong>do not</strong> optimise performance. Instead, we observe behaviour.</p>
<hr>
<section id="training-accuracy-illustrative-only" class="level3">
<h3 class="anchored" data-anchor-id="training-accuracy-illustrative-only">Training Accuracy (Illustrative Only)</h3>
<section id="r-1" class="level4">
<h4 class="anchored" data-anchor-id="r-1">R</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb26"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb26-1"><a href="#cb26-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Training accuracy (illustrative only)</span></span>
<span id="cb26-2"><a href="#cb26-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-3"><a href="#cb26-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision tree</span></span>
<span id="cb26-4"><a href="#cb26-4" aria-hidden="true" tabindex="-1"></a>tree_acc <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(tree_model, model_data, <span class="at">type =</span> <span class="st">"class"</span>) <span class="sc">==</span> model_data<span class="sc">$</span>y)</span>
<span id="cb26-5"><a href="#cb26-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-6"><a href="#cb26-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest</span></span>
<span id="cb26-7"><a href="#cb26-7" aria-hidden="true" tabindex="-1"></a>rf_acc <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(rf_model, model_data) <span class="sc">==</span> model_data<span class="sc">$</span>y)</span>
<span id="cb26-8"><a href="#cb26-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-9"><a href="#cb26-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient boosting</span></span>
<span id="cb26-10"><a href="#cb26-10" aria-hidden="true" tabindex="-1"></a>gb_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(gb_model, model_data, <span class="at">n.trees =</span> <span class="dv">200</span>, <span class="at">type =</span> <span class="st">"response"</span>)</span>
<span id="cb26-11"><a href="#cb26-11" aria-hidden="true" tabindex="-1"></a>gb_preds <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(gb_probs <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"yes"</span>, <span class="st">"no"</span>)</span>
<span id="cb26-12"><a href="#cb26-12" aria-hidden="true" tabindex="-1"></a>gb_acc   <span class="ot">&lt;-</span> <span class="fu">mean</span>(gb_preds <span class="sc">==</span> model_data<span class="sc">$</span>y)</span>
<span id="cb26-13"><a href="#cb26-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb26-14"><a href="#cb26-14" aria-hidden="true" tabindex="-1"></a>tree_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9033746</code></pre>
</div>
<div class="sourceCode cell-code" id="cb28"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb28-1"><a href="#cb28-1" aria-hidden="true" tabindex="-1"></a>rf_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9745084</code></pre>
</div>
<div class="sourceCode cell-code" id="cb30"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb30-1"><a href="#cb30-1" aria-hidden="true" tabindex="-1"></a>gb_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9041029</code></pre>
</div>
</div>
</section>
<section id="python-1" class="level4">
<h4 class="anchored">Python</h4>
<div class="cell">
<div class="sourceCode cell-code" id="cb32"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb32-1"><a href="#cb32-1" aria-hidden="true" tabindex="-1"></a>tree_model.score(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9053168244719592</code></pre>
</div>
<div class="sourceCode cell-code" id="cb34"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb34-1"><a href="#cb34-1" aria-hidden="true" tabindex="-1"></a>rf_model.score(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9997572226268512</code></pre>
</div>
<div class="sourceCode cell-code" id="cb36"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb36-1"><a href="#cb36-1" aria-hidden="true" tabindex="-1"></a>gb_model.score(X, y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9351784413692644</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-15-contents" aria-controls="callout-15" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What does “accuracy” mean here — and why we treat it cautiously
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-15" class="callout-15-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p><strong>Accuracy</strong> is the proportion of predictions that are correct:</p>
<p><span class="math display">\[
\text{Accuracy} = \frac{\text{Number of correct predictions}}{\text{Total predictions}}
\]</span></p>
<p>It is often the first metric people encounter — but it has important limitations.</p>
<hr>
<section id="why-accuracy-is-only-illustrative-here" class="level3">
<h3 class="anchored" data-anchor-id="why-accuracy-is-only-illustrative-here">Why accuracy is only illustrative here</h3>
<p>In this notebook: - we are evaluating models on the <strong>training data</strong>, - the target variable is <strong>imbalanced</strong>, - the prediction task is <strong>constructed</strong>, not given.</p>
<p>This means: - high accuracy may simply reflect overfitting, - small differences between models are not meaningful, - accuracy alone does not indicate a “better” model.</p>
<hr>
</section>
<section id="why-we-still-show-it" class="level3">
<h3 class="anchored" data-anchor-id="why-we-still-show-it">Why we still show it</h3>
<p>We include training accuracy <strong>only to observe behaviour</strong>:</p>
<ul>
<li>single trees typically achieve lower accuracy,</li>
<li>ensemble models often achieve higher accuracy,</li>
<li>this difference is expected due to reduced variance.</li>
</ul>
<p>We are <strong>not</strong> using accuracy to select or tune models.</p>
<hr>
</section>
<section id="key-takeaway-2" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaway-2">Key takeaway</h3>
<blockquote class="blockquote">
<p>Accuracy answers the question<br>
<em>“How often was the model correct on this data?”</em></p>
</blockquote>
<p>It does <strong>not</strong> answer: - whether the model will generalise, - whether the model is valid, - whether the model is appropriate for deployment.</p>
<p>Those questions require deeper evaluation, which comes later in the module.</p>
</section>
</div>
</div>
</div>
<hr>
</section>
</section>
</section>
<section id="d5.-strengths-and-trade-offs" class="level2">
<h2 class="anchored" data-anchor-id="d5.-strengths-and-trade-offs">D5. Strengths and Trade-offs</h2>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Model</th>
<th>Strength</th>
<th>Limitation</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Decision Tree</td>
<td>Transparent</td>
<td>Unstable</td>
</tr>
<tr class="even">
<td>Random Forest</td>
<td>Stable</td>
<td>Less interpretable</td>
</tr>
<tr class="odd">
<td>Boosted Trees</td>
<td>Powerful</td>
<td>Harder to explain</td>
</tr>
</tbody>
</table>
<p>This trade-off leads directly to the next question:</p>
<blockquote class="blockquote">
<p><em>How do we understand what complex models have learned?</em></p>
</blockquote>
<hr>
<p>*Part D6 — Why We Separate Data**</p>
<p>You can drop this <strong>immediately after D4</strong> (before D5), or place it right before the strengths/trade-offs table.</p>
<hr>
</section>
<section id="d6.-training-validation-and-test-sets" class="level2">
<h2 class="anchored" data-anchor-id="d6.-training-validation-and-test-sets">D6. Training, Validation, and Test Sets</h2>
<p>So far, we have evaluated models using the <strong>same data they were trained on</strong>.</p>
<p>This is deliberate — but it is also misleading.</p>
<p>To understand <em>generalisation</em>, we must separate data into <strong>distinct roles</strong>, not just distinct files.</p>
<hr>
<section id="why-we-split-the-data" class="level3">
<h3 class="anchored" data-anchor-id="why-we-split-the-data">Why We Split the Data</h3>
<p>In supervised learning, data typically plays <strong>three conceptually different roles</strong>:</p>
<table class="caption-top table">
<thead>
<tr class="header">
<th>Split</th>
<th>Role in the pipeline</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td>Training</td>
<td>Learn model parameters</td>
</tr>
<tr class="even">
<td>Validation</td>
<td>Inform modelling decisions</td>
</tr>
<tr class="odd">
<td>Test</td>
<td>Final, independent check after decisions stop</td>
</tr>
</tbody>
</table>
<p>Although validation and test both use <em>unseen data</em>,<br>
they serve <strong>different purposes</strong>.</p>
<p>Using the same data for all three roles leads to <strong>over-optimistic conclusions</strong>.</p>
<hr>
</section>
<section id="conceptual-warning" class="level3">
<h3 class="anchored" data-anchor-id="conceptual-warning">Conceptual Warning</h3>
<blockquote class="blockquote">
<p>A model that performs well on training data<br>
has only proven that it can <strong>memorise</strong> that data.</p>
</blockquote>
<p>Generalisation is about performance on <strong>unseen cases</strong>,<br>
<em>after</em> modelling choices are made.</p>
<hr>
</section>
</section>
<section id="d6.1-creating-train-validation-test-splits" class="level2">
<h2 class="anchored" data-anchor-id="d6.1-creating-train-validation-test-splits">D6.1 Creating Train / Validation / Test Splits</h2>
<p>We now repeat the evaluation using <strong>held-out data</strong>.</p>
<p>At this stage: - we do <strong>not</strong> tune hyperparameters, - we do <strong>not</strong> optimise metrics, - we only observe how behaviour changes across roles.</p>
<p>The goal is to understand <em>why</em> splits exist — not to maximise scores.</p>
<hr>
<section id="r-splitting-the-data" class="level3">
<h3 class="anchored" data-anchor-id="r-splitting-the-data">R: Splitting the Data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb38"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb38-1"><a href="#cb38-1" aria-hidden="true" tabindex="-1"></a><span class="fu">set.seed</span>(<span class="dv">42</span>)</span>
<span id="cb38-2"><a href="#cb38-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-3"><a href="#cb38-3" aria-hidden="true" tabindex="-1"></a>n <span class="ot">&lt;-</span> <span class="fu">nrow</span>(model_data)</span>
<span id="cb38-4"><a href="#cb38-4" aria-hidden="true" tabindex="-1"></a>idx <span class="ot">&lt;-</span> <span class="fu">sample</span>(n)</span>
<span id="cb38-5"><a href="#cb38-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-6"><a href="#cb38-6" aria-hidden="true" tabindex="-1"></a>train_idx <span class="ot">&lt;-</span> idx[<span class="dv">1</span><span class="sc">:</span><span class="fu">floor</span>(<span class="fl">0.6</span> <span class="sc">*</span> n)]</span>
<span id="cb38-7"><a href="#cb38-7" aria-hidden="true" tabindex="-1"></a>val_idx   <span class="ot">&lt;-</span> idx[(<span class="fu">floor</span>(<span class="fl">0.6</span> <span class="sc">*</span> n) <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span><span class="fu">floor</span>(<span class="fl">0.8</span> <span class="sc">*</span> n)]</span>
<span id="cb38-8"><a href="#cb38-8" aria-hidden="true" tabindex="-1"></a>test_idx  <span class="ot">&lt;-</span> idx[(<span class="fu">floor</span>(<span class="fl">0.8</span> <span class="sc">*</span> n) <span class="sc">+</span> <span class="dv">1</span>)<span class="sc">:</span>n]</span>
<span id="cb38-9"><a href="#cb38-9" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb38-10"><a href="#cb38-10" aria-hidden="true" tabindex="-1"></a>train_data <span class="ot">&lt;-</span> model_data[train_idx, ]</span>
<span id="cb38-11"><a href="#cb38-11" aria-hidden="true" tabindex="-1"></a>val_data   <span class="ot">&lt;-</span> model_data[val_idx, ]</span>
<span id="cb38-12"><a href="#cb38-12" aria-hidden="true" tabindex="-1"></a>test_data  <span class="ot">&lt;-</span> model_data[test_idx, ]</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-16-contents" aria-controls="callout-16" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-16" class="callout-16-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Randomly shuffles observations.</li>
<li>Assigns <strong>roles</strong> to data: training, validation, test.</li>
<li>Fixes randomness for reproducibility.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Validation data may influence decisions.</li>
<li>Test data must <strong>not</strong> influence decisions.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python-splitting-the-data" class="level3">
<h3 class="anchored" data-anchor-id="python-splitting-the-data">Python: Splitting the Data</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb39"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb39-1"><a href="#cb39-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.model_selection <span class="im">import</span> train_test_split</span>
<span id="cb39-2"><a href="#cb39-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-3"><a href="#cb39-3" aria-hidden="true" tabindex="-1"></a>X_train, X_temp, y_train, y_temp <span class="op">=</span> train_test_split(</span>
<span id="cb39-4"><a href="#cb39-4" aria-hidden="true" tabindex="-1"></a>    X, y, test_size<span class="op">=</span><span class="fl">0.4</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y</span>
<span id="cb39-5"><a href="#cb39-5" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb39-6"><a href="#cb39-6" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb39-7"><a href="#cb39-7" aria-hidden="true" tabindex="-1"></a>X_val, X_test, y_val, y_test <span class="op">=</span> train_test_split(</span>
<span id="cb39-8"><a href="#cb39-8" aria-hidden="true" tabindex="-1"></a>    X_temp, y_temp, test_size<span class="op">=</span><span class="fl">0.5</span>, random_state<span class="op">=</span><span class="dv">42</span>, stratify<span class="op">=</span>y_temp</span>
<span id="cb39-9"><a href="#cb39-9" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-17-contents" aria-controls="callout-17" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-17" class="callout-17-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Splits data into training, validation, and test sets.</li>
<li>Uses stratification to preserve class balance.</li>
<li>Makes the separation between <em>decision</em> and <em>evaluation</em> explicit.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Once validation is used to guide choices, it is no longer independent.</li>
<li>The test set remains untouched.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="d6.2-re-training-models-on-the-training-set" class="level2">
<h2 class="anchored" data-anchor-id="d6.2-re-training-models-on-the-training-set">D6.2 Re-training Models on the Training Set</h2>
<p>We now train the same models <strong>using only the training data</strong>.</p>
<p>This mirrors real workflows:</p>
<ul>
<li>models learn from training data,</li>
<li>validation informs judgement,</li>
<li>test is held back.</li>
</ul>
<hr>
<section id="r-re-training-models" class="level3">
<h3 class="anchored" data-anchor-id="r-re-training-models">R: Re-training Models</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb40"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb40-1"><a href="#cb40-1" aria-hidden="true" tabindex="-1"></a>tree_tr <span class="ot">&lt;-</span> <span class="fu">rpart</span>(</span>
<span id="cb40-2"><a href="#cb40-2" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb40-3"><a href="#cb40-3" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb40-4"><a href="#cb40-4" aria-hidden="true" tabindex="-1"></a>  <span class="at">method =</span> <span class="st">"class"</span>,</span>
<span id="cb40-5"><a href="#cb40-5" aria-hidden="true" tabindex="-1"></a>  <span class="at">control =</span> <span class="fu">rpart.control</span>(<span class="at">maxdepth =</span> <span class="dv">3</span>)</span>
<span id="cb40-6"><a href="#cb40-6" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-7"><a href="#cb40-7" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-8"><a href="#cb40-8" aria-hidden="true" tabindex="-1"></a>rf_tr <span class="ot">&lt;-</span> <span class="fu">randomForest</span>(</span>
<span id="cb40-9"><a href="#cb40-9" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb40-10"><a href="#cb40-10" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data,</span>
<span id="cb40-11"><a href="#cb40-11" aria-hidden="true" tabindex="-1"></a>  <span class="at">ntree =</span> <span class="dv">200</span></span>
<span id="cb40-12"><a href="#cb40-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-13"><a href="#cb40-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-14"><a href="#cb40-14" aria-hidden="true" tabindex="-1"></a><span class="co"># Prepare training data for GBM</span></span>
<span id="cb40-15"><a href="#cb40-15" aria-hidden="true" tabindex="-1"></a>train_data_gbm <span class="ot">&lt;-</span> train_data</span>
<span id="cb40-16"><a href="#cb40-16" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-17"><a href="#cb40-17" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert character predictors to factors</span></span>
<span id="cb40-18"><a href="#cb40-18" aria-hidden="true" tabindex="-1"></a>train_data_gbm[] <span class="ot">&lt;-</span> <span class="fu">lapply</span>(</span>
<span id="cb40-19"><a href="#cb40-19" aria-hidden="true" tabindex="-1"></a>  train_data_gbm,</span>
<span id="cb40-20"><a href="#cb40-20" aria-hidden="true" tabindex="-1"></a>  <span class="cf">function</span>(x) <span class="cf">if</span> (<span class="fu">is.character</span>(x)) <span class="fu">factor</span>(x) <span class="cf">else</span> x</span>
<span id="cb40-21"><a href="#cb40-21" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb40-22"><a href="#cb40-22" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-23"><a href="#cb40-23" aria-hidden="true" tabindex="-1"></a><span class="co"># Convert response to numeric 0/1 (Bernoulli requirement)</span></span>
<span id="cb40-24"><a href="#cb40-24" aria-hidden="true" tabindex="-1"></a>train_data_gbm<span class="sc">$</span>y <span class="ot">&lt;-</span> <span class="fu">as.numeric</span>(train_data_gbm<span class="sc">$</span>y) <span class="sc">-</span> <span class="dv">1</span></span>
<span id="cb40-25"><a href="#cb40-25" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb40-26"><a href="#cb40-26" aria-hidden="true" tabindex="-1"></a><span class="co"># Train GBM model</span></span>
<span id="cb40-27"><a href="#cb40-27" aria-hidden="true" tabindex="-1"></a>gb_tr <span class="ot">&lt;-</span> <span class="fu">gbm</span>(</span>
<span id="cb40-28"><a href="#cb40-28" aria-hidden="true" tabindex="-1"></a>  y <span class="sc">~</span> .,</span>
<span id="cb40-29"><a href="#cb40-29" aria-hidden="true" tabindex="-1"></a>  <span class="at">data =</span> train_data_gbm,</span>
<span id="cb40-30"><a href="#cb40-30" aria-hidden="true" tabindex="-1"></a>  <span class="at">distribution =</span> <span class="st">"bernoulli"</span>,</span>
<span id="cb40-31"><a href="#cb40-31" aria-hidden="true" tabindex="-1"></a>  <span class="at">n.trees =</span> <span class="dv">200</span>,</span>
<span id="cb40-32"><a href="#cb40-32" aria-hidden="true" tabindex="-1"></a>  <span class="at">interaction.depth =</span> <span class="dv">3</span>,</span>
<span id="cb40-33"><a href="#cb40-33" aria-hidden="true" tabindex="-1"></a>  <span class="at">shrinkage =</span> <span class="fl">0.01</span>,</span>
<span id="cb40-34"><a href="#cb40-34" aria-hidden="true" tabindex="-1"></a>  <span class="at">verbose =</span> <span class="cn">FALSE</span></span>
<span id="cb40-35"><a href="#cb40-35" aria-hidden="true" tabindex="-1"></a>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
</div>
<hr>
</section>
<section id="python-re-training-models" class="level3">
<h3 class="anchored" data-anchor-id="python-re-training-models">Python: Re-training Models</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb41"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb41-1"><a href="#cb41-1" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.pipeline <span class="im">import</span> Pipeline</span>
<span id="cb41-2"><a href="#cb41-2" aria-hidden="true" tabindex="-1"></a><span class="im">from</span> sklearn.tree <span class="im">import</span> DecisionTreeClassifier</span>
<span id="cb41-3"><a href="#cb41-3" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-4"><a href="#cb41-4" aria-hidden="true" tabindex="-1"></a>tree_tr <span class="op">=</span> Pipeline(</span>
<span id="cb41-5"><a href="#cb41-5" aria-hidden="true" tabindex="-1"></a>    steps<span class="op">=</span>[</span>
<span id="cb41-6"><a href="#cb41-6" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"prep"</span>, preprocess),</span>
<span id="cb41-7"><a href="#cb41-7" aria-hidden="true" tabindex="-1"></a>        (<span class="st">"tree"</span>, DecisionTreeClassifier(</span>
<span id="cb41-8"><a href="#cb41-8" aria-hidden="true" tabindex="-1"></a>            max_depth<span class="op">=</span><span class="dv">3</span>,</span>
<span id="cb41-9"><a href="#cb41-9" aria-hidden="true" tabindex="-1"></a>            random_state<span class="op">=</span><span class="dv">42</span></span>
<span id="cb41-10"><a href="#cb41-10" aria-hidden="true" tabindex="-1"></a>        )),</span>
<span id="cb41-11"><a href="#cb41-11" aria-hidden="true" tabindex="-1"></a>    ]</span>
<span id="cb41-12"><a href="#cb41-12" aria-hidden="true" tabindex="-1"></a>)</span>
<span id="cb41-13"><a href="#cb41-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb41-14"><a href="#cb41-14" aria-hidden="true" tabindex="-1"></a>tree_tr.fit(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<style>#sk-container-id-4 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: #000;
  --sklearn-color-text-muted: #666;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;
}

#sk-container-id-4.light {
  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: black;
  --sklearn-color-background: white;
  --sklearn-color-border-box: black;
  --sklearn-color-icon: #696969;
}

#sk-container-id-4.dark {
  --sklearn-color-text-on-default-background: white;
  --sklearn-color-background: #111;
  --sklearn-color-border-box: white;
  --sklearn-color-icon: #878787;
}

#sk-container-id-4 {
  color: var(--sklearn-color-text);
}

#sk-container-id-4 pre {
  padding: 0;
}

#sk-container-id-4 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-4 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-4 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-4 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-4 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-4 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-4 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-4 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-4 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-4 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-4 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-4 label.sk-toggleable__label {
  cursor: pointer;
  display: flex;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
  align-items: center;
  justify-content: center;
  gap: 0.5em;
}

#sk-container-id-4 label.sk-toggleable__label .caption {
  font-size: 0.6rem;
  font-weight: lighter;
  color: var(--sklearn-color-text-muted);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-4 div.sk-toggleable__content {
  display: none;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  display: block;
  width: 100%;
  overflow: visible;
}

#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-4 div.sk-label label.sk-toggleable__label,
#sk-container-id-4 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-4 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-4 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  line-height: 1.2em;
}

#sk-container-id-4 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-4 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-4 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-4 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-4 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 0.5em;
  text-align: center;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-3) 1pt solid;
  color: var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3) 1pt solid;
  color: var(--sklearn-color-fitted-level-3);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-unfitted-level-0);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  border: var(--sklearn-color-fitted-level-0) 1pt solid;
  color: var(--sklearn-color-fitted-level-0);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-4 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-unfitted-level-0);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-4 a.estimator_doc_link.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-4 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-4 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}

.estimator-table {
    font-family: monospace;
}

.estimator-table summary {
    padding: .5rem;
    cursor: pointer;
}

.estimator-table summary::marker {
    font-size: 0.7rem;
}

.estimator-table details[open] {
    padding-left: 0.1rem;
    padding-right: 0.1rem;
    padding-bottom: 0.3rem;
}

.estimator-table .parameters-table {
    margin-left: auto !important;
    margin-right: auto !important;
    margin-top: 0;
}

.estimator-table .parameters-table tr:nth-child(odd) {
    background-color: #fff;
}

.estimator-table .parameters-table tr:nth-child(even) {
    background-color: #f6f6f6;
}

.estimator-table .parameters-table tr:hover {
    background-color: #e0e0e0;
}

.estimator-table table td {
    border: 1px solid rgba(106, 105, 104, 0.232);
}

/*
    `table td`is set in notebook with right text-align.
    We need to overwrite it.
*/
.estimator-table table td.param {
    text-align: left;
    position: relative;
    padding: 0;
}

.user-set td {
    color:rgb(255, 94, 0);
    text-align: left !important;
}

.user-set td.value {
    color:rgb(255, 94, 0);
    background-color: transparent;
}

.default td {
    color: black;
    text-align: left !important;
}

.user-set td i,
.default td i {
    color: black;
}

/*
    Styles for parameter documentation links
    We need styling for visited so jupyter doesn't overwrite it
*/
a.param-doc-link,
a.param-doc-link:link,
a.param-doc-link:visited {
    text-decoration: underline dashed;
    text-underline-offset: .3em;
    color: inherit;
    display: block;
    padding: .5em;
}

/* "hack" to make the entire area of the cell containing the link clickable */
a.param-doc-link::before {
    position: absolute;
    content: "";
    inset: 0;
}

.param-doc-description {
    display: none;
    position: absolute;
    z-index: 9999;
    left: 0;
    padding: .5ex;
    margin-left: 1.5em;
    color: var(--sklearn-color-text);
    box-shadow: .3em .3em .4em #999;
    width: max-content;
    text-align: left;
    max-height: 10em;
    overflow-y: auto;

    /* unfitted */
    background: var(--sklearn-color-unfitted-level-0);
    border: thin solid var(--sklearn-color-unfitted-level-3);
}

/* Fitted state for parameter tooltips */
.fitted .param-doc-description {
    /* fitted */
    background: var(--sklearn-color-fitted-level-0);
    border: thin solid var(--sklearn-color-fitted-level-3);
}

.param-doc-link:hover .param-doc-description {
    display: block;
}

.copy-paste-icon {
    background-image: url(data:image/svg+xml;base64,PHN2ZyB4bWxucz0iaHR0cDovL3d3dy53My5vcmcvMjAwMC9zdmciIHZpZXdCb3g9IjAgMCA0NDggNTEyIj48IS0tIUZvbnQgQXdlc29tZSBGcmVlIDYuNy4yIGJ5IEBmb250YXdlc29tZSAtIGh0dHBzOi8vZm9udGF3ZXNvbWUuY29tIExpY2Vuc2UgLSBodHRwczovL2ZvbnRhd2Vzb21lLmNvbS9saWNlbnNlL2ZyZWUgQ29weXJpZ2h0IDIwMjUgRm9udGljb25zLCBJbmMuLS0+PHBhdGggZD0iTTIwOCAwTDMzMi4xIDBjMTIuNyAwIDI0LjkgNS4xIDMzLjkgMTQuMWw2Ny45IDY3LjljOSA5IDE0LjEgMjEuMiAxNC4xIDMzLjlMNDQ4IDMzNmMwIDI2LjUtMjEuNSA0OC00OCA0OGwtMTkyIDBjLTI2LjUgMC00OC0yMS41LTQ4LTQ4bDAtMjg4YzAtMjYuNSAyMS41LTQ4IDQ4LTQ4ek00OCAxMjhsODAgMCAwIDY0LTY0IDAgMCAyNTYgMTkyIDAgMC0zMiA2NCAwIDAgNDhjMCAyNi41LTIxLjUgNDgtNDggNDhMNDggNTEyYy0yNi41IDAtNDgtMjEuNS00OC00OEwwIDE3NmMwLTI2LjUgMjEuNS00OCA0OC00OHoiLz48L3N2Zz4=);
    background-repeat: no-repeat;
    background-size: 14px 14px;
    background-position: 0;
    display: inline-block;
    width: 14px;
    height: 14px;
    cursor: pointer;
}
</style><div id="sk-container-id-4" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>Pipeline(steps=[('prep',
                 ColumnTransformer(transformers=[('num', 'passthrough',
                                                  Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')),
                                                 ('cat',
                                                  OneHotEncoder(handle_unknown='ignore'),
                                                  Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object'))])),
                ('tree', DecisionTreeClassifier(max_depth=3, random_state=42))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br>On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden=""><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-22" type="checkbox"><label for="sk-estimator-id-22" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>Pipeline</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html">?<span>Documentation for Pipeline</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></div></label><div class="sk-toggleable__content fitted" data-param-prefix="">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=steps,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">steps <span class="param-doc-description">steps: list of tuples<br>
<br>
List of (name of step, estimator) tuples that are to be chained in<br>
sequential order. To be compatible with the scikit-learn API, all steps<br>
must define `fit`. All non-last steps must also define `transform`. See<br>
:ref:`Combining Estimators <combining_estimators>` for more details.</combining_estimators></span></a></td>
<td class="value">[('prep', ...), ('tree', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=transform_input,-list%20of%20str%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transform_input <span class="param-doc-description">transform_input: list of str, default=None<br>
<br>
The names of the :term:`metadata` parameters that should be transformed by the<br>
pipeline before passing it to the step consuming it.<br>
<br>
This enables transforming some input arguments to ``fit`` (other than ``X``)<br>
to be transformed by the steps of the pipeline up to the step which requires<br>
them. Requirement is defined via :ref:`metadata routing <metadata_routing>`.<br>
For instance, this can be used to pass a validation set through the pipeline.<br>
<br>
You can only set this if metadata routing is enabled, which you<br>
can enable using ``sklearn.set_config(enable_metadata_routing=True)``.<br>
<br>
.. versionadded:: 1.6</metadata_routing></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=memory,-str%20or%20object%20with%20the%20joblib.Memory%20interface%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">memory <span class="param-doc-description">memory: str or object with the joblib.Memory interface, default=None<br>
<br>
Used to cache the fitted transformers of the pipeline. The last step<br>
will never be cached, even if it is a transformer. By default, no<br>
caching is performed. If a string is given, it is the path to the<br>
caching directory. Enabling caching triggers a clone of the transformers<br>
before fitting. Therefore, the transformer instance given to the<br>
pipeline cannot be inspected directly. Use the attribute ``named_steps``<br>
or ``steps`` to inspect estimators within the pipeline. Caching the<br>
transformers is advantageous when fitting is time consuming. See<br>
:ref:`sphx_glr_auto_examples_neighbors_plot_caching_nearest_neighbors.py`<br>
for an example on how to enable caching.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.pipeline.Pipeline.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each step will be printed as it<br>
is completed.</span></a></td>
<td class="value">False</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-serial"><div class="sk-item sk-dashed-wrapped"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-23" type="checkbox"><label for="sk-estimator-id-23" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>prep: ColumnTransformer</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html">?<span>Documentation for prep: ColumnTransformer</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformers,-list%20of%20tuples" class="param-doc-link" rel="noreferrer" target="_blank">transformers <span class="param-doc-description">transformers: list of tuples<br>
<br>
List of (name, transformer, columns) tuples specifying the<br>
transformer objects to be applied to subsets of the data.<br>
<br>
name : str<br>
Like in Pipeline and FeatureUnion, this allows the transformer and<br>
its parameters to be set using ``set_params`` and searched in grid<br>
search.<br>
transformer : {'drop', 'passthrough'} or estimator<br>
Estimator must support :term:`fit` and :term:`transform`.<br>
Special-cased strings 'drop' and 'passthrough' are accepted as<br>
well, to indicate to drop the columns or to pass them through<br>
untransformed, respectively.<br>
columns : str, array-like of str, int, array-like of int, array-like of bool, slice or callable<br>
Indexes the data on its second axis. Integers are interpreted as<br>
positional columns, while strings can reference DataFrame columns<br>
by name. A scalar string or int should be used where<br>
``transformer`` expects X to be a 1d array-like (vector),<br>
otherwise a 2d array will be passed to the transformer.<br>
A callable is passed the input data `X` and can return any of the<br>
above. To select multiple columns by name or dtype, you can use<br>
:obj:`make_column_selector`.</span></a></td>
<td class="value">[('num', ...), ('cat', ...)]</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=remainder,-%7B%27drop%27%2C%20%27passthrough%27%7D%20or%20estimator%2C%20default%3D%27drop%27" class="param-doc-link" rel="noreferrer" target="_blank">remainder <span class="param-doc-description">remainder: {'drop', 'passthrough'} or estimator, default='drop'<br>
<br>
By default, only the specified columns in `transformers` are<br>
transformed and combined in the output, and the non-specified<br>
columns are dropped. (default of ``'drop'``).<br>
By specifying ``remainder='passthrough'``, all remaining columns that<br>
were not specified in `transformers`, but present in the data passed<br>
to `fit` will be automatically passed through. This subset of columns<br>
is concatenated with the output of the transformers. For dataframes,<br>
extra columns not seen during `fit` will be excluded from the output<br>
of `transform`.<br>
By setting ``remainder`` to be an estimator, the remaining<br>
non-specified columns will use the ``remainder`` estimator. The<br>
estimator must support :term:`fit` and :term:`transform`.<br>
Note that using this feature requires that the DataFrame columns<br>
input at :term:`fit` and :term:`transform` have identical order.</span></a></td>
<td class="value">'drop'</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=sparse_threshold,-float%2C%20default%3D0.3" class="param-doc-link" rel="noreferrer" target="_blank">sparse_threshold <span class="param-doc-description">sparse_threshold: float, default=0.3<br>
<br>
If the output of the different transformers contains sparse matrices,<br>
these will be stacked as a sparse matrix if the overall density is<br>
lower than this value. Use ``sparse_threshold=0`` to always return<br>
dense. When the transformed output consists of all dense data, the<br>
stacked result will be dense, and this keyword will be ignored.</span></a></td>
<td class="value">0.3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=n_jobs,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">n_jobs <span class="param-doc-description">n_jobs: int, default=None<br>
<br>
Number of jobs to run in parallel.<br>
``None`` means 1 unless in a :obj:`joblib.parallel_backend` context.<br>
``-1`` means using all processors. See :term:`Glossary <n_jobs>`<br>
for more details.</n_jobs></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=transformer_weights,-dict%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">transformer_weights <span class="param-doc-description">transformer_weights: dict, default=None<br>
<br>
Multiplicative weights for features per transformer. The output of the<br>
transformer is multiplied by these weights. Keys are transformer names,<br>
values the weights.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">verbose <span class="param-doc-description">verbose: bool, default=False<br>
<br>
If True, the time elapsed while fitting each transformer will be<br>
printed as it is completed.</span></a></td>
<td class="value">False</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=verbose_feature_names_out,-bool%2C%20str%20or%20Callable%5B%5Bstr%2C%20str%5D%2C%20str%5D%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">verbose_feature_names_out <span class="param-doc-description">verbose_feature_names_out: bool, str or Callable[[str, str], str], default=True<br>
<br>
- If True, :meth:`ColumnTransformer.get_feature_names_out` will prefix<br>
all feature names with the name of the transformer that generated that<br>
feature. It is equivalent to setting<br>
`verbose_feature_names_out="{transformer_name}__{feature_name}"`.<br>
- If False, :meth:`ColumnTransformer.get_feature_names_out` will not<br>
prefix any feature names and will error if feature names are not<br>
unique.<br>
- If ``Callable[[str, str], str]``,<br>
:meth:`ColumnTransformer.get_feature_names_out` will rename all the features<br>
using the name of the transformer. The first argument of the callable is the<br>
transformer name and the second argument is the feature name. The returned<br>
string will be the new feature name.<br>
- If ``str``, it must be a string ready for formatting. The given string will<br>
be formatted using two field names: ``transformer_name`` and ``feature_name``.<br>
e.g. ``"{feature_name}__{transformer_name}"``. See :meth:`str.format` method<br>
from the standard library for more info.<br>
<br>
.. versionadded:: 1.0<br>
<br>
.. versionchanged:: 1.6<br>
`verbose_feature_names_out` can be a callable or a string to be formatted.</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.compose.ColumnTransformer.html#:~:text=force_int_remainder_cols,-bool%2C%20default%3DFalse" class="param-doc-link" rel="noreferrer" target="_blank">force_int_remainder_cols <span class="param-doc-description">force_int_remainder_cols: bool, default=False<br>
<br>
This parameter has no effect.<br>
<br>
.. note::<br>
If you do not access the list of columns for the remainder columns<br>
in the `transformers_` fitted attribute, you do not need to set<br>
this parameter.<br>
<br>
.. versionadded:: 1.5<br>
<br>
.. versionchanged:: 1.7<br>
The default value for `force_int_remainder_cols` will change from<br>
`True` to `False` in version 1.7.<br>
<br>
.. deprecated:: 1.7<br>
`force_int_remainder_cols` is deprecated and will be removed in 1.9.</span></a></td>
<td class="value">'deprecated'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div><div class="sk-parallel"><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-24" type="checkbox"><label for="sk-estimator-id-24" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>num</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>Index(['age', 'campaign', 'pdays', 'previous', 'emp.var.rate',
       'cons.price.idx', 'cons.conf.idx', 'euribor3m', 'nr.employed'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-25" type="checkbox"><label for="sk-estimator-id-25" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>passthrough</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__num__"><pre>passthrough</pre></div></div></div></div></div></div><div class="sk-parallel-item"><div class="sk-item"><div class="sk-label-container"><div class="sk-label fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-26" type="checkbox"><label for="sk-estimator-id-26" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>cat</div></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__"><pre>Index(['job', 'marital', 'education', 'default', 'housing', 'loan', 'contact',
       'month', 'day_of_week', 'poutcome'],
      dtype='object')</pre></div></div></div><div class="sk-serial"><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-27" type="checkbox"><label for="sk-estimator-id-27" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>OneHotEncoder</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html">?<span>Documentation for OneHotEncoder</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="prep__cat__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=categories,-%27auto%27%20or%20a%20list%20of%20array-like%2C%20default%3D%27auto%27" class="param-doc-link" rel="noreferrer" target="_blank">categories <span class="param-doc-description">categories: 'auto' or a list of array-like, default='auto'<br>
<br>
Categories (unique values) per feature:<br>
<br>
- 'auto' : Determine categories automatically from the training data.<br>
- list : ``categories[i]`` holds the categories expected in the ith<br>
column. The passed categories should not mix strings and numeric<br>
values within a single feature, and should be sorted in case of<br>
numeric values.<br>
<br>
The used categories can be found in the ``categories_`` attribute.<br>
<br>
.. versionadded:: 0.20</span></a></td>
<td class="value">'auto'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=drop,-%7B%27first%27%2C%20%27if_binary%27%7D%20or%20an%20array-like%20of%20shape%20%28n_features%2C%29%2C%20%20%20%20%20%20%20%20%20%20%20%20%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">drop <span class="param-doc-description">drop: {'first', 'if_binary'} or an array-like of shape (n_features,), default=None<br>
<br>
Specifies a methodology to use to drop one of the categories per<br>
feature. This is useful in situations where perfectly collinear<br>
features cause problems, such as when feeding the resulting data<br>
into an unregularized linear regression model.<br>
<br>
However, dropping one category breaks the symmetry of the original<br>
representation and can therefore induce a bias in downstream models,<br>
for instance for penalized linear classification or regression models.<br>
<br>
- None : retain all features (the default).<br>
- 'first' : drop the first category in each feature. If only one<br>
category is present, the feature will be dropped entirely.<br>
- 'if_binary' : drop the first category in each feature with two<br>
categories. Features with 1 or more than 2 categories are<br>
left intact.<br>
- array : ``drop[i]`` is the category in feature ``X[:, i]`` that<br>
should be dropped.<br>
<br>
When `max_categories` or `min_frequency` is configured to group<br>
infrequent categories, the dropping behavior is handled after the<br>
grouping.<br>
<br>
.. versionadded:: 0.21<br>
The parameter `drop` was added in 0.21.<br>
<br>
.. versionchanged:: 0.23<br>
The option `drop='if_binary'` was added in 0.23.<br>
<br>
.. versionchanged:: 1.1<br>
Support for dropping infrequent categories.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=sparse_output,-bool%2C%20default%3DTrue" class="param-doc-link" rel="noreferrer" target="_blank">sparse_output <span class="param-doc-description">sparse_output: bool, default=True<br>
<br>
When ``True``, it returns a :class:`scipy.sparse.csr_matrix`,<br>
i.e. a sparse matrix in "Compressed Sparse Row" (CSR) format.<br>
<br>
.. versionadded:: 1.2<br>
`sparse` was renamed to `sparse_output`</span></a></td>
<td class="value">True</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=dtype,-number%20type%2C%20default%3Dnp.float64" class="param-doc-link" rel="noreferrer" target="_blank">dtype <span class="param-doc-description">dtype: number type, default=np.float64<br>
<br>
Desired dtype of output.</span></a></td>
<td class="value">&lt;class 'numpy.float64'&gt;</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=handle_unknown,-%7B%27error%27%2C%20%27ignore%27%2C%20%27infrequent_if_exist%27%2C%20%27warn%27%7D%2C%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20%20default%3D%27error%27" class="param-doc-link" rel="noreferrer" target="_blank">handle_unknown <span class="param-doc-description">handle_unknown: {'error', 'ignore', 'infrequent_if_exist', 'warn'}, default='error'<br>
<br>
Specifies the way unknown categories are handled during :meth:`transform`.<br>
<br>
- 'error' : Raise an error if an unknown category is present during transform.<br>
- 'ignore' : When an unknown category is encountered during<br>
transform, the resulting one-hot encoded columns for this feature<br>
will be all zeros. In the inverse transform, an unknown category<br>
will be denoted as None.<br>
- 'infrequent_if_exist' : When an unknown category is encountered<br>
during transform, the resulting one-hot encoded columns for this<br>
feature will map to the infrequent category if it exists. The<br>
infrequent category will be mapped to the last position in the<br>
encoding. During inverse transform, an unknown category will be<br>
mapped to the category denoted `'infrequent'` if it exists. If the<br>
`'infrequent'` category does not exist, then :meth:`transform` and<br>
:meth:`inverse_transform` will handle an unknown category as with<br>
`handle_unknown='ignore'`. Infrequent categories exist based on<br>
`min_frequency` and `max_categories`. Read more in the<br>
:ref:`User Guide <encoder_infrequent_categories>`.<br>
- 'warn' : When an unknown category is encountered during transform<br>
a warning is issued, and the encoding then proceeds as described for<br>
`handle_unknown="infrequent_if_exist"`.<br>
<br>
.. versionchanged:: 1.1<br>
`'infrequent_if_exist'` was added to automatically handle unknown<br>
categories and infrequent categories.<br>
<br>
.. versionadded:: 1.6<br>
The option `"warn"` was added in 1.6.</encoder_infrequent_categories></span></a></td>
<td class="value">'ignore'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=min_frequency,-int%20or%20float%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">min_frequency <span class="param-doc-description">min_frequency: int or float, default=None<br>
<br>
Specifies the minimum frequency below which a category will be<br>
considered infrequent.<br>
<br>
- If `int`, categories with a smaller cardinality will be considered<br>
infrequent.<br>
<br>
- If `float`, categories with a smaller cardinality than<br>
`min_frequency * n_samples` will be considered infrequent.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=max_categories,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_categories <span class="param-doc-description">max_categories: int, default=None<br>
<br>
Specifies an upper limit to the number of output features for each input<br>
feature when considering infrequent categories. If there are infrequent<br>
categories, `max_categories` includes the category representing the<br>
infrequent categories along with the frequent categories. If `None`,<br>
there is no limit to the number of output features.<br>
<br>
.. versionadded:: 1.1<br>
Read more in the :ref:`User Guide <encoder_infrequent_categories>`.</encoder_infrequent_categories></span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.preprocessing.OneHotEncoder.html#:~:text=feature_name_combiner,-%22concat%22%20or%20callable%2C%20default%3D%22concat%22" class="param-doc-link" rel="noreferrer" target="_blank">feature_name_combiner <span class="param-doc-description">feature_name_combiner: "concat" or callable, default="concat"<br>
<br>
Callable with signature `def callable(input_feature, category)` that returns a<br>
string. This is used to create feature names to be returned by<br>
:meth:`get_feature_names_out`.<br>
<br>
`"concat"` concatenates encoded feature name and category with<br>
`feature + "_" + str(category)`.E.g. feature X with values 1, 6, 7 create<br>
feature names `X_1, X_6, X_7`.<br>
<br>
.. versionadded:: 1.3</span></a></td>
<td class="value">'concat'</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div></div><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-28" type="checkbox"><label for="sk-estimator-id-28" class="sk-toggleable__label fitted sk-toggleable__label-arrow"><div><div>DecisionTreeClassifier</div></div><div><a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html">?<span>Documentation for DecisionTreeClassifier</span></a></div></label><div class="sk-toggleable__content fitted" data-param-prefix="tree__">
        <div class="estimator-table">
            <details>
                <summary>Parameters</summary>
                
<table class="parameters-table caption-top table table-sm table-striped small" data-quarto-postprocess="true">
<colgroup>
<col style="width: 33%">
<col style="width: 33%">
<col style="width: 33%">
</colgroup>
<tbody>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=criterion,-%7B%22gini%22%2C%20%22entropy%22%2C%20%22log_loss%22%7D%2C%20default%3D%22gini%22" class="param-doc-link" rel="noreferrer" target="_blank">criterion <span class="param-doc-description">criterion: {"gini", "entropy", "log_loss"}, default="gini"<br>
<br>
The function to measure the quality of a split. Supported criteria are<br>
"gini" for the Gini impurity and "log_loss" and "entropy" both for the<br>
Shannon information gain, see :ref:`tree_mathematical_formulation`.</span></a></td>
<td class="value">'gini'</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=splitter,-%7B%22best%22%2C%20%22random%22%7D%2C%20default%3D%22best%22" class="param-doc-link" rel="noreferrer" target="_blank">splitter <span class="param-doc-description">splitter: {"best", "random"}, default="best"<br>
<br>
The strategy used to choose the split at each node. Supported<br>
strategies are "best" to choose the best split and "random" to choose<br>
the best random split.</span></a></td>
<td class="value">'best'</td>
</tr>
<tr class="user-set odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_depth,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_depth <span class="param-doc-description">max_depth: int, default=None<br>
<br>
The maximum depth of the tree. If None, then nodes are expanded until<br>
all leaves are pure or until all leaves contain less than<br>
min_samples_split samples.</span></a></td>
<td class="value">3</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_split,-int%20or%20float%2C%20default%3D2" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_split <span class="param-doc-description">min_samples_split: int or float, default=2<br>
<br>
The minimum number of samples required to split an internal node:<br>
<br>
- If int, then consider `min_samples_split` as the minimum number.<br>
- If float, then `min_samples_split` is a fraction and<br>
`ceil(min_samples_split * n_samples)` are the minimum<br>
number of samples for each split.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">2</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_samples_leaf,-int%20or%20float%2C%20default%3D1" class="param-doc-link" rel="noreferrer" target="_blank">min_samples_leaf <span class="param-doc-description">min_samples_leaf: int or float, default=1<br>
<br>
The minimum number of samples required to be at a leaf node.<br>
A split point at any depth will only be considered if it leaves at<br>
least ``min_samples_leaf`` training samples in each of the left and<br>
right branches. This may have the effect of smoothing the model,<br>
especially in regression.<br>
<br>
- If int, then consider `min_samples_leaf` as the minimum number.<br>
- If float, then `min_samples_leaf` is a fraction and<br>
`ceil(min_samples_leaf * n_samples)` are the minimum<br>
number of samples for each node.<br>
<br>
.. versionchanged:: 0.18<br>
Added float values for fractions.</span></a></td>
<td class="value">1</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_weight_fraction_leaf,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_weight_fraction_leaf <span class="param-doc-description">min_weight_fraction_leaf: float, default=0.0<br>
<br>
The minimum weighted fraction of the sum total of weights (of all<br>
the input samples) required to be at a leaf node. Samples have<br>
equal weight when sample_weight is not provided.</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_features,-int%2C%20float%20or%20%7B%22sqrt%22%2C%20%22log2%22%7D%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_features <span class="param-doc-description">max_features: int, float or {"sqrt", "log2"}, default=None<br>
<br>
The number of features to consider when looking for the best split:<br>
<br>
- If int, then consider `max_features` features at each split.<br>
- If float, then `max_features` is a fraction and<br>
`max(1, int(max_features * n_features_in_))` features are considered at<br>
each split.<br>
- If "sqrt", then `max_features=sqrt(n_features)`.<br>
- If "log2", then `max_features=log2(n_features)`.<br>
- If None, then `max_features=n_features`.<br>
<br>
.. note::<br>
<br>
The search for a split does not stop until at least one<br>
valid partition of the node samples is found, even if it requires to<br>
effectively inspect more than ``max_features`` features.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="user-set even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=random_state,-int%2C%20RandomState%20instance%20or%20None%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">random_state <span class="param-doc-description">random_state: int, RandomState instance or None, default=None<br>
<br>
Controls the randomness of the estimator. The features are always<br>
randomly permuted at each split, even if ``splitter`` is set to<br>
``"best"``. When ``max_features &lt; n_features``, the algorithm will<br>
select ``max_features`` at random at each split before finding the best<br>
split among them. But the best found split may vary across different<br>
runs, even if ``max_features=n_features``. That is the case, if the<br>
improvement of the criterion is identical for several splits and one<br>
split has to be selected at random. To obtain a deterministic behaviour<br>
during fitting, ``random_state`` has to be fixed to an integer.<br>
See :term:`Glossary <random_state>` for details.</random_state></span></a></td>
<td class="value">42</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=max_leaf_nodes,-int%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">max_leaf_nodes <span class="param-doc-description">max_leaf_nodes: int, default=None<br>
<br>
Grow a tree with ``max_leaf_nodes`` in best-first fashion.<br>
Best nodes are defined as relative reduction in impurity.<br>
If None then unlimited number of leaf nodes.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=min_impurity_decrease,-float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">min_impurity_decrease <span class="param-doc-description">min_impurity_decrease: float, default=0.0<br>
<br>
A node will be split if this split induces a decrease of the impurity<br>
greater than or equal to this value.<br>
<br>
The weighted impurity decrease equation is the following::<br>
<br>
N_t / N * (impurity - N_t_R / N_t * right_impurity<br>
- N_t_L / N_t * left_impurity)<br>
<br>
where ``N`` is the total number of samples, ``N_t`` is the number of<br>
samples at the current node, ``N_t_L`` is the number of samples in the<br>
left child, and ``N_t_R`` is the number of samples in the right child.<br>
<br>
``N``, ``N_t``, ``N_t_R`` and ``N_t_L`` all refer to the weighted sum,<br>
if ``sample_weight`` is passed.<br>
<br>
.. versionadded:: 0.19</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=class_weight,-dict%2C%20list%20of%20dict%20or%20%22balanced%22%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">class_weight <span class="param-doc-description">class_weight: dict, list of dict or "balanced", default=None<br>
<br>
Weights associated with classes in the form ``{class_label: weight}``.<br>
If None, all classes are supposed to have weight one. For<br>
multi-output problems, a list of dicts can be provided in the same<br>
order as the columns of y.<br>
<br>
Note that for multioutput (including multilabel) weights should be<br>
defined for each class of every column in its own dict. For example,<br>
for four-class multilabel classification weights should be<br>
[{0: 1, 1: 1}, {0: 1, 1: 5}, {0: 1, 1: 1}, {0: 1, 1: 1}] instead of<br>
[{1:1}, {2:5}, {3:1}, {4:1}].<br>
<br>
The "balanced" mode uses the values of y to automatically adjust<br>
weights inversely proportional to class frequencies in the input data<br>
as ``n_samples / (n_classes * np.bincount(y))``<br>
<br>
For multi-output, the weights of each column of y will be multiplied.<br>
<br>
Note that these weights will be multiplied with sample_weight (passed<br>
through the fit method) if sample_weight is specified.</span></a></td>
<td class="value">None</td>
</tr>
<tr class="default even">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=ccp_alpha,-non-negative%20float%2C%20default%3D0.0" class="param-doc-link" rel="noreferrer" target="_blank">ccp_alpha <span class="param-doc-description">ccp_alpha: non-negative float, default=0.0<br>
<br>
Complexity parameter used for Minimal Cost-Complexity Pruning. The<br>
subtree with the largest cost complexity that is smaller than<br>
``ccp_alpha`` will be chosen. By default, no pruning is performed. See<br>
:ref:`minimal_cost_complexity_pruning` for details. See<br>
:ref:`sphx_glr_auto_examples_tree_plot_cost_complexity_pruning.py`<br>
for an example of such pruning.<br>
<br>
.. versionadded:: 0.22</span></a></td>
<td class="value">0.0</td>
</tr>
<tr class="default odd">
<td><em></em></td>
<td class="param"><a href="https://scikit-learn.org/1.8/modules/generated/sklearn.tree.DecisionTreeClassifier.html#:~:text=monotonic_cst,-array-like%20of%20int%20of%20shape%20%28n_features%29%2C%20default%3DNone" class="param-doc-link" rel="noreferrer" target="_blank">monotonic_cst <span class="param-doc-description">monotonic_cst: array-like of int of shape (n_features), default=None<br>
<br>
Indicates the monotonicity constraint to enforce on each feature.<br>
- 1: monotonic increase<br>
- 0: no constraint<br>
- -1: monotonic decrease<br>
<br>
If monotonic_cst is None, no constraints are applied.<br>
<br>
Monotonicity constraints are not supported for:<br>
- multiclass classifications (i.e. when `n_classes &gt; 2`),<br>
- multioutput classifications (i.e. when `n_outputs_ &gt; 1`),<br>
- classifications trained on data with missing values.<br>
<br>
The constraints hold over the probability of the positive class.<br>
<br>
Read more in the :ref:`User Guide <monotonic_cst_gbdt>`.<br>
<br>
.. versionadded:: 1.4</monotonic_cst_gbdt></span></a></td>
<td class="value">None</td>
</tr>
</tbody>
</table>

            </details>
        </div>
    </div></div></div></div></div></div></div><script>function copyToClipboard(text, element) {
    // Get the parameter prefix from the closest toggleable content
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const fullParamName = paramPrefix ? `${paramPrefix}${text}` : text;

    const originalStyle = element.style;
    const computedStyle = window.getComputedStyle(element);
    const originalWidth = computedStyle.width;
    const originalHTML = element.innerHTML.replace('Copied!', '');

    navigator.clipboard.writeText(fullParamName)
        .then(() => {
            element.style.width = originalWidth;
            element.style.color = 'green';
            element.innerHTML = "Copied!";

            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        })
        .catch(err => {
            console.error('Failed to copy:', err);
            element.style.color = 'red';
            element.innerHTML = "Failed!";
            setTimeout(() => {
                element.innerHTML = originalHTML;
                element.style = originalStyle;
            }, 2000);
        });
    return false;
}

document.querySelectorAll('.copy-paste-icon').forEach(function(element) {
    const toggleableContent = element.closest('.sk-toggleable__content');
    const paramPrefix = toggleableContent ? toggleableContent.dataset.paramPrefix : '';
    const paramName = element.parentElement.nextElementSibling
        .textContent.trim().split(' ')[0];
    const fullParamName = paramPrefix ? `${paramPrefix}${paramName}` : paramName;

    element.setAttribute('title', fullParamName);
});


/**
 * Adapted from Skrub
 * https://github.com/skrub-data/skrub/blob/403466d1d5d4dc76a7ef569b3f8228db59a31dc3/skrub/_reporting/_data/templates/report.js#L789
 * @returns "light" or "dark"
 */
function detectTheme(element) {
    const body = document.querySelector('body');

    // Check VSCode theme
    const themeKindAttr = body.getAttribute('data-vscode-theme-kind');
    const themeNameAttr = body.getAttribute('data-vscode-theme-name');

    if (themeKindAttr && themeNameAttr) {
        const themeKind = themeKindAttr.toLowerCase();
        const themeName = themeNameAttr.toLowerCase();

        if (themeKind.includes("dark") || themeName.includes("dark")) {
            return "dark";
        }
        if (themeKind.includes("light") || themeName.includes("light")) {
            return "light";
        }
    }

    // Check Jupyter theme
    if (body.getAttribute('data-jp-theme-light') === 'false') {
        return 'dark';
    } else if (body.getAttribute('data-jp-theme-light') === 'true') {
        return 'light';
    }

    // Guess based on a parent element's color
    const color = window.getComputedStyle(element.parentNode, null).getPropertyValue('color');
    const match = color.match(/^rgb\s*\(\s*(\d+)\s*,\s*(\d+)\s*,\s*(\d+)\s*\)\s*$/i);
    if (match) {
        const [r, g, b] = [
            parseFloat(match[1]),
            parseFloat(match[2]),
            parseFloat(match[3])
        ];

        // https://en.wikipedia.org/wiki/HSL_and_HSV#Lightness
        const luma = 0.299 * r + 0.587 * g + 0.114 * b;

        if (luma > 180) {
            // If the text is very bright we have a dark theme
            return 'dark';
        }
        if (luma < 75) {
            // If the text is very dark we have a light theme
            return 'light';
        }
        // Otherwise fall back to the next heuristic.
    }

    // Fallback to system preference
    return window.matchMedia('(prefers-color-scheme: dark)').matches ? 'dark' : 'light';
}


function forceTheme(elementId) {
    const estimatorElement = document.querySelector(`#${elementId}`);
    if (estimatorElement === null) {
        console.error(`Element with id ${elementId} not found.`);
    } else {
        const theme = detectTheme(estimatorElement);
        estimatorElement.classList.add(theme);
    }
}

forceTheme('sk-container-id-4');</script>
</div>
</div>
<hr>
</section>
</section>
<section id="d6.3-comparing-behaviour-across-roles" class="level2">
<h2 class="anchored" data-anchor-id="d6.3-comparing-behaviour-across-roles">D6.3 Comparing Behaviour Across Roles</h2>
<p>We now compare <strong>training vs validation accuracy</strong> for all three model families.</p>
<p>The purpose is not to rank models, but to observe how complexity affects generalisation.</p>
<hr>
<section id="r-2" class="level3">
<h3 class="anchored" data-anchor-id="r-2">R</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb42"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb42-1"><a href="#cb42-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision tree</span></span>
<span id="cb42-2"><a href="#cb42-2" aria-hidden="true" tabindex="-1"></a>tree_train_acc <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(tree_tr, train_data, <span class="at">type=</span><span class="st">"class"</span>) <span class="sc">==</span> train_data<span class="sc">$</span>y)</span>
<span id="cb42-3"><a href="#cb42-3" aria-hidden="true" tabindex="-1"></a>tree_val_acc   <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(tree_tr, val_data, <span class="at">type=</span><span class="st">"class"</span>) <span class="sc">==</span> val_data<span class="sc">$</span>y)</span>
<span id="cb42-4"><a href="#cb42-4" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-5"><a href="#cb42-5" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest</span></span>
<span id="cb42-6"><a href="#cb42-6" aria-hidden="true" tabindex="-1"></a>rf_train_acc <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(rf_tr, train_data) <span class="sc">==</span> train_data<span class="sc">$</span>y)</span>
<span id="cb42-7"><a href="#cb42-7" aria-hidden="true" tabindex="-1"></a>rf_val_acc   <span class="ot">&lt;-</span> <span class="fu">mean</span>(<span class="fu">predict</span>(rf_tr, val_data) <span class="sc">==</span> val_data<span class="sc">$</span>y)</span>
<span id="cb42-8"><a href="#cb42-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-9"><a href="#cb42-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient boosting</span></span>
<span id="cb42-10"><a href="#cb42-10" aria-hidden="true" tabindex="-1"></a>gb_train_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(gb_tr, train_data, <span class="at">n.trees=</span><span class="dv">200</span>, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb42-11"><a href="#cb42-11" aria-hidden="true" tabindex="-1"></a>gb_train_preds <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(gb_train_probs <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"yes"</span>, <span class="st">"no"</span>)</span>
<span id="cb42-12"><a href="#cb42-12" aria-hidden="true" tabindex="-1"></a>gb_train_acc   <span class="ot">&lt;-</span> <span class="fu">mean</span>(gb_train_preds <span class="sc">==</span> train_data<span class="sc">$</span>y)</span>
<span id="cb42-13"><a href="#cb42-13" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-14"><a href="#cb42-14" aria-hidden="true" tabindex="-1"></a>gb_val_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(gb_tr, val_data, <span class="at">n.trees=</span><span class="dv">200</span>, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb42-15"><a href="#cb42-15" aria-hidden="true" tabindex="-1"></a>gb_val_preds <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(gb_val_probs <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"yes"</span>, <span class="st">"no"</span>)</span>
<span id="cb42-16"><a href="#cb42-16" aria-hidden="true" tabindex="-1"></a>gb_val_acc   <span class="ot">&lt;-</span> <span class="fu">mean</span>(gb_val_preds <span class="sc">==</span> val_data<span class="sc">$</span>y)</span>
<span id="cb42-17"><a href="#cb42-17" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb42-18"><a href="#cb42-18" aria-hidden="true" tabindex="-1"></a>tree_train_acc; tree_val_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9101578</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.901699</code></pre>
</div>
<div class="sourceCode cell-code" id="cb45"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb45-1"><a href="#cb45-1" aria-hidden="true" tabindex="-1"></a>rf_train_acc;   rf_val_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9830028</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9029126</code></pre>
</div>
<div class="sourceCode cell-code" id="cb48"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb48-1"><a href="#cb48-1" aria-hidden="true" tabindex="-1"></a>gb_train_acc;   gb_val_acc</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9113719</code></pre>
</div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.9029126</code></pre>
</div>
</div>
<hr>
</section>
<section id="python-2" class="level3">
<h3 class="anchored" data-anchor-id="python-2">Python</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb51"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb51-1"><a href="#cb51-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision tree</span></span>
<span id="cb51-2"><a href="#cb51-2" aria-hidden="true" tabindex="-1"></a>tree_tr.score(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9085390530149737</code></pre>
</div>
<div class="sourceCode cell-code" id="cb53"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb53-1"><a href="#cb53-1" aria-hidden="true" tabindex="-1"></a>tree_tr.score(X_val, y_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9016990291262136</code></pre>
</div>
<div class="sourceCode cell-code" id="cb55"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb55-1"><a href="#cb55-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest</span></span>
<span id="cb55-2"><a href="#cb55-2" aria-hidden="true" tabindex="-1"></a>rf_model.score(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb57"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb57-1"><a href="#cb57-1" aria-hidden="true" tabindex="-1"></a>rf_model.score(X_val, y_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>1.0</code></pre>
</div>
<div class="sourceCode cell-code" id="cb59"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb59-1"><a href="#cb59-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient boosting</span></span>
<span id="cb59-2"><a href="#cb59-2" aria-hidden="true" tabindex="-1"></a>gb_model.score(X_train, y_train)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9376770538243626</code></pre>
</div>
<div class="sourceCode cell-code" id="cb61"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb61-1"><a href="#cb61-1" aria-hidden="true" tabindex="-1"></a>gb_model.score(X_val, y_val)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9296116504854369</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-18-contents" aria-controls="callout-18" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
How to read these numbers
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-18" class="callout-18-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>Across models, we typically observe:</p>
<ul>
<li>training accuracy increases with model complexity,</li>
<li>the train–validation gap widens for complex models,</li>
<li>ensembles often reduce this gap compared to a single tree.</li>
</ul>
<p>The <strong>gap</strong> matters more than the absolute value.</p>
<p>It tells us how much the model relies on memorisation rather than general patterns.</p>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="d6.4-a-final-check-on-the-test-set" class="level2">
<h2 class="anchored" data-anchor-id="d6.4-a-final-check-on-the-test-set">D6.4 A Final Check on the Test Set</h2>
<p>At this point, modelling decisions are fixed.</p>
<p>We now evaluate <strong>once</strong> on the test set.</p>
<p>This simulates real practice: - the test set is untouched during model design, - it provides an unbiased reference point.</p>
<section id="r-test-set-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="r-test-set-accuracy">R: Test Set Accuracy</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb63"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb63-1"><a href="#cb63-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Decision tree</span></span>
<span id="cb63-2"><a href="#cb63-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">predict</span>(tree_tr, test_data, <span class="at">type=</span><span class="st">"class"</span>) <span class="sc">==</span> test_data<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.881068</code></pre>
</div>
<div class="sourceCode cell-code" id="cb65"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb65-1"><a href="#cb65-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Random forest</span></span>
<span id="cb65-2"><a href="#cb65-2" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(<span class="fu">predict</span>(rf_tr, test_data) <span class="sc">==</span> test_data<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8798544</code></pre>
</div>
<div class="sourceCode cell-code" id="cb67"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb67-1"><a href="#cb67-1" aria-hidden="true" tabindex="-1"></a><span class="co"># Gradient boosting</span></span>
<span id="cb67-2"><a href="#cb67-2" aria-hidden="true" tabindex="-1"></a>gb_test_probs <span class="ot">&lt;-</span> <span class="fu">predict</span>(gb_tr, test_data, <span class="at">n.trees=</span><span class="dv">200</span>, <span class="at">type=</span><span class="st">"response"</span>)</span>
<span id="cb67-3"><a href="#cb67-3" aria-hidden="true" tabindex="-1"></a>gb_test_preds <span class="ot">&lt;-</span> <span class="fu">ifelse</span>(gb_test_probs <span class="sc">&gt;</span> <span class="fl">0.5</span>, <span class="st">"yes"</span>, <span class="st">"no"</span>)</span>
<span id="cb67-4"><a href="#cb67-4" aria-hidden="true" tabindex="-1"></a><span class="fu">mean</span>(gb_test_preds <span class="sc">==</span> test_data<span class="sc">$</span>y)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>[1] 0.8822816</code></pre>
</div>
</div>
</section>
<section id="python-test-set-accuracy" class="level3">
<h3 class="anchored" data-anchor-id="python-test-set-accuracy">Python: Test Set Accuracy</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb69"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb69-1"><a href="#cb69-1" aria-hidden="true" tabindex="-1"></a>tree_tr.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.8968446601941747</code></pre>
</div>
<div class="sourceCode cell-code" id="cb71"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb71-1"><a href="#cb71-1" aria-hidden="true" tabindex="-1"></a>rf_model.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.9987864077669902</code></pre>
</div>
<div class="sourceCode cell-code" id="cb73"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb73-1"><a href="#cb73-1" aria-hidden="true" tabindex="-1"></a>gb_model.score(X_test, y_test)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>0.933252427184466</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-19-contents" aria-controls="callout-19" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
Why we evaluate on the test set only once
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-19" class="callout-19-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<p>The test set is a <strong>sealed reference</strong>.</p>
<p>Once we look at it: - we should not revise models, - we should not compare alternatives, - we should not adjust thresholds.</p>
<p>If we did, the test set would lose its meaning.</p>
<p>Its purpose is confirmation — not optimisation.</p>
</div>
</div>
</div>
</section>
</section>
<section id="d6.5-whats-not-covered" class="level2">
<h2 class="anchored" data-anchor-id="d6.5-whats-not-covered">D6.5 Whats Not Covered</h2>
<p>At this point, we deliberately <strong>stop making decisions</strong>. We do <strong>not</strong>:</p>
<ul>
<li>tune hyperparameters,</li>
<li>compare further variants,</li>
<li>optimise metrics.</li>
</ul>
<hr>
<section id="key-takeaway-from-part-d6" class="level3">
<h3 class="anchored" data-anchor-id="key-takeaway-from-part-d6">Key takeaway from Part D6</h3>
<blockquote class="blockquote">
<p><strong>Training data is for learning. Validation data is for deciding. Test data is for confirming — once.</strong></p>
</blockquote>
<p>Confusing these roles is one of the most common modelling mistakes.</p>
<hr>
</section>
</section>
</section>
<section id="part-e-interpretability-understanding-model-decisions" class="level1">
<h1>Part E — Interpretability: Understanding Model Decisions</h1>
<hr>
<p>In many real-world settings:</p>
<ul>
<li>predictions affect people,</li>
<li>decisions must be justified,</li>
<li>models are audited.</li>
</ul>
<p>Accuracy alone is not sufficient.</p>
<blockquote class="blockquote">
<p><strong>Interpretability connects models back to meaning.</strong></p>
</blockquote>
<p>This echoes Week 1’s emphasis on understanding the data-generating process.</p>
<hr>
<section id="e1.-global-interpretability-which-features-matter-overall" class="level2">
<h2 class="anchored" data-anchor-id="e1.-global-interpretability-which-features-matter-overall">E1. Global Interpretability — Which Features Matter Overall?</h2>
<p>Global interpretability asks:</p>
<blockquote class="blockquote">
<p><em>Which variables influence predictions the most, on average?</em></p>
</blockquote>
<p>Tree ensembles provide <strong>feature importance</strong> measures.</p>
<hr>
<section id="r-feature-importance-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="r-feature-importance-random-forest">R: Feature Importance (Random Forest)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb75"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb75-1"><a href="#cb75-1" aria-hidden="true" tabindex="-1"></a><span class="fu">importance</span>(rf_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>                        no         yes MeanDecreaseAccuracy MeanDecreaseGini
age            12.87159607 -1.61789371           11.8962782        104.64488
job             6.02562186  0.76264374            5.9408909         54.04041
marital         4.74750736 -2.59671911            3.5526989         27.13940
education       4.78833310 -0.00946013            4.5878486         48.33564
default         1.77387451 -2.12239928            1.1449725         10.77093
housing        -0.05745128 -1.95042737           -0.8435041         20.86489
loan           -3.10961619 -2.29308046           -3.7814744         15.43300
contact         2.46068597 10.52235747            4.5809944         12.07009
month          13.57062228 -3.70291225           13.6668294         19.77309
day_of_week     3.33767612 -2.52481307            1.9337136         41.81593
campaign        2.24476079  0.15170713            2.2149330         44.32041
pdays           4.82104111 14.28165366           12.1485066         30.78187
previous        5.49012078 -0.19244248            5.0128260         17.80570
poutcome        4.19802399  8.24588361            8.1270388         27.75714
emp.var.rate   10.23273316  2.19628438           10.5551281         23.12753
cons.price.idx  8.91522770 -6.57623611            8.4430762         24.39056
cons.conf.idx  10.00325966 -2.71314503           10.2933156         29.86761
euribor3m      19.23702235 -3.92572196           20.7544872        110.75941
nr.employed     9.76703610 10.32646731           11.7172904         52.41638</code></pre>
</div>
<div class="sourceCode cell-code" id="cb77"><pre class="sourceCode r code-with-copy"><code class="sourceCode r"><span id="cb77-1"><a href="#cb77-1" aria-hidden="true" tabindex="-1"></a><span class="fu">varImpPlot</span>(rf_model)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output-display">
<div>
<figure class="figure">
<p><img src="week3_files/figure-html/unnamed-chunk-28-1.png" class="img-fluid figure-img" width="672"></p>
</figure>
</div>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-20-contents" aria-controls="callout-20" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-20" class="callout-20-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Computes how much each feature contributes to prediction.</li>
<li>Higher values indicate greater influence.</li>
<li><code>varImpPlot()</code> visualises feature importance.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Helps identify dominant variables.</li>
<li>Allows sanity checks against domain knowledge.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
<section id="python-feature-importance-random-forest" class="level3">
<h3 class="anchored" data-anchor-id="python-feature-importance-random-forest">Python: Feature Importance (Random Forest)</h3>
<div class="cell">
<div class="sourceCode cell-code" id="cb78"><pre class="sourceCode python code-with-copy"><code class="sourceCode python"><span id="cb78-1"><a href="#cb78-1" aria-hidden="true" tabindex="-1"></a><span class="im">import</span> pandas <span class="im">as</span> pd</span>
<span id="cb78-2"><a href="#cb78-2" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-3"><a href="#cb78-3" aria-hidden="true" tabindex="-1"></a><span class="co"># Get fitted preprocessing step</span></span>
<span id="cb78-4"><a href="#cb78-4" aria-hidden="true" tabindex="-1"></a>prep <span class="op">=</span> rf_model.named_steps[<span class="st">"prep"</span>]</span>
<span id="cb78-5"><a href="#cb78-5" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-6"><a href="#cb78-6" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature names after preprocessing</span></span>
<span id="cb78-7"><a href="#cb78-7" aria-hidden="true" tabindex="-1"></a>feature_names <span class="op">=</span> prep.get_feature_names_out()</span>
<span id="cb78-8"><a href="#cb78-8" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-9"><a href="#cb78-9" aria-hidden="true" tabindex="-1"></a><span class="co"># Get feature importances from the RandomForest</span></span>
<span id="cb78-10"><a href="#cb78-10" aria-hidden="true" tabindex="-1"></a>importances <span class="op">=</span> pd.Series(</span>
<span id="cb78-11"><a href="#cb78-11" aria-hidden="true" tabindex="-1"></a>    rf_model.named_steps[<span class="st">"rf"</span>].feature_importances_,</span>
<span id="cb78-12"><a href="#cb78-12" aria-hidden="true" tabindex="-1"></a>    index<span class="op">=</span>feature_names</span>
<span id="cb78-13"><a href="#cb78-13" aria-hidden="true" tabindex="-1"></a>).sort_values(ascending<span class="op">=</span><span class="va">False</span>)</span>
<span id="cb78-14"><a href="#cb78-14" aria-hidden="true" tabindex="-1"></a></span>
<span id="cb78-15"><a href="#cb78-15" aria-hidden="true" tabindex="-1"></a>importances.head(<span class="dv">10</span>)</span></code><button title="Copy to Clipboard" class="code-copy-button"><i class="bi"></i></button></pre></div>
<div class="cell-output cell-output-stdout">
<pre><code>num__age                 0.122498
num__euribor3m           0.120926
num__campaign            0.057941
num__nr.employed         0.053607
num__pdays               0.035379
num__cons.conf.idx       0.034093
num__cons.price.idx      0.028137
num__emp.var.rate        0.025986
cat__poutcome_success    0.025882
cat__housing_yes         0.019471
dtype: float64</code></pre>
</div>
</div>
<div class="callout callout-style-default callout-note callout-titled">
<div class="callout-header d-flex align-content-center" data-bs-toggle="collapse" data-bs-target=".callout-21-contents" aria-controls="callout-21" aria-expanded="false" aria-label="Toggle callout">
<div class="callout-icon-container">
<i class="callout-icon"></i>
</div>
<div class="callout-title-container flex-fill">
What this code is doing
</div>
<div class="callout-btn-toggle d-inline-block border-0 py-1 ps-1 pe-0 float-end"><i class="callout-toggle"></i></div>
</div>
<div id="callout-21" class="callout-21-contents callout-collapse collapse">
<div class="callout-body-container callout-body">
<ul>
<li>Extracts feature importance scores from the model.</li>
<li>Sorts features by influence.</li>
</ul>
<p>Why this matters:</p>
<ul>
<li>Importance rankings reveal what the model relies on.</li>
<li>Unexpected dominance may indicate leakage or bias.</li>
</ul>
</div>
</div>
</div>
<hr>
</section>
</section>
<section id="e2.-interpreting-feature-importance-carefully" class="level2">
<h2 class="anchored" data-anchor-id="e2.-interpreting-feature-importance-carefully">E2. Interpreting Feature Importance Carefully</h2>
<p>Important cautions:</p>
<ul>
<li>Feature importance ≠ causation</li>
<li>Correlated features share importance</li>
<li>High importance does not imply fairness or validity</li>
</ul>
<p>For example:</p>
<ul>
<li>If <code>duration</code> were included, it would likely dominate importance, reinforcing why we excluded it earlier.</li>
</ul>
<hr>
</section>
<section id="e3.-local-interpretability-explaining-individual-predictions" class="level2">
<h2 class="anchored" data-anchor-id="e3.-local-interpretability-explaining-individual-predictions">E3. Local Interpretability — Explaining Individual Predictions</h2>
<p>Global importance explains <em>overall behaviour</em>. Local interpretability explains <strong>specific decisions</strong>.</p>
<p>Local explanations answer:</p>
<blockquote class="blockquote">
<p><em>Why was this client predicted “yes” or “no”?</em></p>
</blockquote>
<p>Rather than introducing complex mathematics, we focus on the idea:</p>
<ul>
<li>break a prediction into feature contributions,</li>
<li>reason about decisions case by case.</li>
</ul>
<p>This is essential for:</p>
<ul>
<li>audits,</li>
<li>appeals,</li>
<li>trust.</li>
</ul>
<hr>
</section>
<section id="e4.-interpretability-as-a-modelling-constraint" class="level2">
<h2 class="anchored" data-anchor-id="e4.-interpretability-as-a-modelling-constraint">E4. Interpretability as a Modelling Constraint</h2>
<p>Interpretability is not an afterthought.</p>
<p>It influences:</p>
<ul>
<li>model choice,</li>
<li>feature representation,</li>
<li>deployment decisions.</li>
</ul>
<p>In some settings:</p>
<ul>
<li>a simpler model may be preferred,</li>
<li>even if it is slightly less accurate.</li>
</ul>
<hr>
</section>
<section id="key-takeaway-from-parts-d-and-e" class="level2">
<h2 class="anchored" data-anchor-id="key-takeaway-from-parts-d-and-e">Key Takeaway from Parts D and E</h2>
<blockquote class="blockquote">
<p><strong>More powerful models require stronger justification.</strong></p>
</blockquote>
<p>We have seen:</p>
<ul>
<li>why single trees are limited,</li>
<li>how ensembles improve stability,</li>
<li>why interpretability becomes critical as complexity grows.</li>
</ul>
<p>This completes the modelling arc:</p>
<ul>
<li>from meaning (Week 1),</li>
<li>to framing (Parts A–B),</li>
<li>to models (Parts C–D),</li>
<li>back to understanding (Part E).</li>
</ul>
<hr>
</section>
</section>
<section id="part-f-from-meaning-to-models-a-reflective-synthesis" class="level1">
<h1>Part F — From Meaning to Models: A Reflective Synthesis</h1>
<hr>
<section id="part-f-what-have-we-actually-done" class="level2">
<h2 class="anchored" data-anchor-id="part-f-what-have-we-actually-done">Part F: What Have We Actually Done?</h2>
<p>At first glance, this notebook may look like a sequence of models:</p>
<ul>
<li>decision trees,</li>
<li>random forests,</li>
<li>boosted trees.</li>
</ul>
<p>But that is <strong>not</strong> what this notebook was about.</p>
<p>Instead, it was about <strong>how modelling decisions emerge from understanding the data</strong>.</p>
<p>Let us step back and reflect.</p>
<hr>
</section>
<section id="f1.-the-journey-so-far" class="level2">
<h2 class="anchored" data-anchor-id="f1.-the-journey-so-far">F1. The Journey So Far</h2>
<p>Across Week 1 and this notebook, we have followed a deliberate progression:</p>
<ol type="1">
<li><p><strong>Understanding the data-generating process</strong></p>
<ul>
<li>What does one row represent?</li>
<li>Which variables are known when?</li>
<li>Which values are codes rather than measurements?</li>
</ul></li>
<li><p><strong>Framing the learning task</strong></p>
<ul>
<li>Do we have labels?</li>
<li>Is this supervised learning?</li>
<li>Is this classification or regression?</li>
</ul></li>
<li><p><strong>Defining valid inputs</strong></p>
<ul>
<li>Which variables are legitimate at prediction time?</li>
<li>Why some variables must be excluded (e.g.&nbsp;<code>duration</code>).</li>
</ul></li>
<li><p><strong>Choosing interpretable models</strong></p>
<ul>
<li>Starting with a single decision tree.</li>
<li>Understanding how splits represent decisions.</li>
</ul></li>
<li><p><strong>Addressing model limitations</strong></p>
<ul>
<li>Recognising instability in single trees.</li>
<li>Introducing ensembles as a response, not a shortcut.</li>
</ul></li>
<li><p><strong>Returning to meaning through interpretability</strong></p>
<ul>
<li>Understanding what the model relies on globally.</li>
<li>Reasoning about individual predictions locally.</li>
</ul></li>
</ol>
<p>At no point did we jump straight to performance.</p>
<p>This was intentional.</p>
<hr>
</section>
<section id="f2.-accuracy-was-never-the-main-goal" class="level2">
<h2 class="anchored" data-anchor-id="f2.-accuracy-was-never-the-main-goal">F2. Accuracy Was Never the Main Goal</h2>
<p>Throughout this notebook, you may have noticed:</p>
<ul>
<li>performance metrics were shown sparingly,</li>
<li>training accuracy was explicitly labelled as illustrative,</li>
<li>no leaderboard-style comparisons were made.</li>
</ul>
<p>This reflects an important principle:</p>
<blockquote class="blockquote">
<p><strong>A model that scores well for the wrong reasons is worse than a weaker but valid model.</strong></p>
</blockquote>
<p>High accuracy can arise from:</p>
<ul>
<li>leakage,</li>
<li>proxy variables,</li>
<li>historical bias.</li>
</ul>
<p>Without careful reasoning, such models can be:</p>
<ul>
<li>misleading,</li>
<li>unfair,</li>
<li>impossible to justify.</li>
</ul>
<hr>
</section>
<section id="f3.-why-interpretability-is-not-optional" class="level2">
<h2 class="anchored" data-anchor-id="f3.-why-interpretability-is-not-optional">F3. Why Interpretability Is Not Optional</h2>
<p>As models become more complex:</p>
<ul>
<li>their internal logic becomes harder to inspect,</li>
<li>their decisions become harder to justify,</li>
<li>their failure modes become harder to detect.</li>
</ul>
<p>Interpretability allows us to:</p>
<ul>
<li>check whether the model aligns with domain knowledge,</li>
<li>detect suspicious reliance on certain variables,</li>
<li>explain decisions to non-technical stakeholders.</li>
</ul>
<p>This is not a technical luxury — it is a <strong>practical necessity</strong>.</p>
<hr>
</section>
<section id="f4.-model-choice-is-a-contextual-decision" class="level2">
<h2 class="anchored" data-anchor-id="f4.-model-choice-is-a-contextual-decision">F4. Model Choice Is a Contextual Decision</h2>
<p>There is no universally “best” model.</p>
<p>Choosing between:</p>
<ul>
<li>a single decision tree,</li>
<li>a random forest,</li>
<li>a boosted model</li>
</ul>
<p>depends on:</p>
<ul>
<li>the application,</li>
<li>the cost of errors,</li>
<li>the need for explanation,</li>
<li>ethical and regulatory constraints.</li>
</ul>
<p>In some settings:</p>
<ul>
<li>transparency may outweigh accuracy. In others:</li>
<li>performance may justify complexity.</li>
</ul>
<p>The key is that the choice must be <strong>defensible</strong>.</p>
<hr>
</section>
<section id="f5.-what-we-deliberately-did-not-do" class="level2">
<h2 class="anchored" data-anchor-id="f5.-what-we-deliberately-did-not-do">F5. What We Deliberately Did <em>Not</em> Do</h2>
<p>To maintain clarity and focus, we avoided:</p>
<ul>
<li>aggressive feature engineering,</li>
<li>hyperparameter tuning,</li>
<li>cross-validation pipelines,</li>
<li>automated model selection.</li>
</ul>
<p>These steps are important — but <strong>only after</strong>:</p>
<ul>
<li>the problem is framed correctly,</li>
<li>the data is validated,</li>
<li>the modelling assumptions are understood.</li>
</ul>
<p>Those steps belong later in the module.</p>
<hr>
</section>
<section id="f6.-looking-ahead" class="level2">
<h2 class="anchored" data-anchor-id="f6.-looking-ahead">F6. Looking Ahead</h2>
<p>In subsequent work, you will be expected to:</p>
<ul>
<li>evaluate models properly using held-out data,</li>
<li>reason about bias and fairness,</li>
<li>justify modelling choices in writing,</li>
<li>explain predictions clearly.</li>
</ul>
<p>The foundation for all of this has already been laid.</p>
<hr>
</section>
<section id="final-takeaway" class="level2">
<h2 class="anchored" data-anchor-id="final-takeaway">Final Takeaway</h2>
<blockquote class="blockquote">
<p><strong>Good machine learning is not about choosing the most powerful algorithm. It is about making careful, transparent, and justifiable decisions at every step.</strong></p>
</blockquote>
<p>If you can explain:</p>
<ul>
<li><em>what your model is doing</em>,</li>
<li><em>why it is allowed to do it</em>,</li>
<li>and <em>what its limitations are</em>,</li>
</ul>
<p>then you are practising machine learning responsibly.</p>
<hr>
</section>
</section>

</main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
  window.document.addEventListener("DOMContentLoaded", function (event) {
    const icon = "";
    const anchorJS = new window.AnchorJS();
    anchorJS.options = {
      placement: 'right',
      icon: icon
    };
    anchorJS.add('.anchored');
    const isCodeAnnotation = (el) => {
      for (const clz of el.classList) {
        if (clz.startsWith('code-annotation-')) {                     
          return true;
        }
      }
      return false;
    }
    const onCopySuccess = function(e) {
      // button target
      const button = e.trigger;
      // don't keep focus
      button.blur();
      // flash "checked"
      button.classList.add('code-copy-button-checked');
      var currentTitle = button.getAttribute("title");
      button.setAttribute("title", "Copied!");
      let tooltip;
      if (window.bootstrap) {
        button.setAttribute("data-bs-toggle", "tooltip");
        button.setAttribute("data-bs-placement", "left");
        button.setAttribute("data-bs-title", "Copied!");
        tooltip = new bootstrap.Tooltip(button, 
          { trigger: "manual", 
            customClass: "code-copy-button-tooltip",
            offset: [0, -8]});
        tooltip.show();    
      }
      setTimeout(function() {
        if (tooltip) {
          tooltip.hide();
          button.removeAttribute("data-bs-title");
          button.removeAttribute("data-bs-toggle");
          button.removeAttribute("data-bs-placement");
        }
        button.setAttribute("title", currentTitle);
        button.classList.remove('code-copy-button-checked');
      }, 1000);
      // clear code selection
      e.clearSelection();
    }
    const getTextToCopy = function(trigger) {
        const codeEl = trigger.previousElementSibling.cloneNode(true);
        for (const childEl of codeEl.children) {
          if (isCodeAnnotation(childEl)) {
            childEl.remove();
          }
        }
        return codeEl.innerText;
    }
    const clipboard = new window.ClipboardJS('.code-copy-button:not([data-in-quarto-modal])', {
      text: getTextToCopy
    });
    clipboard.on('success', onCopySuccess);
    if (window.document.getElementById('quarto-embedded-source-code-modal')) {
      const clipboardModal = new window.ClipboardJS('.code-copy-button[data-in-quarto-modal]', {
        text: getTextToCopy,
        container: window.document.getElementById('quarto-embedded-source-code-modal')
      });
      clipboardModal.on('success', onCopySuccess);
    }
      var localhostRegex = new RegExp(/^(?:http|https):\/\/localhost\:?[0-9]*\//);
      var mailtoRegex = new RegExp(/^mailto:/);
        var filterRegex = new RegExp('/' + window.location.host + '/');
      var isInternal = (href) => {
          return filterRegex.test(href) || localhostRegex.test(href) || mailtoRegex.test(href);
      }
      // Inspect non-navigation links and adorn them if external
     var links = window.document.querySelectorAll('a[href]:not(.nav-link):not(.navbar-brand):not(.toc-action):not(.sidebar-link):not(.sidebar-item-toggle):not(.pagination-link):not(.no-external):not([aria-hidden]):not(.dropdown-item):not(.quarto-navigation-tool):not(.about-link)');
      for (var i=0; i<links.length; i++) {
        const link = links[i];
        if (!isInternal(link.href)) {
          // undo the damage that might have been done by quarto-nav.js in the case of
          // links that we want to consider external
          if (link.dataset.originalHref !== undefined) {
            link.href = link.dataset.originalHref;
          }
        }
      }
    function tippyHover(el, contentFn, onTriggerFn, onUntriggerFn) {
      const config = {
        allowHTML: true,
        maxWidth: 500,
        delay: 100,
        arrow: false,
        appendTo: function(el) {
            return el.parentElement;
        },
        interactive: true,
        interactiveBorder: 10,
        theme: 'quarto',
        placement: 'bottom-start',
      };
      if (contentFn) {
        config.content = contentFn;
      }
      if (onTriggerFn) {
        config.onTrigger = onTriggerFn;
      }
      if (onUntriggerFn) {
        config.onUntrigger = onUntriggerFn;
      }
      window.tippy(el, config); 
    }
    const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
    for (var i=0; i<noterefs.length; i++) {
      const ref = noterefs[i];
      tippyHover(ref, function() {
        // use id or data attribute instead here
        let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
        try { href = new URL(href).hash; } catch {}
        const id = href.replace(/^#\/?/, "");
        const note = window.document.getElementById(id);
        if (note) {
          return note.innerHTML;
        } else {
          return "";
        }
      });
    }
    const xrefs = window.document.querySelectorAll('a.quarto-xref');
    const processXRef = (id, note) => {
      // Strip column container classes
      const stripColumnClz = (el) => {
        el.classList.remove("page-full", "page-columns");
        if (el.children) {
          for (const child of el.children) {
            stripColumnClz(child);
          }
        }
      }
      stripColumnClz(note)
      if (id === null || id.startsWith('sec-')) {
        // Special case sections, only their first couple elements
        const container = document.createElement("div");
        if (note.children && note.children.length > 2) {
          container.appendChild(note.children[0].cloneNode(true));
          for (let i = 1; i < note.children.length; i++) {
            const child = note.children[i];
            if (child.tagName === "P" && child.innerText === "") {
              continue;
            } else {
              container.appendChild(child.cloneNode(true));
              break;
            }
          }
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(container);
          }
          return container.innerHTML
        } else {
          if (window.Quarto?.typesetMath) {
            window.Quarto.typesetMath(note);
          }
          return note.innerHTML;
        }
      } else {
        // Remove any anchor links if they are present
        const anchorLink = note.querySelector('a.anchorjs-link');
        if (anchorLink) {
          anchorLink.remove();
        }
        if (window.Quarto?.typesetMath) {
          window.Quarto.typesetMath(note);
        }
        if (note.classList.contains("callout")) {
          return note.outerHTML;
        } else {
          return note.innerHTML;
        }
      }
    }
    for (var i=0; i<xrefs.length; i++) {
      const xref = xrefs[i];
      tippyHover(xref, undefined, function(instance) {
        instance.disable();
        let url = xref.getAttribute('href');
        let hash = undefined; 
        if (url.startsWith('#')) {
          hash = url;
        } else {
          try { hash = new URL(url).hash; } catch {}
        }
        if (hash) {
          const id = hash.replace(/^#\/?/, "");
          const note = window.document.getElementById(id);
          if (note !== null) {
            try {
              const html = processXRef(id, note.cloneNode(true));
              instance.setContent(html);
            } finally {
              instance.enable();
              instance.show();
            }
          } else {
            // See if we can fetch this
            fetch(url.split('#')[0])
            .then(res => res.text())
            .then(html => {
              const parser = new DOMParser();
              const htmlDoc = parser.parseFromString(html, "text/html");
              const note = htmlDoc.getElementById(id);
              if (note !== null) {
                const html = processXRef(id, note);
                instance.setContent(html);
              } 
            }).finally(() => {
              instance.enable();
              instance.show();
            });
          }
        } else {
          // See if we can fetch a full url (with no hash to target)
          // This is a special case and we should probably do some content thinning / targeting
          fetch(url)
          .then(res => res.text())
          .then(html => {
            const parser = new DOMParser();
            const htmlDoc = parser.parseFromString(html, "text/html");
            const note = htmlDoc.querySelector('main.content');
            if (note !== null) {
              // This should only happen for chapter cross references
              // (since there is no id in the URL)
              // remove the first header
              if (note.children.length > 0 && note.children[0].tagName === "HEADER") {
                note.children[0].remove();
              }
              const html = processXRef(null, note);
              instance.setContent(html);
            } 
          }).finally(() => {
            instance.enable();
            instance.show();
          });
        }
      }, function(instance) {
      });
    }
        let selectedAnnoteEl;
        const selectorForAnnotation = ( cell, annotation) => {
          let cellAttr = 'data-code-cell="' + cell + '"';
          let lineAttr = 'data-code-annotation="' +  annotation + '"';
          const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
          return selector;
        }
        const selectCodeLines = (annoteEl) => {
          const doc = window.document;
          const targetCell = annoteEl.getAttribute("data-target-cell");
          const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
          const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
          const lines = annoteSpan.getAttribute("data-code-lines").split(",");
          const lineIds = lines.map((line) => {
            return targetCell + "-" + line;
          })
          let top = null;
          let height = null;
          let parent = null;
          if (lineIds.length > 0) {
              //compute the position of the single el (top and bottom and make a div)
              const el = window.document.getElementById(lineIds[0]);
              top = el.offsetTop;
              height = el.offsetHeight;
              parent = el.parentElement.parentElement;
            if (lineIds.length > 1) {
              const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
              const bottom = lastEl.offsetTop + lastEl.offsetHeight;
              height = bottom - top;
            }
            if (top !== null && height !== null && parent !== null) {
              // cook up a div (if necessary) and position it 
              let div = window.document.getElementById("code-annotation-line-highlight");
              if (div === null) {
                div = window.document.createElement("div");
                div.setAttribute("id", "code-annotation-line-highlight");
                div.style.position = 'absolute';
                parent.appendChild(div);
              }
              div.style.top = top - 2 + "px";
              div.style.height = height + 4 + "px";
              div.style.left = 0;
              let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
              if (gutterDiv === null) {
                gutterDiv = window.document.createElement("div");
                gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
                gutterDiv.style.position = 'absolute';
                const codeCell = window.document.getElementById(targetCell);
                const gutter = codeCell.querySelector('.code-annotation-gutter');
                gutter.appendChild(gutterDiv);
              }
              gutterDiv.style.top = top - 2 + "px";
              gutterDiv.style.height = height + 4 + "px";
            }
            selectedAnnoteEl = annoteEl;
          }
        };
        const unselectCodeLines = () => {
          const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
          elementsIds.forEach((elId) => {
            const div = window.document.getElementById(elId);
            if (div) {
              div.remove();
            }
          });
          selectedAnnoteEl = undefined;
        };
          // Handle positioning of the toggle
      window.addEventListener(
        "resize",
        throttle(() => {
          elRect = undefined;
          if (selectedAnnoteEl) {
            selectCodeLines(selectedAnnoteEl);
          }
        }, 10)
      );
      function throttle(fn, ms) {
      let throttle = false;
      let timer;
        return (...args) => {
          if(!throttle) { // first call gets through
              fn.apply(this, args);
              throttle = true;
          } else { // all the others get throttled
              if(timer) clearTimeout(timer); // cancel #2
              timer = setTimeout(() => {
                fn.apply(this, args);
                timer = throttle = false;
              }, ms);
          }
        };
      }
        // Attach click handler to the DT
        const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
        for (const annoteDlNode of annoteDls) {
          annoteDlNode.addEventListener('click', (event) => {
            const clickedEl = event.target;
            if (clickedEl !== selectedAnnoteEl) {
              unselectCodeLines();
              const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
              if (activeEl) {
                activeEl.classList.remove('code-annotation-active');
              }
              selectCodeLines(clickedEl);
              clickedEl.classList.add('code-annotation-active');
            } else {
              // Unselect the line
              unselectCodeLines();
              clickedEl.classList.remove('code-annotation-active');
            }
          });
        }
    const findCites = (el) => {
      const parentEl = el.parentElement;
      if (parentEl) {
        const cites = parentEl.dataset.cites;
        if (cites) {
          return {
            el,
            cites: cites.split(' ')
          };
        } else {
          return findCites(el.parentElement)
        }
      } else {
        return undefined;
      }
    };
    var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
    for (var i=0; i<bibliorefs.length; i++) {
      const ref = bibliorefs[i];
      const citeInfo = findCites(ref);
      if (citeInfo) {
        tippyHover(citeInfo.el, function() {
          var popup = window.document.createElement('div');
          citeInfo.cites.forEach(function(cite) {
            var citeDiv = window.document.createElement('div');
            citeDiv.classList.add('hanging-indent');
            citeDiv.classList.add('csl-entry');
            var biblioDiv = window.document.getElementById('ref-' + cite);
            if (biblioDiv) {
              citeDiv.innerHTML = biblioDiv.innerHTML;
            }
            popup.appendChild(citeDiv);
          });
          return popup.innerHTML;
        });
      }
    }
  });
  </script>
</div> <!-- /content -->




</body></html>